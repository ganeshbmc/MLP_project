{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported all libraries successfully!\n"
     ]
    }
   ],
   "source": [
    "from mytools import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "print(\"Imported all libraries successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = load_csv(\"train\")\n",
    "moviesdf = load_csv(\"movies\")\n",
    "traindf.shape, moviesdf.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine movies.csv data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moviesdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moviesdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moviesdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moviesdf.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moviesdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moviesdf[\"genre\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop duplicates from moviesdf dataframe  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_unique = moviesdf.drop_duplicates(subset=[\"movieid\"])\n",
    "movies_unique.shape, moviesdf.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge traindf and moviesdf  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_movies_merged = pd.merge(traindf, movies_unique, on=\"movieid\")\n",
    "train_movies_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_movies_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_movies_merged = train_movies_merged[['movieid', 'reviewerName', 'isFrequentReviewer', 'reviewText',\n",
    "       'title', 'audienceScore', 'rating', 'ratingContents',\n",
    "       'releaseDateTheaters', 'releaseDateStreaming', 'runtimeMinutes',\n",
    "       'genre', 'originalLanguage', 'director', 'boxOffice', 'distributor',\n",
    "       'soundType', 'sentiment']]\n",
    "train_movies_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_movies_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_movies_merged.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data in merged df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in \"reviewText\", 'rating\" column with empty string and \"NA\" respectively\n",
    "# Clean language names\n",
    "\n",
    "train_final = train_movies_merged.copy()\n",
    "train_final[\"reviewText\"] = train_final[\"reviewText\"].fillna(\" \")\n",
    "train_final[\"rating\"] = train_final[\"rating\"].fillna(\"NA\")\n",
    "train_final[\"originalLanguage\"].replace({\"English (United Kingdom)\": \"English\", \n",
    "                                         \"English (Australia)\" : \"English\",\n",
    "                                         \"French (France)\": \"French\", \n",
    "                                         \"French (Canada)\": \"French\",\n",
    "                                         \"Portuguese (Brazil)\": \"Portuguese\",\n",
    "                                         \"Spanish (Spain)\": \"Spanish\"},                                         \n",
    "                                         inplace=True)\n",
    "train_final[\"reviewText\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final[\"rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final[\"genre\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final[\"originalLanguage\"].unique(), train_final[\"originalLanguage\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep only the columns to work on  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final = train_final.drop(columns=[\"title\", \"ratingContents\", \"releaseDateTheaters\", \"releaseDateStreaming\", \"boxOffice\", \"distributor\", \"soundType\"])\n",
    "train_final.shape,  train_final.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate features and labels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_final.iloc[:, :-1]\n",
    "train_labels = train_final.iloc[:, -1]\n",
    "train_features.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try \"select_features\" function from mytools module  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieid</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>isFrequentReviewer</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>audienceScore</th>\n",
       "      <th>rating</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genre</th>\n",
       "      <th>originalLanguage</th>\n",
       "      <th>director</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>marvelous_pirate</td>\n",
       "      <td>Benjamin Henry</td>\n",
       "      <td>False</td>\n",
       "      <td>Henry Selick’s first movie since 2009’s Corali...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>65.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Comedy, Animation, Adventure, Fantasy</td>\n",
       "      <td>English</td>\n",
       "      <td>Bennie Basso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>marvelous_pirate</td>\n",
       "      <td>Sharon Foster</td>\n",
       "      <td>False</td>\n",
       "      <td>&amp;#91;T&amp;#93;he haphazard way this story is asse...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>65.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Comedy, Animation, Adventure, Fantasy</td>\n",
       "      <td>English</td>\n",
       "      <td>Bennie Basso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marvelous_pirate</td>\n",
       "      <td>Melinda Dunn</td>\n",
       "      <td>False</td>\n",
       "      <td>The stop-motion artistry of Wendell &amp;amp; Wild...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>65.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Comedy, Animation, Adventure, Fantasy</td>\n",
       "      <td>English</td>\n",
       "      <td>Bennie Basso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>marvelous_pirate</td>\n",
       "      <td>Mr. Wayne Smith</td>\n",
       "      <td>False</td>\n",
       "      <td>Wendell &amp;amp; Wild is narratively overstuffed ...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>65.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Comedy, Animation, Adventure, Fantasy</td>\n",
       "      <td>English</td>\n",
       "      <td>Bennie Basso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marvelous_pirate</td>\n",
       "      <td>Connor Nelson</td>\n",
       "      <td>False</td>\n",
       "      <td>For being about the Netherworlds&amp;#44; it&amp;#8217...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>65.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Comedy, Animation, Adventure, Fantasy</td>\n",
       "      <td>English</td>\n",
       "      <td>Bennie Basso</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            movieid     reviewerName  isFrequentReviewer  \\\n",
       "0  marvelous_pirate   Benjamin Henry               False   \n",
       "1  marvelous_pirate    Sharon Foster               False   \n",
       "2  marvelous_pirate     Melinda Dunn               False   \n",
       "3  marvelous_pirate  Mr. Wayne Smith               False   \n",
       "4  marvelous_pirate    Connor Nelson               False   \n",
       "\n",
       "                                          reviewText sentiment  audienceScore  \\\n",
       "0  Henry Selick’s first movie since 2009’s Corali...  POSITIVE           65.0   \n",
       "1  &#91;T&#93;he haphazard way this story is asse...  NEGATIVE           65.0   \n",
       "2  The stop-motion artistry of Wendell &amp; Wild...  POSITIVE           65.0   \n",
       "3  Wendell &amp; Wild is narratively overstuffed ...  NEGATIVE           65.0   \n",
       "4  For being about the Netherworlds&#44; it&#8217...  POSITIVE           65.0   \n",
       "\n",
       "  rating  runtimeMinutes                                  genre  \\\n",
       "0  PG-13           105.0  Comedy, Animation, Adventure, Fantasy   \n",
       "1  PG-13           105.0  Comedy, Animation, Adventure, Fantasy   \n",
       "2  PG-13           105.0  Comedy, Animation, Adventure, Fantasy   \n",
       "3  PG-13           105.0  Comedy, Animation, Adventure, Fantasy   \n",
       "4  PG-13           105.0  Comedy, Animation, Adventure, Fantasy   \n",
       "\n",
       "  originalLanguage      director  \n",
       "0          English  Bennie Basso  \n",
       "1          English  Bennie Basso  \n",
       "2          English  Bennie Basso  \n",
       "3          English  Bennie Basso  \n",
       "4          English  Bennie Basso  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = select_features(load_csv(\"train\"), load_csv(\"movies\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162758, 11)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movieid', 'reviewerName', 'isFrequentReviewer', 'reviewText',\n",
       "       'sentiment', 'audienceScore', 'rating', 'runtimeMinutes', 'genre',\n",
       "       'originalLanguage', 'director'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieid</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>isTopCritic</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>audienceScore</th>\n",
       "      <th>rating</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genre</th>\n",
       "      <th>originalLanguage</th>\n",
       "      <th>director</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>legend_marty_mcfly_oracle</td>\n",
       "      <td>John Kim</td>\n",
       "      <td>False</td>\n",
       "      <td>Green slowly cranks up the dread with style an...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>R</td>\n",
       "      <td>111.0</td>\n",
       "      <td>Holiday, Horror, Mystery &amp; thriller</td>\n",
       "      <td>English</td>\n",
       "      <td>Sara Barnett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>legend_marty_mcfly_oracle</td>\n",
       "      <td>Kathleen Poole</td>\n",
       "      <td>False</td>\n",
       "      <td>Considering this is the 13th Halloween movie&amp;#...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>R</td>\n",
       "      <td>111.0</td>\n",
       "      <td>Holiday, Horror, Mystery &amp; thriller</td>\n",
       "      <td>English</td>\n",
       "      <td>Sara Barnett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>legend_marty_mcfly_oracle</td>\n",
       "      <td>Kenneth Lamb</td>\n",
       "      <td>False</td>\n",
       "      <td>Halloween Ends is by no means the worst horror...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>R</td>\n",
       "      <td>111.0</td>\n",
       "      <td>Holiday, Horror, Mystery &amp; thriller</td>\n",
       "      <td>English</td>\n",
       "      <td>Sara Barnett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>legend_marty_mcfly_oracle</td>\n",
       "      <td>Brittany Lane</td>\n",
       "      <td>False</td>\n",
       "      <td>A concluding chapter that shares more DNA with...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>R</td>\n",
       "      <td>111.0</td>\n",
       "      <td>Holiday, Horror, Mystery &amp; thriller</td>\n",
       "      <td>English</td>\n",
       "      <td>Sara Barnett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>legend_marty_mcfly_oracle</td>\n",
       "      <td>Yolanda Thomas</td>\n",
       "      <td>False</td>\n",
       "      <td>For a film called Halloween Ends&amp;#44; let&amp;#821...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>R</td>\n",
       "      <td>111.0</td>\n",
       "      <td>Holiday, Horror, Mystery &amp; thriller</td>\n",
       "      <td>English</td>\n",
       "      <td>Sara Barnett</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     movieid    reviewerName  isTopCritic  \\\n",
       "0  legend_marty_mcfly_oracle        John Kim        False   \n",
       "1  legend_marty_mcfly_oracle  Kathleen Poole        False   \n",
       "2  legend_marty_mcfly_oracle    Kenneth Lamb        False   \n",
       "3  legend_marty_mcfly_oracle   Brittany Lane        False   \n",
       "4  legend_marty_mcfly_oracle  Yolanda Thomas        False   \n",
       "\n",
       "                                          reviewText  audienceScore rating  \\\n",
       "0  Green slowly cranks up the dread with style an...           57.0      R   \n",
       "1  Considering this is the 13th Halloween movie&#...           57.0      R   \n",
       "2  Halloween Ends is by no means the worst horror...           57.0      R   \n",
       "3  A concluding chapter that shares more DNA with...           57.0      R   \n",
       "4  For a film called Halloween Ends&#44; let&#821...           57.0      R   \n",
       "\n",
       "   runtimeMinutes                                genre originalLanguage  \\\n",
       "0           111.0  Holiday, Horror, Mystery & thriller          English   \n",
       "1           111.0  Holiday, Horror, Mystery & thriller          English   \n",
       "2           111.0  Holiday, Horror, Mystery & thriller          English   \n",
       "3           111.0  Holiday, Horror, Mystery & thriller          English   \n",
       "4           111.0  Holiday, Horror, Mystery & thriller          English   \n",
       "\n",
       "       director  \n",
       "0  Sara Barnett  \n",
       "1  Sara Barnett  \n",
       "2  Sara Barnett  \n",
       "3  Sara Barnett  \n",
       "4  Sara Barnett  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest = select_features(load_csv(\"test\"), load_csv(\"movies\"))\n",
    "dftest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55315, 10)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movieid', 'reviewerName', 'isTopCritic', 'reviewText', 'audienceScore',\n",
       "       'rating', 'runtimeMinutes', 'genre', 'originalLanguage', 'director'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movieid', 'reviewerName', 'isFrequentReviewer', 'reviewText',\n",
       "       'sentiment', 'audienceScore', 'rating', 'runtimeMinutes', 'genre',\n",
       "       'originalLanguage', 'director'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((162758, 10), (162758,))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1_fs = df[['movieid', \n",
    "                'reviewerName', \n",
    "                'isFrequentReviewer', \n",
    "                'reviewText',\n",
    "                'audienceScore', \n",
    "                'rating', \n",
    "                'runtimeMinutes', \n",
    "                'genre', \n",
    "                'originalLanguage', \n",
    "                'director'\n",
    "                ]]\n",
    "\n",
    "# train1_fs = df[['reviewText',\n",
    "#                 'audienceScore', \n",
    "#                 'runtimeMinutes', \n",
    "#                 'genre', \n",
    "#                 'originalLanguage', \n",
    "#                 'director'\n",
    "#               ]]\n",
    "\n",
    "train1_labels = df['sentiment']\n",
    "train1_fs.shape, train1_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train1_fs.loc[:, \"audienceScore\"] = SimpleImputer(strategy='mean', missing_values=np.nan).fit_transform(train1_fs[[\"audienceScore\"]])\n",
    "# train1_fs.loc[:, \"runtimeMinutes\"] = SimpleImputer(strategy='mean', missing_values=np.nan).fit_transform(train1_fs[[\"runtimeMinutes\"]])\n",
    "# train1_fs.loc[:, \"genre\"] = SimpleImputer(strategy='most_frequent').fit_transform(train1_fs[[\"genre\"]])\n",
    "# train1_fs.loc[:, \"originalLanguage\"] = SimpleImputer(strategy='constant', fill_value='Unknown').fit_transform(train1_fs[[\"originalLanguage\"]])\n",
    "# train1_fs.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((122068, 10), (40690, 10), (122068,), (40690,))"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train1_fs, train1_labels, test_size=0.25, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 162758 entries, 0 to 162757\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   movieid             162758 non-null  object \n",
      " 1   reviewerName        162758 non-null  object \n",
      " 2   isFrequentReviewer  162758 non-null  bool   \n",
      " 3   reviewText          162758 non-null  object \n",
      " 4   audienceScore       149510 non-null  float64\n",
      " 5   rating              162758 non-null  object \n",
      " 6   runtimeMinutes      159382 non-null  float64\n",
      " 7   genre               160320 non-null  object \n",
      " 8   originalLanguage    159468 non-null  object \n",
      " 9   director            162758 non-null  object \n",
      "dtypes: bool(1), float64(2), object(7)\n",
      "memory usage: 12.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train1_fs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieid                   0\n",
       "reviewerName              0\n",
       "isFrequentReviewer        0\n",
       "reviewText                0\n",
       "audienceScore         13248\n",
       "rating                    0\n",
       "runtimeMinutes         3376\n",
       "genre                  2438\n",
       "originalLanguage       3290\n",
       "director                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1_fs.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ct1_imputer = ColumnTransformer(transformers=[\n",
    "#                                 ('imputer_audienceScore', SimpleImputer(strategy='mean', missing_values=np.nan), ['audienceScore']),\n",
    "#                                 ('imputer_runtimeMinutes', SimpleImputer(strategy='mean', missing_values=np.nan), ['runtimeMinutes']),\n",
    "#                                 ('imputer_genre', SimpleImputer(strategy='most_frequent'), ['genre']),\n",
    "#                                 ('imputer_lang', SimpleImputer(strategy='constant', fill_value='Unknown'), ['originalLanguage']),\n",
    "#                                 ], \n",
    "#                                 remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_imputer_num = Pipeline(steps=[\n",
    "                                ('imp1', SimpleImputer(strategy='mean', missing_values=np.nan)),\n",
    "                                # ('toarray', FunctionTransformer(lambda x: x.toarray(), accept_sparse=True))\n",
    "                            ])\n",
    "\n",
    "pipe_imputer_freq = Pipeline(steps=[\n",
    "                                ('imp2', SimpleImputer(strategy='most_frequent')),\n",
    "                                ('toarray', FunctionTransformer(lambda x: x.toarray(), accept_sparse=True))\n",
    "                            ])\n",
    "\n",
    "pipe_imputer_const = Pipeline(steps=[\n",
    "                                ('imp3', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "                                ('toarray', FunctionTransformer(lambda x: x.toarray(), accept_sparse=True))\n",
    "                            ])\n",
    "\n",
    "# pipe_tvec = Pipeline(steps=[\n",
    "#                             ('tvec', TfidfVectorizer(max_features=10000)),\n",
    "#                             ('toarray', FunctionTransformer(lambda x: x.toarray(), accept_sparse=True))\n",
    "#                             ])\n",
    "\n",
    "vectorizer_params = dict(max_features=10000)\n",
    "pipe_text = Pipeline(steps=[\n",
    "                            # ('imp', SimpleImputer(strategy='most_frequent')),\n",
    "                            # (\"squeez\", FunctionTransformer(lambda x: x.squeeze())),\n",
    "                            # (\"vect\", CountVectorizer(**vectorizer_params)),\n",
    "                            # (\"tfidf\", TfidfTransformer()),\n",
    "                            (\"tvec\", TfidfVectorizer(**vectorizer_params)),\n",
    "                            # (\"toarray\", FunctionTransformer(lambda x: x.toarray())),\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieid                   0\n",
       "reviewerName              0\n",
       "isFrequentReviewer        0\n",
       "reviewText                0\n",
       "audienceScore         13248\n",
       "rating                    0\n",
       "runtimeMinutes         3376\n",
       "genre                  2438\n",
       "originalLanguage       3290\n",
       "director                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1_fs.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movieid', 'reviewerName', 'isFrequentReviewer', 'reviewText',\n",
       "       'audienceScore', 'rating', 'runtimeMinutes', 'genre',\n",
       "       'originalLanguage', 'director'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1_fs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct2 = ColumnTransformer(transformers=[\n",
    "                                    ('num', pipe_imputer_num, ['audienceScore', 'runtimeMinutes']),\n",
    "                                    ('text', pipe_text, 'director'),\n",
    "                                    ('reviewText', pipe_text, 'reviewText'),\n",
    "                                    ], \n",
    "                                    remainder='drop', sparse_threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ct1 = ColumnTransformer(transformers=[\n",
    "#                         ('tvec_movieid', TfidfVectorizer(), ['movieid']),\n",
    "#                          ('tvec_reviewerName', TfidfVectorizer(max_features=10000), ['reviewerName']),\n",
    "#                         #  ('ohe_freqRev', OneHotEncoder(handle_unknown='ignore'), ['isFrequentReviewer']),\n",
    "#                         ('tvec_isFreq', TfidfVectorizer(), ['isFrequentReviewer']),\n",
    "#                          ('tvec_reviewText', TfidfVectorizer(ngram_range=(1,2), max_features=10000), ['reviewText']),\n",
    "#                         #  ('std_scaler_audienceScore', StandardScaler(), ['audienceScore']),\n",
    "#                         #  ('ohe_rating', OneHotEncoder(handle_unknown='ignore'), ['rating']),\n",
    "#                         ('tvec_rating', TfidfVectorizer(), ['rating']),\n",
    "#                         #  ('mm_scaler_runtimeMinutes', MinMaxScaler(), ['runtimeMinutes']),\n",
    "#                          ('tvec_genre', TfidfVectorizer(max_features=20), ['genre']),\n",
    "#                          ('tvec_originalLanguage', TfidfVectorizer(max_features=100), ['originalLanguage']),\n",
    "#                          ('tvec_director', TfidfVectorizer(max_features=10000), ['director']),\n",
    "#                          ], remainder='passthrough', sparse_threshold=0.3)\n",
    "# ct1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = Pipeline(steps=[\n",
    "                        # ('imputer', ct1_imputer),\n",
    "                        ('transformer', ct2), \n",
    "                        ('logreg', LogisticRegression(C=2, max_iter=1000))\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7395058491988072"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred shape: (40690,)\n",
      "Summary of predictions: (array(['NEGATIVE', 'POSITIVE'], dtype=object), array([ 8600, 32090], dtype=int64))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.63      0.40      0.49     13717\n",
      "    POSITIVE       0.74      0.88      0.81     26973\n",
      "\n",
      "    accuracy                           0.72     40690\n",
      "   macro avg       0.69      0.64      0.65     40690\n",
      "weighted avg       0.71      0.72      0.70     40690\n",
      "\n",
      "[[ 5444  8273]\n",
      " [ 3156 23817]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE', 'POSITIVE', 'POSITIVE', ..., 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE'], dtype=object)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_n_evaluate(pipe1, X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test1 = dftest[['reviewerName', 'isTopCritic', 'reviewText']]\n",
    "# test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movieid', 'reviewerName', 'isFrequentReviewer', 'reviewText',\n",
       "       'audienceScore', 'rating', 'runtimeMinutes', 'genre',\n",
       "       'originalLanguage', 'director'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NA       47713\n",
       "R        37952\n",
       "PG-13    27155\n",
       "PG        8806\n",
       "NC-17      153\n",
       "TVPG       147\n",
       "TV14       110\n",
       "TVMA        32\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 81.0 MiB for an array with shape (122068, 87) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GANESH~1\\AppData\\Local\\Temp/ipykernel_15944/1518944333.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0myyyy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"originalLanguage\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mypd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myyyy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mypd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\All users\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1029\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\All users\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 81.0 MiB for an array with shape (122068, 87) and data type float64"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer()\n",
    "yyyy = vec.fit_transform(X_train[\"originalLanguage\"].astype(str))\n",
    "ypd = pd.DataFrame(yyyy.toarray())\n",
    "ypd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      34.0\n",
       "1      29.0\n",
       "2       8.0\n",
       "3     534.0\n",
       "4      24.0\n",
       "      ...  \n",
       "82     43.0\n",
       "83     10.0\n",
       "84     14.0\n",
       "85      2.0\n",
       "86     29.0\n",
       "Length: 87, dtype: float64"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypd.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['afrikaans',\n",
       " 'albanian',\n",
       " 'amharic',\n",
       " 'arabic',\n",
       " 'aramaic',\n",
       " 'armenian',\n",
       " 'azerbaijani',\n",
       " 'bambara',\n",
       " 'bangla',\n",
       " 'bosnian',\n",
       " 'bulgarian',\n",
       " 'catalan',\n",
       " 'chinese',\n",
       " 'croatian',\n",
       " 'crp',\n",
       " 'czech',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'dzongkha',\n",
       " 'english',\n",
       " 'estonian',\n",
       " 'filipino',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'galician',\n",
       " 'georgian',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'gujarati',\n",
       " 'hebrew',\n",
       " 'hindi',\n",
       " 'hungarian',\n",
       " 'icelandic',\n",
       " 'indonesian',\n",
       " 'inuktitut',\n",
       " 'irish',\n",
       " 'italian',\n",
       " 'japanese',\n",
       " 'kalaallisut',\n",
       " 'kannada',\n",
       " 'khmer',\n",
       " 'korean',\n",
       " 'kurdish',\n",
       " 'language',\n",
       " 'lao',\n",
       " 'latvian',\n",
       " 'lingala',\n",
       " 'lithuanian',\n",
       " 'luxembourgish',\n",
       " 'macedonian',\n",
       " 'malay',\n",
       " 'malayalam',\n",
       " 'maltese',\n",
       " 'maori',\n",
       " 'marathi',\n",
       " 'mongolian',\n",
       " 'nan',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'pashto',\n",
       " 'persian',\n",
       " 'polish',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'romany',\n",
       " 'russian',\n",
       " 'serbian',\n",
       " 'slovak',\n",
       " 'slovenian',\n",
       " 'somali',\n",
       " 'spanish',\n",
       " 'swahili',\n",
       " 'swedish',\n",
       " 'tagalog',\n",
       " 'tamil',\n",
       " 'telugu',\n",
       " 'thai',\n",
       " 'tibetan',\n",
       " 'turkish',\n",
       " 'ukrainian',\n",
       " 'unknown',\n",
       " 'urdu',\n",
       " 'vietnamese',\n",
       " 'welsh',\n",
       " 'wolof',\n",
       " 'xhosa',\n",
       " 'yiddish']"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english': 19,\n",
       " 'french': 23,\n",
       " 'korean': 41,\n",
       " 'unknown': 80,\n",
       " 'language': 43,\n",
       " 'chinese': 12,\n",
       " 'spanish': 70,\n",
       " 'nan': 56,\n",
       " 'italian': 36,\n",
       " 'japanese': 37,\n",
       " 'german': 26,\n",
       " 'hebrew': 29,\n",
       " 'malayalam': 51,\n",
       " 'serbian': 66,\n",
       " 'persian': 60,\n",
       " 'hindi': 30,\n",
       " 'marathi': 54,\n",
       " 'czech': 15,\n",
       " 'hungarian': 31,\n",
       " 'thai': 76,\n",
       " 'finnish': 22,\n",
       " 'portuguese': 62,\n",
       " 'albanian': 1,\n",
       " 'danish': 16,\n",
       " 'vietnamese': 82,\n",
       " 'swedish': 72,\n",
       " 'romanian': 63,\n",
       " 'turkish': 78,\n",
       " 'bangla': 8,\n",
       " 'russian': 65,\n",
       " 'arabic': 3,\n",
       " 'tamil': 74,\n",
       " 'polish': 61,\n",
       " 'telugu': 75,\n",
       " 'croatian': 13,\n",
       " 'norwegian': 58,\n",
       " 'bulgarian': 10,\n",
       " 'icelandic': 32,\n",
       " 'kannada': 39,\n",
       " 'kurdish': 42,\n",
       " 'lithuanian': 47,\n",
       " 'dutch': 17,\n",
       " 'afrikaans': 0,\n",
       " 'tagalog': 73,\n",
       " 'dzongkha': 18,\n",
       " 'wolof': 84,\n",
       " 'urdu': 81,\n",
       " 'pashto': 59,\n",
       " 'greek': 27,\n",
       " 'romany': 64,\n",
       " 'amharic': 2,\n",
       " 'macedonian': 49,\n",
       " 'khmer': 40,\n",
       " 'estonian': 20,\n",
       " 'filipino': 21,\n",
       " 'inuktitut': 34,\n",
       " 'slovenian': 68,\n",
       " 'welsh': 83,\n",
       " 'georgian': 25,\n",
       " 'catalan': 11,\n",
       " 'indonesian': 33,\n",
       " 'yiddish': 86,\n",
       " 'swahili': 71,\n",
       " 'bambara': 7,\n",
       " 'kalaallisut': 38,\n",
       " 'maori': 53,\n",
       " 'galician': 24,\n",
       " 'mongolian': 55,\n",
       " 'aramaic': 4,\n",
       " 'lingala': 46,\n",
       " 'latvian': 45,\n",
       " 'ukrainian': 79,\n",
       " 'crp': 14,\n",
       " 'tibetan': 77,\n",
       " 'bosnian': 9,\n",
       " 'maltese': 52,\n",
       " 'nepali': 57,\n",
       " 'lao': 44,\n",
       " 'slovak': 67,\n",
       " 'xhosa': 85,\n",
       " 'luxembourgish': 48,\n",
       " 'irish': 35,\n",
       " 'armenian': 5,\n",
       " 'gujarati': 28,\n",
       " 'malay': 50,\n",
       " 'somali': 69,\n",
       " 'azerbaijani': 6}"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyzer': 'word',\n",
       " 'binary': False,\n",
       " 'decode_error': 'strict',\n",
       " 'dtype': numpy.float64,\n",
       " 'encoding': 'utf-8',\n",
       " 'input': 'content',\n",
       " 'lowercase': True,\n",
       " 'max_df': 1.0,\n",
       " 'max_features': None,\n",
       " 'min_df': 1,\n",
       " 'ngram_range': (1, 1),\n",
       " 'norm': 'l2',\n",
       " 'preprocessor': None,\n",
       " 'smooth_idf': True,\n",
       " 'stop_words': None,\n",
       " 'strip_accents': None,\n",
       " 'sublinear_tf': False,\n",
       " 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tokenizer': None,\n",
       " 'use_idf': True,\n",
       " 'vocabulary': None}"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.get_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
