{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# MLP Project (T2 2023) by Ganesh P  ","metadata":{}},{"cell_type":"markdown","source":"`Disclaimer`   \n\n> This final notebook contains only the most relevant code to show the path/flow of my project work over few weeks. Rest of the code is in [my github repo](https://github.com/ganeshbmc/MLP_project) which is private at present (I will make it public after the project is over).  ","metadata":{}},{"cell_type":"markdown","source":"`Strengths`  \n\n> * Modular code (DRY principle)  \n> * End to end pipeline in one function (with helper functions)   ","metadata":{}},{"cell_type":"markdown","source":"`Overview`  \n\n`PART I`  \n\n1.\t> Screen the datasets and import them.  \n2.\t> Perform EDA (first round).\n3.\t> Data cleaning.\n4.\t> Basic models including dummy model.\n5.\t> Because this is a text sentiment analysis project, focus on 'reviewText' column, work on cleaning text data and vectorising/tokenising it, build several models till the best possible score is reached.  \n\n`PART II`  \n\n6.\t> Merge train and movies dataset.\n7.\t> Perform EDA (second round) on merged dataset.\n8.\t> Data cleaning.\n9.\t> Build models on merged dataset.\n10.\t> Understand the results and do another round of EDA if needed.\n11.\t> Build final model.  \n\n`PART III (After project window closes)`  \n\n12. > Use NLTK library for further processing text data.  \n13. > Try to address comments from different languages, special characters etc.  \n14. > Try imblearn library to address class imbalance.  \n15. > Try to use currently available LLMs and see how my model performs agains them.  ","metadata":{}},{"cell_type":"markdown","source":"`Default code on Kaggle notebook`  ","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.028392,"end_time":"2023-06-05T20:36:35.300111","exception":false,"start_time":"2023-06-05T20:36:35.271719","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:02:41.377287Z","iopub.execute_input":"2023-08-11T19:02:41.378248Z","iopub.status.idle":"2023-08-11T19:02:41.419675Z","shell.execute_reply.started":"2023-08-11T19:02:41.378199Z","shell.execute_reply":"2023-08-11T19:02:41.418782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Specify platform  ","metadata":{}},{"cell_type":"code","source":"platform = 'kaggle'  ","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:02:41.425675Z","iopub.execute_input":"2023-08-11T19:02:41.426338Z","iopub.status.idle":"2023-08-11T19:02:41.431017Z","shell.execute_reply.started":"2023-08-11T19:02:41.426304Z","shell.execute_reply":"2023-08-11T19:02:41.429690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Import libraries  ","metadata":{"papermill":{"duration":0.012641,"end_time":"2023-06-05T20:36:35.326003","exception":false,"start_time":"2023-06-05T20:36:35.313362","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nfrom itertools import compress\n\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import classification_report, confusion_matrix,f1_score\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.naive_bayes import GaussianNB, BernoulliNB, CategoricalNB, ComplementNB, MultinomialNB\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.decomposition import PCA, TruncatedSVD\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.feature_selection import RFE\nfrom sklearn.neural_network import MLPClassifier\n\n# import lightgbm as ltb\n\nimport scipy.stats as stats\nprint(\"Imports done.\")","metadata":{"papermill":{"duration":1.333584,"end_time":"2023-06-05T20:36:36.672264","exception":false,"start_time":"2023-06-05T20:36:35.338680","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:02:41.479778Z","iopub.execute_input":"2023-08-11T19:02:41.480275Z","iopub.status.idle":"2023-08-11T19:02:44.100731Z","shell.execute_reply.started":"2023-08-11T19:02:41.480227Z","shell.execute_reply":"2023-08-11T19:02:44.099136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PART I  ","metadata":{}},{"cell_type":"markdown","source":"## Load datasets  ","metadata":{"papermill":{"duration":0.012132,"end_time":"2023-06-05T20:36:36.697539","exception":false,"start_time":"2023-06-05T20:36:36.685407","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if platform == 'vscode':\n    traindf = pd.read_csv(\"data/train.csv\")\nelse:\n    traindf = pd.read_csv(\"/kaggle/input/sentiment-prediction-on-movie-reviews/train.csv\")\n    \ntraindf.shape","metadata":{"papermill":{"duration":0.776221,"end_time":"2023-06-05T20:36:37.486187","exception":false,"start_time":"2023-06-05T20:36:36.709966","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:02:44.102817Z","iopub.execute_input":"2023-08-11T19:02:44.103230Z","iopub.status.idle":"2023-08-11T19:02:45.192571Z","shell.execute_reply.started":"2023-08-11T19:02:44.103198Z","shell.execute_reply":"2023-08-11T19:02:45.190991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if platform == 'vscode':\n    testdf = pd.read_csv(\"data/test.csv\")\nelse:\n    testdf = pd.read_csv(\"/kaggle/input/sentiment-prediction-on-movie-reviews/test.csv\")\n\ntestdf.shape","metadata":{"papermill":{"duration":0.270116,"end_time":"2023-06-05T20:36:37.769765","exception":false,"start_time":"2023-06-05T20:36:37.499649","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:02:45.200971Z","iopub.execute_input":"2023-08-11T19:02:45.201870Z","iopub.status.idle":"2023-08-11T19:02:45.580346Z","shell.execute_reply.started":"2023-08-11T19:02:45.201827Z","shell.execute_reply":"2023-08-11T19:02:45.579123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Understanding the data and getting it ready for training and evaluating models  \n","metadata":{"papermill":{"duration":0.016128,"end_time":"2023-06-05T20:36:37.801303","exception":false,"start_time":"2023-06-05T20:36:37.785175","status":"completed"},"tags":[]}},{"cell_type":"code","source":"traindf.shape","metadata":{"papermill":{"duration":0.022103,"end_time":"2023-06-05T20:36:37.836648","exception":false,"start_time":"2023-06-05T20:36:37.814545","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:02:45.581979Z","iopub.execute_input":"2023-08-11T19:02:45.582483Z","iopub.status.idle":"2023-08-11T19:02:45.590681Z","shell.execute_reply.started":"2023-08-11T19:02:45.582441Z","shell.execute_reply":"2023-08-11T19:02:45.589382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traindf.info()","metadata":{"papermill":{"duration":0.143829,"end_time":"2023-06-05T20:36:37.993990","exception":false,"start_time":"2023-06-05T20:36:37.850161","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:02:45.592037Z","iopub.execute_input":"2023-08-11T19:02:45.592475Z","iopub.status.idle":"2023-08-11T19:02:45.844981Z","shell.execute_reply.started":"2023-08-11T19:02:45.592437Z","shell.execute_reply":"2023-08-11T19:02:45.842821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traindf.isna().sum()","metadata":{"papermill":{"duration":0.11876,"end_time":"2023-06-05T20:36:38.126201","exception":false,"start_time":"2023-06-05T20:36:38.007441","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:02:45.846852Z","iopub.execute_input":"2023-08-11T19:02:45.847390Z","iopub.status.idle":"2023-08-11T19:02:46.074053Z","shell.execute_reply.started":"2023-08-11T19:02:45.847339Z","shell.execute_reply":"2023-08-11T19:02:46.072962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fill empty reviewText with custom text  ","metadata":{"papermill":{"duration":0.013309,"end_time":"2023-06-05T20:36:38.153155","exception":false,"start_time":"2023-06-05T20:36:38.139846","status":"completed"},"tags":[]}},{"cell_type":"code","source":"traindf[\"reviewText\"].fillna(\"empty\", inplace=True)\ntraindf.isna().sum()","metadata":{"papermill":{"duration":0.135765,"end_time":"2023-06-05T20:36:38.301838","exception":false,"start_time":"2023-06-05T20:36:38.166073","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:02:46.075776Z","iopub.execute_input":"2023-08-11T19:02:46.076247Z","iopub.status.idle":"2023-08-11T19:02:46.330552Z","shell.execute_reply.started":"2023-08-11T19:02:46.076207Z","shell.execute_reply":"2023-08-11T19:02:46.329195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA  \n","metadata":{}},{"cell_type":"code","source":"# Pie chart for sentiment column\nplt.figure(figsize=(6, 4))\ntraindf[\"sentiment\"].value_counts().plot(kind='pie', autopct='%1.0f%%', colors=[\"lightgreen\", \"crimson\"])\nplt.title(\"Pie chart for sentiment column\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:02:46.332196Z","iopub.execute_input":"2023-08-11T19:02:46.332565Z","iopub.status.idle":"2023-08-11T19:02:46.592246Z","shell.execute_reply.started":"2023-08-11T19:02:46.332531Z","shell.execute_reply":"2023-08-11T19:02:46.590683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Chi-square test for isFrequentReviewer column and sentiment column   \n\ncontingency_table = pd.crosstab(traindf['isFrequentReviewer'], traindf['sentiment'])\nprint(contingency_table)\nstats.chi2_contingency(contingency_table)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:02:46.600060Z","iopub.execute_input":"2023-08-11T19:02:46.600980Z","iopub.status.idle":"2023-08-11T19:02:46.708160Z","shell.execute_reply.started":"2023-08-11T19:02:46.600916Z","shell.execute_reply":"2023-08-11T19:02:46.706851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Separate features and labels  ","metadata":{"papermill":{"duration":0.013792,"end_time":"2023-06-05T20:36:38.329368","exception":false,"start_time":"2023-06-05T20:36:38.315576","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_features = traindf[\"reviewText\"]\ntrain_labels = traindf.iloc[:, -1]\ntrain_features.shape, train_labels.shape","metadata":{"papermill":{"duration":0.024205,"end_time":"2023-06-05T20:36:38.367032","exception":false,"start_time":"2023-06-05T20:36:38.342827","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:02:46.709842Z","iopub.execute_input":"2023-08-11T19:02:46.710334Z","iopub.status.idle":"2023-08-11T19:02:46.720509Z","shell.execute_reply.started":"2023-08-11T19:02:46.710294Z","shell.execute_reply":"2023-08-11T19:02:46.719389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split traindf into training and testing parts  ","metadata":{"papermill":{"duration":0.013734,"end_time":"2023-06-05T20:36:38.394823","exception":false,"start_time":"2023-06-05T20:36:38.381089","status":"completed"},"tags":[]}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(train_features, train_labels, test_size=0.25, random_state=42)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","metadata":{"papermill":{"duration":0.055089,"end_time":"2023-06-05T20:36:38.463565","exception":false,"start_time":"2023-06-05T20:36:38.408476","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:02:46.722348Z","iopub.execute_input":"2023-08-11T19:02:46.722843Z","iopub.status.idle":"2023-08-11T19:02:46.767863Z","shell.execute_reply.started":"2023-08-11T19:02:46.722805Z","shell.execute_reply":"2023-08-11T19:02:46.766702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model evaluation plan and code  ","metadata":{"papermill":{"duration":0.013427,"end_time":"2023-06-05T20:36:38.519250","exception":false,"start_time":"2023-06-05T20:36:38.505823","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n# from sklearn.metrics import f1_score","metadata":{"papermill":{"duration":0.021543,"end_time":"2023-06-05T20:36:38.554503","exception":false,"start_time":"2023-06-05T20:36:38.532960","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:02:46.769326Z","iopub.execute_input":"2023-08-11T19:02:46.770522Z","iopub.status.idle":"2023-08-11T19:02:46.775158Z","shell.execute_reply.started":"2023-08-11T19:02:46.770488Z","shell.execute_reply":"2023-08-11T19:02:46.773831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def evaluate(y_test, y_pred):\n#     print(classification_report(y_test, y_pred))\n#     print(confusion_matrix(y_test, y_pred))\n#     # print(f1_score(y_test, y_pred))\n#     ConfusionMatrixDisplay(y_test, y_pred)\n#     return","metadata":{"papermill":{"duration":0.021888,"end_time":"2023-06-05T20:36:38.589756","exception":false,"start_time":"2023-06-05T20:36:38.567868","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:02:46.776390Z","iopub.execute_input":"2023-08-11T19:02:46.776710Z","iopub.status.idle":"2023-08-11T19:02:46.789688Z","shell.execute_reply.started":"2023-08-11T19:02:46.776681Z","shell.execute_reply":"2023-08-11T19:02:46.788668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data preprocessing  ","metadata":{"papermill":{"duration":0.012807,"end_time":"2023-06-05T20:36:38.616748","exception":false,"start_time":"2023-06-05T20:36:38.603941","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"`Define stop words`  ","metadata":{"papermill":{"duration":0.012719,"end_time":"2023-06-05T20:36:38.642458","exception":false,"start_time":"2023-06-05T20:36:38.629739","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# stop_words = [\"able\", \"about\", \"above\", \"abst\", \"ac\"]     # Deprecated  \n# type(stop_words), len(stop_words)","metadata":{"papermill":{"duration":0.058831,"end_time":"2023-06-05T20:36:38.762925","exception":false,"start_time":"2023-06-05T20:36:38.704094","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:02:46.791155Z","iopub.execute_input":"2023-08-11T19:02:46.791518Z","iopub.status.idle":"2023-08-11T19:02:46.804141Z","shell.execute_reply.started":"2023-08-11T19:02:46.791488Z","shell.execute_reply":"2023-08-11T19:02:46.802991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature extraction  ","metadata":{"papermill":{"duration":0.012936,"end_time":"2023-06-05T20:36:38.789627","exception":false,"start_time":"2023-06-05T20:36:38.776691","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Understand CountVectorizer and TfidfVectorizer  ","metadata":{"papermill":{"duration":0.012811,"end_time":"2023-06-05T20:36:38.815440","exception":false,"start_time":"2023-06-05T20:36:38.802629","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# text = X_train.copy()\n# text.head()","metadata":{"papermill":{"duration":0.018937,"end_time":"2023-06-05T20:36:38.847704","exception":false,"start_time":"2023-06-05T20:36:38.828767","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:02:46.805781Z","iopub.execute_input":"2023-08-11T19:02:46.807046Z","iopub.status.idle":"2023-08-11T19:02:46.817541Z","shell.execute_reply.started":"2023-08-11T19:02:46.806999Z","shell.execute_reply":"2023-08-11T19:02:46.816478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# vectorizer = TfidfVectorizer(stop_words=stop_words)\n# vectorized_text = vectorizer.fit_transform(text[\"reviewText\"])\n# vectorized_text","metadata":{"papermill":{"duration":0.021444,"end_time":"2023-06-05T20:36:38.882854","exception":false,"start_time":"2023-06-05T20:36:38.861410","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:02:46.819403Z","iopub.execute_input":"2023-08-11T19:02:46.820619Z","iopub.status.idle":"2023-08-11T19:02:46.832019Z","shell.execute_reply.started":"2023-08-11T19:02:46.820576Z","shell.execute_reply":"2023-08-11T19:02:46.830654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`Without stop words`  \n<122068x58624 sparse matrix of type '<class 'numpy.float64'>'\n\twith 2312222 stored elements in Compressed Sparse Row format>\n\n`With stop words`  \n<122068x57784 sparse matrix of type '<class 'numpy.float64'>'\n\twith 1188395 stored elements in Compressed Sparse Row format>   ","metadata":{"papermill":{"duration":0.013473,"end_time":"2023-06-05T20:36:38.911219","exception":false,"start_time":"2023-06-05T20:36:38.897746","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# vectorizer2 = CountVectorizer(stop_words=stop_words)\n# vectorized_text2 = vectorizer2.fit_transform(text[\"reviewText\"])\n# vectorized_text2","metadata":{"papermill":{"duration":0.020642,"end_time":"2023-06-05T20:36:38.945415","exception":false,"start_time":"2023-06-05T20:36:38.924773","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:02:46.833546Z","iopub.execute_input":"2023-08-11T19:02:46.833964Z","iopub.status.idle":"2023-08-11T19:02:46.844596Z","shell.execute_reply.started":"2023-08-11T19:02:46.833919Z","shell.execute_reply":"2023-08-11T19:02:46.843584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`Without stop words`  \n<122068x58624 sparse matrix of type '<class 'numpy.int64'>'\n\twith 2312222 stored elements in Compressed Sparse Row format>\n\n`With stop words`  \n<122068x57784 sparse matrix of type '<class 'numpy.int64'>'\n\twith 1188395 stored elements in Compressed Sparse Row format>","metadata":{"papermill":{"duration":0.01386,"end_time":"2023-06-05T20:36:38.973552","exception":false,"start_time":"2023-06-05T20:36:38.959692","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Conclusion   \n`TfidfVectorizer is equivalent to CountVectorizer followed by TfidfTransformer.`  \n\nhttps://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html","metadata":{"papermill":{"duration":0.013362,"end_time":"2023-06-05T20:36:39.000890","exception":false,"start_time":"2023-06-05T20:36:38.987528","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Model building workflow  \n\n`Make pipeline for preprocesing and model training and predictions`  \n","metadata":{"papermill":{"duration":0.014555,"end_time":"2023-06-05T20:36:39.030033","exception":false,"start_time":"2023-06-05T20:36:39.015478","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# def preprocess_n_train(X_train, y_train, preprocessor, model):\n#     pipe = Pipeline(steps=[\n#                             (\"preprocessor\", preprocessor),\n#                             (\"model\", model)\n#                         ])\n    \n#     pipe.fit(X_train, y_train)\n\n#     print(\"Given model has been trained. Use predict method to get predictions array.\")\n#     return pipe\n\n\n# def predict_n_evaluate(pipeline, X_test, y_test):\n#     y_pred = pipeline.predict(X_test)\n#     print(f\"y_pred shape: {y_pred.shape}\")\n#     print(f\"Summary of predictions: {np.unique(y_pred, return_counts=True)}\")\n#     print(classification_report(y_test, y_pred))\n#     print(confusion_matrix(y_test, y_pred))\n#     return y_pred","metadata":{"papermill":{"duration":0.023659,"end_time":"2023-06-05T20:36:39.111109","exception":false,"start_time":"2023-06-05T20:36:39.087450","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:02:46.846041Z","iopub.execute_input":"2023-08-11T19:02:46.846392Z","iopub.status.idle":"2023-08-11T19:02:46.860151Z","shell.execute_reply.started":"2023-08-11T19:02:46.846363Z","shell.execute_reply":"2023-08-11T19:02:46.858883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building 3 basic models  ","metadata":{}},{"cell_type":"markdown","source":"### Text preprocessors  ","metadata":{}},{"cell_type":"code","source":"# tvec = TfidfVectorizer()\n# cvec = CountVectorizer()        # Note that TfidfVectorizer and CountVectorizer+TfidsTransformer do the same function\n# tvec, cvec","metadata":{"papermill":{"duration":0.023539,"end_time":"2023-06-05T20:36:39.405297","exception":false,"start_time":"2023-06-05T20:36:39.381758","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:02:46.861845Z","iopub.execute_input":"2023-08-11T19:02:46.862751Z","iopub.status.idle":"2023-08-11T19:02:46.877514Z","shell.execute_reply.started":"2023-08-11T19:02:46.862704Z","shell.execute_reply":"2023-08-11T19:02:46.876352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Logistic Regression with TfidVectorizer for preprocessing  ","metadata":{"papermill":{"duration":0.013152,"end_time":"2023-06-05T20:36:39.199712","exception":false,"start_time":"2023-06-05T20:36:39.186560","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# logreg = LogisticRegression(max_iter=1000)\n# logreg_pipe = preprocess_n_train(X_train, y_train, tvec, logreg)\n# y_pred_logreg = predict_n_evaluate(logreg_pipe, X_test, y_test)\n# y_pred_logreg","metadata":{"papermill":{"duration":0.030205,"end_time":"2023-06-05T20:36:39.367462","exception":false,"start_time":"2023-06-05T20:36:39.337257","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:02:46.878838Z","iopub.execute_input":"2023-08-11T19:02:46.879888Z","iopub.status.idle":"2023-08-11T19:02:46.892202Z","shell.execute_reply.started":"2023-08-11T19:02:46.879845Z","shell.execute_reply":"2023-08-11T19:02:46.890670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### SVM model  ","metadata":{"papermill":{"duration":0.015482,"end_time":"2023-06-05T20:37:00.621842","exception":false,"start_time":"2023-06-05T20:37:00.606360","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# svm = LinearSVC()\n# svm_pipe = preprocess_n_train(X_train, y_train, tvec, svm)\n# y_pred_svm = predict_n_evaluate(svm_pipe, X_test, y_test)\n# y_pred_svm","metadata":{"papermill":{"duration":0.022841,"end_time":"2023-06-05T20:37:00.698933","exception":false,"start_time":"2023-06-05T20:37:00.676092","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:02:46.893752Z","iopub.execute_input":"2023-08-11T19:02:46.894787Z","iopub.status.idle":"2023-08-11T19:02:46.909578Z","shell.execute_reply.started":"2023-08-11T19:02:46.894750Z","shell.execute_reply":"2023-08-11T19:02:46.908106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Naive Bayes model  ","metadata":{"papermill":{"duration":0.015021,"end_time":"2023-06-05T20:37:00.912962","exception":false,"start_time":"2023-06-05T20:37:00.897941","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"#### MultinomialNB  ","metadata":{"papermill":{"duration":0.014057,"end_time":"2023-06-05T20:37:00.941471","exception":false,"start_time":"2023-06-05T20:37:00.927414","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# mnb = MultinomialNB()\n# mnb_pipe = preprocess_n_train(X_train, y_train, tvec, mnb)\n# y_pred_mnb = predict_n_evaluate(mnb_pipe, X_test, y_test)\n# y_pred_mnb","metadata":{"papermill":{"duration":0.02211,"end_time":"2023-06-05T20:37:01.024253","exception":false,"start_time":"2023-06-05T20:37:01.002143","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:02:46.911227Z","iopub.execute_input":"2023-08-11T19:02:46.911582Z","iopub.status.idle":"2023-08-11T19:02:46.925094Z","shell.execute_reply.started":"2023-08-11T19:02:46.911544Z","shell.execute_reply":"2023-08-11T19:02:46.923753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submitting predictions to Kaggle competition  ","metadata":{"papermill":{"duration":0.014078,"end_time":"2023-06-05T20:37:01.256040","exception":false,"start_time":"2023-06-05T20:37:01.241962","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# def submit(selected_model=logreg, selected_preprocessor=tvec):\n    \n#     # Retrain on the whole train.csv file  \n#     traindf = pd.read_csv(\"/kaggle/input/sentiment-prediction-on-movie-reviews/train.csv\")\n#     X_train = traindf[\"reviewText\"]\n#     X_train.fillna(\"empty\", inplace=True)\n#     y_train = traindf[\"sentiment\"]\n#     pipe = preprocess_n_train(X_train, y_train, selected_preprocessor, selected_model)\n    \n#     # Predict on test.csv file\n#     testdf = pd.read_csv(\"/kaggle/input/sentiment-prediction-on-movie-reviews/test.csv\")\n#     X_test = testdf[\"reviewText\"]\n#     X_test.fillna(\"empty\", inplace=True)\n    \n#     y_pred = pipe.predict(X_test)\n    \n#     pred_df = pd.DataFrame(y_pred)\n#     pred_df.columns = [\"sentiment\"]\n#     pred_df.index.name = \"id\"\n#     pred_df.to_csv(\"submission.csv\")\n    \n#     return \"Successfully created the submission file!!!\"","metadata":{"papermill":{"duration":0.026207,"end_time":"2023-06-05T20:37:01.296720","exception":false,"start_time":"2023-06-05T20:37:01.270513","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:02:46.926621Z","iopub.execute_input":"2023-08-11T19:02:46.927302Z","iopub.status.idle":"2023-08-11T19:02:46.941541Z","shell.execute_reply.started":"2023-08-11T19:02:46.927263Z","shell.execute_reply":"2023-08-11T19:02:46.940403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit(logreg_cv1, tvec_cv1)","metadata":{"papermill":{"duration":32.987121,"end_time":"2023-06-05T20:37:34.299133","exception":false,"start_time":"2023-06-05T20:37:01.312012","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:02:46.942772Z","iopub.execute_input":"2023-08-11T19:02:46.943173Z","iopub.status.idle":"2023-08-11T19:02:46.959754Z","shell.execute_reply.started":"2023-08-11T19:02:46.943141Z","shell.execute_reply":"2023-08-11T19:02:46.958853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PART II  ","metadata":{}},{"cell_type":"markdown","source":"## Merge \"movies.csv\" with \"train.csv\" and \"test.csv\"  ","metadata":{}},{"cell_type":"markdown","source":"### Helper functions  ","metadata":{}},{"cell_type":"code","source":"# Helper function for loading files  \n\ndef load_csv(filename: str):\n    if platform == \"vscode\":\n        df = pd.read_csv(f\"data/{filename}.csv\")\n    else:\n        df = pd.read_csv(f\"/kaggle/input/sentiment-prediction-on-movie-reviews/{filename}.csv\")\n        \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:02:46.961271Z","iopub.execute_input":"2023-08-11T19:02:46.962094Z","iopub.status.idle":"2023-08-11T19:02:46.975350Z","shell.execute_reply.started":"2023-08-11T19:02:46.962062Z","shell.execute_reply":"2023-08-11T19:02:46.974147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inspect(df: pd.DataFrame):\n    print(f\"Shape of the dataframe: {df.shape}\")\n    print()\n    print(f\"Columns in the dataframe:\\n{df.columns}\")\n    print()\n    print(f\"{df.info()}\")\n    print()\n    # print(f\"Summary: {df.describe()}\")\n    print(f\"Missing values:\\n{df.isna().sum()}\")\n    return","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:02:46.977303Z","iopub.execute_input":"2023-08-11T19:02:46.978069Z","iopub.status.idle":"2023-08-11T19:02:46.988264Z","shell.execute_reply.started":"2023-08-11T19:02:46.978028Z","shell.execute_reply":"2023-08-11T19:02:46.987256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def name_fl(name):\n    l = name.split()\n    n = ' '.join((l[0], l[-1]))\n    return n","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:02:47.000187Z","iopub.execute_input":"2023-08-11T19:02:47.000883Z","iopub.status.idle":"2023-08-11T19:02:47.007151Z","shell.execute_reply.started":"2023-08-11T19:02:47.000838Z","shell.execute_reply":"2023-08-11T19:02:47.006224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def select_features(df: pd.DataFrame, moviesdf: pd.DataFrame, row_thresh_null=None):\n    '''\n    This function merges the given dataframes. Note that the first df must be \"train\" or \"test\" and\n    the second df should be \"movies\".\n    Note: Sentiment column is present only in \"train.csv\" file and not \"test.csv\" file.\n    '''\n    \n    # Drop duplicates from moviesdf\n#     movies_unique = moviesdf.drop_duplicates(subset=[\"movieid\"])\n\n    # Drop duplicates using groupby - clubs similar rows and fills in missing values better\n    movies_unique = moviesdf.fillna(value=np.nan).groupby(\"movieid\").first().reset_index()\n    \n\n    # Handle missing values in movies.csv better than just dropping duplicates?\n#     movies_unique = moviesdf.copy()\n#     movies_unique[[\"audienceScore\", \"runtimeMinutes\"]] = movies_unique[[\"audienceScore\", \"runtimeMinutes\"]].interpolate(method='linear', axis=0)\n#     movies_unique = movies_unique.fillna(value=np.nan).groupby(\"movieid\").first().fillna(method='ffill').reset_index()\n\n    \n\n    # Merge df and movies_unique\n    df_merged = pd.merge(df, movies_unique, on=\"movieid\", how='left')\n    \n    # Rename \"isTopCritic\" column, if it exists, to \"isFrequentReviewer\"\n    df_merged.rename(columns={\"isTopCritic\": \"isFrequentReviewer\"}, inplace=True)\n    \n    # Drop columns\n#     df_merged = df_merged.drop(columns=[\"title\", \"ratingContents\", \"releaseDateTheaters\", \"releaseDateStreaming\", \"distributor\", \"soundType\"])\n#     df_merged = df_merged.drop(columns=[\"title\", \"soundType\"])\n    \n    # Drop rows (OPTIONAL: Uses kwarg row_thresh_null)\n    if row_thresh_null != None:\n        df_merged.dropna(axis=0, thresh=(df_merged.shape[1] - row_thresh_null), inplace=True)\n        \n\n    # Create new columns based on reviewText\n    final = df_merged.copy()\n    final[\"reviewYN\"] = np.where(final[\"reviewText\"].isnull(), 1, 0)    # Feature engineering - adding a new column\n    final[\"reviewWC\"] = final.apply(lambda x: len(str(x[\"reviewText\"]).split()), axis=1)    # Feature engineering - adding second new column\n    \n    # Clean text (replace numbers with empty string) and fill missing values in \"reviewText\" with empty string\n    final[\"reviewText\"] = final[\"reviewText\"].str.replace('\\d+', '', regex=True)\n    final[\"reviewText\"] = final[\"reviewText\"].fillna(\"neutral\")\n    \n    # Fill missing values in \"rating\", \"genre\", original columns with the word \"unknown\"\n    final[\"rating\"] = final[\"rating\"].fillna(\"unknown\")\n    final[\"originalLanguage\"] = final[\"originalLanguage\"].fillna(\"unknown\")\n    final[\"genre\"] = final[\"genre\"].fillna(\"unknown\")\n    final[\"genre\"] = final[\"genre\"].apply(lambda x: re.sub(r\"-\", \"\", x))\n    final[\"genreSorted\"] = final[\"genre\"].apply(lambda x: (\",\").join(sorted(x.split(\", \"))))\n#     final[\"genre\"] = final[\"genre\"].replace(to_replace={\"&\": \"\"})\n\n    # Impute missing values for \"audienceScore\" and \"runtimeMinutes\" columns\n#     final[\"audienceScore\"] = final[\"audienceScore\"].fillna(final[\"audienceScore\"].mean())        # MOVED\n#     final[\"runtimeMinutes\"] = final[\"runtimeMinutes\"].fillna(final[\"runtimeMinutes\"].median())   # MOVED\n    \n    # Preprocess and impute missing values in \"boxOffice\" column\n    final[\"boxOffice\"] = final[\"boxOffice\"].str[1:]\n    final[\"boxOffice\"] = final[\"boxOffice\"].replace(to_replace={\"M\": \"*1000000\", \"K\": \"*1000\"}, regex=True)\n    final[\"boxOffice\"] = final[\"boxOffice\"].loc[final[\"boxOffice\"].notnull()].apply(lambda x: eval(str(x)))\n#     final[\"boxOffice\"] = final[\"boxOffice\"].fillna(final[\"boxOffice\"].median())                  # MOVED\n    # (Optional) Replace outliers in boxOffice with median\n#     median = final[\"boxOffice\"].describe()['50%']\n#     iqr = final[\"boxOffice\"].describe()['75%'] - final[\"boxOffice\"].describe()['25%']\n#     ll = median - (1.5*iqr)\n#     ul = median + (1.5*iqr)\n#     final.loc[final[\"boxOffice\"] > ul, \"boxOffice\"] = median\n    \n    # Clean language names\n    final[\"originalLanguage\"].replace({\"English (United Kingdom)\": \"English\", \n                                            \"English (Australia)\" : \"English\",\n                                            \"French (France)\": \"French\", \n                                            \"French (Canada)\": \"French\",\n                                            \"Portuguese (Brazil)\": \"Portuguese\",\n                                            \"Spanish (Spain)\": \"Spanish\"},                                         \n                                            inplace=True)\n    \n    # Clean reviewerName column\n    pre_post_fixes = {\"Mr. \": \"\", \"Mrs. \": \"\", \"Ms. \": \"\", \"Dr. \": \"\", \n                      \" MD\": \"\", \" DDS\": \"\", \" DVM\": \"\", \" Jr.\": \"\", \" PhD\": \"\", \" II\": \"\", \" IV\": \"\"}\n    final[\"reviewerName\"] = final[\"reviewerName\"].replace(pre_post_fixes, regex=True)\n    final[\"reviewerName\"] = final[\"reviewerName\"].apply(name_fl)\n    \n    # Handle 'ratingContents' column\n    final[\"ratingContents\"] = final[\"ratingContents\"].fillna(\"neutral\")\n    final[\"rcSorted\"] = final[\"ratingContents\"].apply(lambda x: (\",\").join(sorted(x.strip(\"][\").split(\", \"))))\n    final[\"rcSorted\"] = final[\"rcSorted\"].apply(lambda x: re.sub(r\"'\", \"\", x))\n    final[\"rcSorted\"] = final[\"rcSorted\"].apply(lambda x: re.sub(r\"[/\\s]\", \"_\", x))  \n    \n    # Handle 'ratingContents' column\n    final[\"distributor\"] = final[\"distributor\"].fillna(\"unknown\")\n    \n    # Work with 'releaseDateTheaters', releaseDateStreaming column\n    final[[\"releaseDateTheaters\", \"releaseDateStreaming\"]] = final[[\"releaseDateTheaters\", \"releaseDateStreaming\"]].astype('datetime64[ns]')\n\n    final[\"releaseDate\"] = final[[\"releaseDateTheaters\", \"releaseDateStreaming\"]].min(axis=1, skipna=False)\n#     final[\"releaseDate\"] = final[\"releaseDate\"].fillna(final[\"releaseDate\"].median())               # MOVED\n\n    final[\"releaseYear\"] = final[\"releaseDate\"].dt.year\n    final[\"releaseMonth\"] = final[\"releaseDate\"].dt.month\n    \n    # Compute \"releaseDiff\" column and fill missing values in \"releaseDiff\" and (optional) replace outliers\n    final[\"releaseDiff\"] = (final[\"releaseDateStreaming\"] - final[\"releaseDateTheaters\"]) / np.timedelta64(1, 'D')\n    final[\"releaseDiff\"] = final[\"releaseDiff\"].apply(lambda x: abs(x))\n    final[\"releaseDiff\"] = final[\"releaseDiff\"].fillna(value=0)\n#     final[\"releaseDiff\"] = final[\"releaseDiff\"].fillna(final[\"releaseDiff\"].median())\n    # median = final[\"releaseDiff\"].describe()['50%']\n    # iqr = final[\"releaseDiff\"].describe()['75%'] - final[\"releaseDiff\"].describe()['25%']\n    # ll = median - (1.5*iqr)\n    # ul = median + (1.5*iqr)\n    # final.loc[final[\"releaseDiff\"] > ul, \"releaseDiff\"] = median\n    # final.loc[final[\"releaseDiff\"] < ll, \"releaseDiff\"] = median\n    \n#     # Create new feature columns\n    \n#     # Convert audienceScore to categories  \n#     num_bins_as = 20\n#     final[\"audScoreBins\"] = pd.cut(final['audienceScore'], bins=num_bins_as, labels=False)\n    \n#     # Convert runtimeMinutes to categories  \n# #     num_bins_rt = 20\n#     final[\"runtimeBins\"] = pd.cut(final['runtimeMinutes'], bins=[0,75,120,180,565], labels=[4,3,2,1])\n    \n#     # Convert boxOffice to categories  \n#     num_bins_bo = 5\n#     final[\"boxOfficeBins\"] = pd.cut(final['boxOffice'], bins=num_bins_bo, labels=False)\n    \n#     # Convert releaseDiff to categories  \n#     num_bins_rd = 5\n#     final[\"releaseDiffBins\"] = pd.cut(final['releaseDiff'], bins=[-1, 180, 360, 1000, 40000], labels=[0, 1, 2, 3])\n\n    return final","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:02:47.009468Z","iopub.execute_input":"2023-08-11T19:02:47.010079Z","iopub.status.idle":"2023-08-11T19:02:47.041404Z","shell.execute_reply.started":"2023-08-11T19:02:47.010045Z","shell.execute_reply":"2023-08-11T19:02:47.040199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_train_predict(features, labels, pipeline, test_size=0.25, random_state=42):\n    # cols = features.columns\n    if len(features.shape) == 1:\n        features = features.to_numpy().reshape(-1, 1)  # reshape to 2D array\n    features = pd.DataFrame(features)\n    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=test_size, random_state=random_state)\n    pipeline.fit(X_train, y_train)\n    y_pred = pipeline.predict(X_test)\n    print(classification_report(y_test, y_pred))\n    print(confusion_matrix(y_test, y_pred))\n    return pipeline","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:02:47.043002Z","iopub.execute_input":"2023-08-11T19:02:47.043361Z","iopub.status.idle":"2023-08-11T19:02:47.060209Z","shell.execute_reply.started":"2023-08-11T19:02:47.043321Z","shell.execute_reply":"2023-08-11T19:02:47.058986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Merge \"train.csv\" file with \"movies.csv\" file  ","metadata":{}},{"cell_type":"code","source":"merged = select_features(load_csv(\"train\"), load_csv(\"movies\"), row_thresh_null=None)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:02:47.061989Z","iopub.execute_input":"2023-08-11T19:02:47.062505Z","iopub.status.idle":"2023-08-11T19:03:02.109852Z","shell.execute_reply.started":"2023-08-11T19:02:47.062466Z","shell.execute_reply":"2023-08-11T19:03:02.108776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# inspect(merged)    # Note missing values in ['audienceScore', 'runtimeMinutes', 'boxOffice'] columns  ","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:02.111208Z","iopub.execute_input":"2023-08-11T19:03:02.111747Z","iopub.status.idle":"2023-08-11T19:03:02.116170Z","shell.execute_reply.started":"2023-08-11T19:03:02.111716Z","shell.execute_reply":"2023-08-11T19:03:02.114986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Simple Imputer for ['audienceScore', 'runtimeMinutes', 'boxOffice'] columns\nsi = SimpleImputer(strategy='median')\nmerged[['audienceScore', 'runtimeMinutes', 'boxOffice']] = si.fit_transform(merged[['audienceScore', 'runtimeMinutes', 'boxOffice']])\nsi.statistics_","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:02.117533Z","iopub.execute_input":"2023-08-11T19:03:02.118184Z","iopub.status.idle":"2023-08-11T19:03:02.229021Z","shell.execute_reply.started":"2023-08-11T19:03:02.118148Z","shell.execute_reply":"2023-08-11T19:03:02.227798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill 'releaseDate' column with median  \nmerged['releaseDate'] = merged[\"releaseDate\"].fillna(merged[\"releaseDate\"].median())","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:02.230748Z","iopub.execute_input":"2023-08-11T19:03:02.231128Z","iopub.status.idle":"2023-08-11T19:03:02.247295Z","shell.execute_reply.started":"2023-08-11T19:03:02.231095Z","shell.execute_reply":"2023-08-11T19:03:02.245935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check out 'merged' df after imputation  \ninspect(merged)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:02.249209Z","iopub.execute_input":"2023-08-11T19:03:02.249592Z","iopub.status.idle":"2023-08-11T19:03:03.774027Z","shell.execute_reply.started":"2023-08-11T19:03:02.249558Z","shell.execute_reply":"2023-08-11T19:03:03.773088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged[['audienceScore', 'runtimeMinutes', 'boxOffice']].describe()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:03.775019Z","iopub.execute_input":"2023-08-11T19:03:03.775343Z","iopub.status.idle":"2023-08-11T19:03:03.834985Z","shell.execute_reply.started":"2023-08-11T19:03:03.775316Z","shell.execute_reply":"2023-08-11T19:03:03.833592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### EDA releaseDiff  ","metadata":{}},{"cell_type":"code","source":"# abs values\nmerged[\"releaseDiff\"].describe()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:03.836698Z","iopub.execute_input":"2023-08-11T19:03:03.837165Z","iopub.status.idle":"2023-08-11T19:03:03.860256Z","shell.execute_reply.started":"2023-08-11T19:03:03.837125Z","shell.execute_reply":"2023-08-11T19:03:03.858833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merged['releaseDiffBins'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:03.861819Z","iopub.execute_input":"2023-08-11T19:03:03.862740Z","iopub.status.idle":"2023-08-11T19:03:03.873785Z","shell.execute_reply.started":"2023-08-11T19:03:03.862707Z","shell.execute_reply":"2023-08-11T19:03:03.872445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(x=merged['sentiment'], y=merged['releaseDiff'], showfliers=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:03.875422Z","iopub.execute_input":"2023-08-11T19:03:03.875756Z","iopub.status.idle":"2023-08-11T19:03:04.280154Z","shell.execute_reply.started":"2023-08-11T19:03:03.875729Z","shell.execute_reply":"2023-08-11T19:03:04.278636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sns.displot(merged['releaseDiffBins'])","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:04.282210Z","iopub.execute_input":"2023-08-11T19:03:04.282670Z","iopub.status.idle":"2023-08-11T19:03:05.022038Z","shell.execute_reply.started":"2023-08-11T19:03:04.282629Z","shell.execute_reply":"2023-08-11T19:03:05.020274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merged['sentiment'].loc[merged['releaseDiffBins'] > 0].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:05.024713Z","iopub.execute_input":"2023-08-11T19:03:05.026061Z","iopub.status.idle":"2023-08-11T19:03:05.049569Z","shell.execute_reply.started":"2023-08-11T19:03:05.026007Z","shell.execute_reply":"2023-08-11T19:03:05.048248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merged['releaseDiffBins'].describe()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:05.051006Z","iopub.execute_input":"2023-08-11T19:03:05.051661Z","iopub.status.idle":"2023-08-11T19:03:05.062924Z","shell.execute_reply.started":"2023-08-11T19:03:05.051617Z","shell.execute_reply":"2023-08-11T19:03:05.061710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### EDA 'distributor'  ","metadata":{}},{"cell_type":"code","source":"merged[\"distributor\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:05.064584Z","iopub.execute_input":"2023-08-11T19:03:05.064947Z","iopub.status.idle":"2023-08-11T19:03:05.102826Z","shell.execute_reply.started":"2023-08-11T19:03:05.064885Z","shell.execute_reply":"2023-08-11T19:03:05.101644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged[\"runtimeMinutes\"].describe()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:05.104703Z","iopub.execute_input":"2023-08-11T19:03:05.105070Z","iopub.status.idle":"2023-08-11T19:03:05.124725Z","shell.execute_reply.started":"2023-08-11T19:03:05.105040Z","shell.execute_reply":"2023-08-11T19:03:05.123883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(y=merged[\"runtimeMinutes\"], x=merged[\"sentiment\"])","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:05.126020Z","iopub.execute_input":"2023-08-11T19:03:05.126533Z","iopub.status.idle":"2023-08-11T19:03:05.551215Z","shell.execute_reply.started":"2023-08-11T19:03:05.126504Z","shell.execute_reply":"2023-08-11T19:03:05.549992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(merged[\"boxOfficeBins\"].value_counts())\n# sns.displot(merged[\"boxOfficeBins\"])","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:05.552981Z","iopub.execute_input":"2023-08-11T19:03:05.553519Z","iopub.status.idle":"2023-08-11T19:03:06.272569Z","shell.execute_reply.started":"2023-08-11T19:03:05.553472Z","shell.execute_reply":"2023-08-11T19:03:06.271323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged[\"reviewText\"].head()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:06.274111Z","iopub.execute_input":"2023-08-11T19:03:06.274437Z","iopub.status.idle":"2023-08-11T19:03:06.283093Z","shell.execute_reply.started":"2023-08-11T19:03:06.274408Z","shell.execute_reply":"2023-08-11T19:03:06.281946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged[\"reviewYN\"].sum()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:06.284859Z","iopub.execute_input":"2023-08-11T19:03:06.285218Z","iopub.status.idle":"2023-08-11T19:03:06.301905Z","shell.execute_reply.started":"2023-08-11T19:03:06.285189Z","shell.execute_reply":"2023-08-11T19:03:06.300203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged[\"reviewWC\"].head()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:06.303882Z","iopub.execute_input":"2023-08-11T19:03:06.304275Z","iopub.status.idle":"2023-08-11T19:03:06.321792Z","shell.execute_reply.started":"2023-08-11T19:03:06.304244Z","shell.execute_reply":"2023-08-11T19:03:06.320553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged[\"reviewWC\"].describe()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:06.323803Z","iopub.execute_input":"2023-08-11T19:03:06.324304Z","iopub.status.idle":"2023-08-11T19:03:06.349877Z","shell.execute_reply.started":"2023-08-11T19:03:06.324262Z","shell.execute_reply":"2023-08-11T19:03:06.348695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(merged[\"reviewWC\"])","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:06.351697Z","iopub.execute_input":"2023-08-11T19:03:06.352760Z","iopub.status.idle":"2023-08-11T19:03:07.217252Z","shell.execute_reply.started":"2023-08-11T19:03:06.352716Z","shell.execute_reply":"2023-08-11T19:03:07.215984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged['rating'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:07.218778Z","iopub.execute_input":"2023-08-11T19:03:07.219122Z","iopub.status.idle":"2023-08-11T19:03:07.253701Z","shell.execute_reply.started":"2023-08-11T19:03:07.219093Z","shell.execute_reply":"2023-08-11T19:03:07.252252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged['isFrequentReviewer'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:07.255728Z","iopub.execute_input":"2023-08-11T19:03:07.256163Z","iopub.status.idle":"2023-08-11T19:03:07.274510Z","shell.execute_reply.started":"2023-08-11T19:03:07.256121Z","shell.execute_reply":"2023-08-11T19:03:07.273269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged[\"reviewerName\"].head()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:07.276369Z","iopub.execute_input":"2023-08-11T19:03:07.276834Z","iopub.status.idle":"2023-08-11T19:03:07.294431Z","shell.execute_reply.started":"2023-08-11T19:03:07.276794Z","shell.execute_reply":"2023-08-11T19:03:07.293093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged['boxOffice'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:07.296222Z","iopub.execute_input":"2023-08-11T19:03:07.296676Z","iopub.status.idle":"2023-08-11T19:03:07.319459Z","shell.execute_reply.started":"2023-08-11T19:03:07.296633Z","shell.execute_reply":"2023-08-11T19:03:07.318469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check correlation between 'boxOffice' and ''sentiment'\n# bo_df = merged.copy()\n# print(bo_df[\"boxOffice\"])\n# bo_df[\"boxOffice\"] = bo_df[\"boxOffice\"].str[1:]\n# bo_df[\"boxOffice\"] = bo_df[\"boxOffice\"].replace(to_replace={\"M\": \"*1000000\", \"K\": \"*1000\"}, regex=True)\n# bo_df[\"boxOffice\"] = bo_df[\"boxOffice\"].loc[bo_df[\"boxOffice\"].notnull()].apply(lambda x: eval(str(x)))\n# bo_df[\"boxOffice\"] = bo_df[\"boxOffice\"].fillna(bo_df[\"boxOffice\"].median())\n# bo_df[\"boxOffice\"].describe()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:07.321073Z","iopub.execute_input":"2023-08-11T19:03:07.321399Z","iopub.status.idle":"2023-08-11T19:03:07.328778Z","shell.execute_reply.started":"2023-08-11T19:03:07.321370Z","shell.execute_reply":"2023-08-11T19:03:07.327494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# median = bo_df[\"boxOffice\"].describe()['50%']\n# iqr = bo_df[\"boxOffice\"].describe()['75%'] - bo_df[\"boxOffice\"].describe()['25%']\n# median, iqr","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:07.330853Z","iopub.execute_input":"2023-08-11T19:03:07.331214Z","iopub.status.idle":"2023-08-11T19:03:07.342851Z","shell.execute_reply.started":"2023-08-11T19:03:07.331185Z","shell.execute_reply":"2023-08-11T19:03:07.341936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ll = median - (1.5*iqr)\n# ul = median + (1.5*iqr)\n# ll, ul","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:07.344520Z","iopub.execute_input":"2023-08-11T19:03:07.345265Z","iopub.status.idle":"2023-08-11T19:03:07.363579Z","shell.execute_reply.started":"2023-08-11T19:03:07.345231Z","shell.execute_reply":"2023-08-11T19:03:07.362406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# bo_df[\"boxOffice\"].mean()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:07.364718Z","iopub.execute_input":"2023-08-11T19:03:07.365097Z","iopub.status.idle":"2023-08-11T19:03:07.381306Z","shell.execute_reply.started":"2023-08-11T19:03:07.365065Z","shell.execute_reply":"2023-08-11T19:03:07.379677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# bo_df.loc[bo_df[\"boxOffice\"] > ul, \"boxOffice\"] = median\n# bo_df[\"boxOffice\"].mean()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:07.382822Z","iopub.execute_input":"2023-08-11T19:03:07.383877Z","iopub.status.idle":"2023-08-11T19:03:07.396428Z","shell.execute_reply.started":"2023-08-11T19:03:07.383831Z","shell.execute_reply":"2023-08-11T19:03:07.395169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# bo_df[\"boxOffice\"].min(), bo_df[\"boxOffice\"].max()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:07.398209Z","iopub.execute_input":"2023-08-11T19:03:07.398926Z","iopub.status.idle":"2023-08-11T19:03:07.412367Z","shell.execute_reply.started":"2023-08-11T19:03:07.398858Z","shell.execute_reply":"2023-08-11T19:03:07.410781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sns.boxplot(x=\"sentiment\", y=\"boxOffice\", data=bo_df, showfliers = False)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:07.414234Z","iopub.execute_input":"2023-08-11T19:03:07.414601Z","iopub.status.idle":"2023-08-11T19:03:07.427312Z","shell.execute_reply.started":"2023-08-11T19:03:07.414569Z","shell.execute_reply":"2023-08-11T19:03:07.425811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA  ","metadata":{}},{"cell_type":"markdown","source":"### An interesting finding through exploration  \n  \n* OHE and TfidfVectorizer on director column give the same result when ngram_range(2,2) is used (see code below)!","metadata":{}},{"cell_type":"code","source":"# Compare OHE and TfidfVectorizer on director column\n\ndirs = merged[\"director\"].copy()\nprint(dirs.shape)\ndirs_uniq = merged[\"director\"].unique()\nprint(len(dirs_uniq))\n\ndu_ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False).fit_transform(dirs.to_numpy().reshape(-1, 1))\nprint(du_ohe.shape, type(du_ohe))\n\ndirs_2 = merged[\"director\"].copy()\nprint(dirs_2.shape)\ndu_tfidf = TfidfVectorizer(ngram_range=(2,2)).fit_transform(dirs_2).toarray()\nprint(du_tfidf.shape, type(du_tfidf))\n\nprint(np.array_equal(du_ohe, du_tfidf))","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:07.428793Z","iopub.execute_input":"2023-08-11T19:03:07.429160Z","iopub.status.idle":"2023-08-11T19:03:21.119231Z","shell.execute_reply.started":"2023-08-11T19:03:07.429131Z","shell.execute_reply":"2023-08-11T19:03:21.118182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dirs.head())\nd = dirs.copy()\nd[\"name_len\"] = d.apply(lambda x: len(x.split()))\nd[\"name_len\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:21.120329Z","iopub.execute_input":"2023-08-11T19:03:21.120933Z","iopub.status.idle":"2023-08-11T19:03:21.483350Z","shell.execute_reply.started":"2023-08-11T19:03:21.120869Z","shell.execute_reply":"2023-08-11T19:03:21.482300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compare OHE and TfidfVectorizer on reviewerName column\n# Note: reviewerName column has salutations like \"Mr. \" etc, and some names appear middle names. Therefore needs cleaning\n\n# def name_fl(name):\n#     l = name.split()\n#     n = ' '.join((l[0], l[-1]))\n#     return n\n\n# reviewers = merged[\"reviewerName\"].copy()\n# reviewers = pd.DataFrame(reviewers)\n# reviewers = reviewers.replace({\"Mr. \": \"\", \"Mrs. \": \"\"}, regex=True)\n# reviewers[\"reviewerName\"] = reviewers[\"reviewerName\"].apply(name_fl)\n# print(reviewers.shape)\n\n# reviewers_uniq = merged[\"reviewerName\"].unique()\n# print(len(reviewers_uniq))\n\n# reviewers_ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False).fit_transform(reviewers.to_numpy().reshape(-1, 1))\n# print(reviewers_ohe.shape, type(reviewers_ohe))\n\n# reviewers_2 = merged[\"reviewerName\"].copy()\n# reviewers_2 = pd.DataFrame(reviewers_2)\n# print(reviewers_2.head())\n# reviewers_2 = reviewers_2.replace({\"Mr. \": \"\", \"Mrs. \": \"\"}, regex=True)\n# reviewers_2[\"reviewerName\"] = reviewers_2[\"reviewerName\"].apply(name_fl)\n# reviewers_2 = reviewers_2.squeeze()\n# print(reviewers_2.shape)\n# print(reviewers_2.head())\n\n# reviewers_tfidf = TfidfVectorizer(ngram_range=(2,2)).fit_transform(reviewers_2).toarray()\n# print(reviewers_tfidf.shape, type(reviewers_tfidf))\n\n# print(np.array_equal(reviewers_ohe, reviewers_tfidf))","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:21.484681Z","iopub.execute_input":"2023-08-11T19:03:21.485007Z","iopub.status.idle":"2023-08-11T19:03:21.492077Z","shell.execute_reply.started":"2023-08-11T19:03:21.484981Z","shell.execute_reply":"2023-08-11T19:03:21.490759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def name_fl(name):\n#     l = name.split()\n#     n = ' '.join((l[0], l[-1]))\n#     return n","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:21.493985Z","iopub.execute_input":"2023-08-11T19:03:21.494357Z","iopub.status.idle":"2023-08-11T19:03:21.509068Z","shell.execute_reply.started":"2023-08-11T19:03:21.494327Z","shell.execute_reply":"2023-08-11T19:03:21.508101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(reviewers.head())\n# r = pd.DataFrame(reviewers.copy())\n# r[\"reviewerName\"] = r[\"reviewerName\"].apply(name_fl)\n# r[\"name_len\"] = r[\"reviewerName\"].apply(lambda x: len(x.split()))\n# print(r.shape)\n# print(r.head())\n# print(r['name_len'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:21.510231Z","iopub.execute_input":"2023-08-11T19:03:21.510925Z","iopub.status.idle":"2023-08-11T19:03:21.523347Z","shell.execute_reply.started":"2023-08-11T19:03:21.510871Z","shell.execute_reply":"2023-08-11T19:03:21.522129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Box plot audienceScore and sentiment  \n# plt.figure(figsize=(6, 4))\n# sns.boxplot(x=\"sentiment\", y=\"audienceScore\", data=merged, width=0.3)\n# plt.title(\"Box plot audienceScore and sentiment\")\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:21.525148Z","iopub.execute_input":"2023-08-11T19:03:21.525497Z","iopub.status.idle":"2023-08-11T19:03:21.535090Z","shell.execute_reply.started":"2023-08-11T19:03:21.525466Z","shell.execute_reply":"2023-08-11T19:03:21.533850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Box plot runtimeMinutes and sentiment  \n# plt.figure(figsize=(6, 4))\n# sns.boxplot(x=\"sentiment\", y=\"runtimeMinutes\", data=merged, width=0.3)\n# plt.title(\"Box plot runtimeMinutes and sentiment\")\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:21.537062Z","iopub.execute_input":"2023-08-11T19:03:21.537528Z","iopub.status.idle":"2023-08-11T19:03:21.549588Z","shell.execute_reply.started":"2023-08-11T19:03:21.537485Z","shell.execute_reply":"2023-08-11T19:03:21.548496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Column chart for sentiment and rating columns\n# plt.figure(figsize=(6, 4))\n# sns.countplot(x=\"sentiment\", hue=\"rating\", data=merged)\n# plt.title(\"Column chart for sentiment and rating columns\")\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:21.550996Z","iopub.execute_input":"2023-08-11T19:03:21.551368Z","iopub.status.idle":"2023-08-11T19:03:21.568731Z","shell.execute_reply.started":"2023-08-11T19:03:21.551337Z","shell.execute_reply":"2023-08-11T19:03:21.567509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation heatmap  \n# plt.figure(figsize=(10, 8))\n# sns.heatmap(merged.corr(), annot=True, cmap=\"coolwarm\")\n# plt.title(\"Correlation heatmap\")\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:21.570591Z","iopub.execute_input":"2023-08-11T19:03:21.571056Z","iopub.status.idle":"2023-08-11T19:03:21.582330Z","shell.execute_reply.started":"2023-08-11T19:03:21.571009Z","shell.execute_reply":"2023-08-11T19:03:21.580967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Merge and preprocess \"test.csv\" and \"movies.csv\" files  ","metadata":{}},{"cell_type":"code","source":"# Merge test and movies  \nmerged_test = select_features(load_csv(\"test\"), load_csv(\"movies\"))","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:21.584078Z","iopub.execute_input":"2023-08-11T19:03:21.584601Z","iopub.status.idle":"2023-08-11T19:03:27.815297Z","shell.execute_reply.started":"2023-08-11T19:03:21.584562Z","shell.execute_reply":"2023-08-11T19:03:27.814162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# inspect(merged_test)      # Note the missing values in ['audienceScore', 'runtimeMinutes', 'boxOffice']","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:27.816871Z","iopub.execute_input":"2023-08-11T19:03:27.817270Z","iopub.status.idle":"2023-08-11T19:03:27.822141Z","shell.execute_reply.started":"2023-08-11T19:03:27.817237Z","shell.execute_reply":"2023-08-11T19:03:27.820546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transform ['audienceScore', 'runtimeMinutes', 'boxOffice'] columns in merged_test using 'si' fitted on 'merged' df  \nmerged_test[['audienceScore', 'runtimeMinutes', 'boxOffice']] = si.transform(merged_test[['audienceScore', 'runtimeMinutes', 'boxOffice']])\nsi.statistics_","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:27.823668Z","iopub.execute_input":"2023-08-11T19:03:27.824006Z","iopub.status.idle":"2023-08-11T19:03:27.851887Z","shell.execute_reply.started":"2023-08-11T19:03:27.823978Z","shell.execute_reply":"2023-08-11T19:03:27.850695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill 'releaseDate' column in 'merged_test' df with median from the train (merged) df  \nmerged_test['releaseDate'] = merged_test[\"releaseDate\"].fillna(merged[\"releaseDate\"].median())","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:27.853764Z","iopub.execute_input":"2023-08-11T19:03:27.854281Z","iopub.status.idle":"2023-08-11T19:03:27.866945Z","shell.execute_reply.started":"2023-08-11T19:03:27.854238Z","shell.execute_reply":"2023-08-11T19:03:27.865738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# After transforming merged_test  \ninspect(merged_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:27.868311Z","iopub.execute_input":"2023-08-11T19:03:27.868667Z","iopub.status.idle":"2023-08-11T19:03:28.367772Z","shell.execute_reply.started":"2023-08-11T19:03:27.868620Z","shell.execute_reply":"2023-08-11T19:03:28.366626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(merged_test[\"reviewYN\"].sum())\nprint(merged_test[\"reviewYN\"].sum() * 100 / merged_test.shape[0])","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:28.369183Z","iopub.execute_input":"2023-08-11T19:03:28.369546Z","iopub.status.idle":"2023-08-11T19:03:28.376504Z","shell.execute_reply.started":"2023-08-11T19:03:28.369516Z","shell.execute_reply":"2023-08-11T19:03:28.375347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_test['rating'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:28.378426Z","iopub.execute_input":"2023-08-11T19:03:28.378831Z","iopub.status.idle":"2023-08-11T19:03:28.400355Z","shell.execute_reply.started":"2023-08-11T19:03:28.378800Z","shell.execute_reply":"2023-08-11T19:03:28.399452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_test['isFrequentReviewer'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:28.402270Z","iopub.execute_input":"2023-08-11T19:03:28.402634Z","iopub.status.idle":"2023-08-11T19:03:28.419582Z","shell.execute_reply.started":"2023-08-11T19:03:28.402604Z","shell.execute_reply":"2023-08-11T19:03:28.418328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_test['boxOffice'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:28.421358Z","iopub.execute_input":"2023-08-11T19:03:28.421815Z","iopub.status.idle":"2023-08-11T19:03:28.439743Z","shell.execute_reply.started":"2023-08-11T19:03:28.421773Z","shell.execute_reply":"2023-08-11T19:03:28.438802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Work on vocabulary  \n\n`Build vocabulary from 'reviewText' column`  ","metadata":{}},{"cell_type":"code","source":"rt_senti = merged[[\"reviewText\", \"sentiment\"]].copy()\nrt_senti.shape, rt_senti.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:28.441911Z","iopub.execute_input":"2023-08-11T19:03:28.442456Z","iopub.status.idle":"2023-08-11T19:03:28.465075Z","shell.execute_reply.started":"2023-08-11T19:03:28.442416Z","shell.execute_reply":"2023-08-11T19:03:28.463722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rt_test = pd.DataFrame(merged_test[\"reviewText\"].copy())\nrt_test.shape, rt_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:28.490192Z","iopub.execute_input":"2023-08-11T19:03:28.490581Z","iopub.status.idle":"2023-08-11T19:03:28.503944Z","shell.execute_reply.started":"2023-08-11T19:03:28.490552Z","shell.execute_reply":"2023-08-11T19:03:28.502740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_vocab(text_df, ngram_range=(1,1)):\n    print(f\"Generating vocabulary for ngram_range: {ngram_range}...\")\n    tvec1 = CountVectorizer(ngram_range=ngram_range, stop_words='english', strip_accents='unicode')\n    tvec1.fit(text_df)\n    voc_ngram = set(tvec1.vocabulary_.keys())\n    return voc_ngram","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:28.509318Z","iopub.execute_input":"2023-08-11T19:03:28.509650Z","iopub.status.idle":"2023-08-11T19:03:28.517232Z","shell.execute_reply.started":"2023-08-11T19:03:28.509621Z","shell.execute_reply":"2023-08-11T19:03:28.515985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_common_vocab(df_list: list, ngram_range_list: list):\n    \"\"\"\n    Get common vocabulary from a list of dataframes.\n    \"\"\"\n    final_common_vocab = set()\n    # Get vocabulary from each dataframe for a given ngram-range\n    for ngram_range in ngram_range_list:\n        vocab_ngram = set()\n        for num, df in enumerate(df_list, start=1):\n            print(f\"Working on DF#{num} in the list of DFs provided\")\n            vocab_ngram_df = set(get_vocab(df['reviewText'], ngram_range))\n            print(f\"Vocabulary size for ngram-range {ngram_range} in DF#{num}: {len(vocab_ngram_df)}\\n\")\n            if len(vocab_ngram) > 0:\n                print(f\"Keeping only the common (intersection) words for ngram-range {ngram_range}...\")\n                vocab_ngram = vocab_ngram.intersection(vocab_ngram_df)\n            else:\n                print(f\"Words from the first df for ngram-range {ngram_range} added.\\n\")\n                vocab_ngram = vocab_ngram_df\n        print(f\"Common vocabulary for ngram-range {ngram_range}: {len(vocab_ngram)}\\n\")\n        \n        if len(final_common_vocab) > 0:\n            print(f\"Fusing (union) with final common vocabulary: ngram-range = {ngram_range}.\\n\")\n            final_common_vocab = final_common_vocab.union(vocab_ngram)\n        else:\n            print(f\"Appended first time to final common vocabulary: ngram-range = {ngram_range}.\\n\")\n            final_common_vocab = vocab_ngram\n    return final_common_vocab","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:28.518992Z","iopub.execute_input":"2023-08-11T19:03:28.519358Z","iopub.status.idle":"2023-08-11T19:03:28.537261Z","shell.execute_reply.started":"2023-08-11T19:03:28.519327Z","shell.execute_reply":"2023-08-11T19:03:28.535852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# voc_1gram = get_vocab(rt_senti[\"reviewText\"], ngram_range=(1,1))\n# len(voc_1gram), voc_1gram[:10]","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:28.538887Z","iopub.execute_input":"2023-08-11T19:03:28.539269Z","iopub.status.idle":"2023-08-11T19:03:28.550980Z","shell.execute_reply.started":"2023-08-11T19:03:28.539240Z","shell.execute_reply":"2023-08-11T19:03:28.549695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# voc_2gram = get_vocab(rt_senti[\"reviewText\"], ngram_range=(2,2))\n# len(voc_2gram), voc_2gram[:10]","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:28.552112Z","iopub.execute_input":"2023-08-11T19:03:28.552454Z","iopub.status.idle":"2023-08-11T19:03:28.564545Z","shell.execute_reply.started":"2023-08-11T19:03:28.552423Z","shell.execute_reply":"2023-08-11T19:03:28.563226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# voc_3gram = get_vocab(rt_senti[\"reviewText\"], ngram_range=(3,3))\n# len(voc_3gram), voc_3gram[:10]","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:28.565841Z","iopub.execute_input":"2023-08-11T19:03:28.566311Z","iopub.status.idle":"2023-08-11T19:03:28.578601Z","shell.execute_reply.started":"2023-08-11T19:03:28.566279Z","shell.execute_reply":"2023-08-11T19:03:28.577680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# common_unigrams = get_common_vocab([rt_senti, rt_test], ngram_range_list=[(1,1)])\n# print(len(common_unigrams))\n# # sorted(list(common_unigrams))","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:28.580023Z","iopub.execute_input":"2023-08-11T19:03:28.580973Z","iopub.status.idle":"2023-08-11T19:03:28.597105Z","shell.execute_reply.started":"2023-08-11T19:03:28.580930Z","shell.execute_reply":"2023-08-11T19:03:28.595792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# common_bigrams = get_common_vocab([rt_senti, rt_test], ngram_range_list=[(2,2)])\n# print(len(common_bigrams))\n# # # common_bigrams","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:28.598525Z","iopub.execute_input":"2023-08-11T19:03:28.598874Z","iopub.status.idle":"2023-08-11T19:03:46.072114Z","shell.execute_reply.started":"2023-08-11T19:03:28.598844Z","shell.execute_reply":"2023-08-11T19:03:46.071129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# common_1_2_grams = get_common_vocab([rt_senti, rt_test], ngram_range_list=[(1,1), (2,2)])\n# print(len(common_1_2_grams))\n# # sorted(list(common_1_2_grams))\n\n# # common_1_2_grams = common_unigrams | common_bigrams    # older code","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:46.073384Z","iopub.execute_input":"2023-08-11T19:03:46.073767Z","iopub.status.idle":"2023-08-11T19:03:46.079541Z","shell.execute_reply.started":"2023-08-11T19:03:46.073738Z","shell.execute_reply":"2023-08-11T19:03:46.077958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# common_trigrams = get_common_vocab([rt_senti, rt_test], ngram_range_list=[(3,3)])\n# print(len(common_trigrams))\n# # common_trigrams","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:46.080995Z","iopub.execute_input":"2023-08-11T19:03:46.081315Z","iopub.status.idle":"2023-08-11T19:03:46.095247Z","shell.execute_reply.started":"2023-08-11T19:03:46.081287Z","shell.execute_reply":"2023-08-11T19:03:46.093886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# common_1_2_3_grams = get_common_vocab([rt_senti, rt_test], ngram_range_list=[(1,1), (2,2), (3,3)])\n# print(len(common_1_2_3_grams))\n# # sorted((common_1_2_3_grams))\n\n# # common_1_2_3_grams = common_unigrams | common_bigrams | common_trigrams    # Older code  ","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:46.097028Z","iopub.execute_input":"2023-08-11T19:03:46.097350Z","iopub.status.idle":"2023-08-11T19:03:46.111018Z","shell.execute_reply.started":"2023-08-11T19:03:46.097322Z","shell.execute_reply":"2023-08-11T19:03:46.109549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Find common vocabulary between text with positive and negative sentiments in training dataset  ","metadata":{}},{"cell_type":"code","source":"# Dataframe for positive sentiment\nrt_senti_pos = rt_senti.loc[rt_senti['sentiment'] == 'POSITIVE'].copy()\nrt_senti_pos.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:46.113068Z","iopub.execute_input":"2023-08-11T19:03:46.113450Z","iopub.status.idle":"2023-08-11T19:03:46.171827Z","shell.execute_reply.started":"2023-08-11T19:03:46.113418Z","shell.execute_reply":"2023-08-11T19:03:46.170910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataframe for negative sentiment\nrt_senti_neg = rt_senti.loc[rt_senti['sentiment'] == 'NEGATIVE'].copy()\nrt_senti_neg.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:46.173482Z","iopub.execute_input":"2023-08-11T19:03:46.173789Z","iopub.status.idle":"2023-08-11T19:03:46.217156Z","shell.execute_reply.started":"2023-08-11T19:03:46.173763Z","shell.execute_reply":"2023-08-11T19:03:46.215945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate stop words/phrases specific for this project data  \n\n# common_1_2_3_grams_sentiment = get_common_vocab([rt_senti_pos, rt_senti_neg], ngram_range_list=[(1,1), (2,2), (3,3)])\n# print(len(common_1_2_3_grams_sentiment))\n# # sorted(list(common_1_2_3_grams_sentiment))","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:46.218801Z","iopub.execute_input":"2023-08-11T19:03:46.219246Z","iopub.status.idle":"2023-08-11T19:03:46.224658Z","shell.execute_reply.started":"2023-08-11T19:03:46.219201Z","shell.execute_reply":"2023-08-11T19:03:46.223425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate and store the entire vocabulary of training data  \n\n# train_1_2_3_grams = get_vocab(rt_senti['reviewText'], ngram_range=(1,3))\n# print(len(train_1_2_3_grams))\n# # sorted(train_1_2_3_grams)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:46.226359Z","iopub.execute_input":"2023-08-11T19:03:46.226717Z","iopub.status.idle":"2023-08-11T19:03:46.239074Z","shell.execute_reply.started":"2023-08-11T19:03:46.226686Z","shell.execute_reply":"2023-08-11T19:03:46.238005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# type(train_1_2_3_grams)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:46.240544Z","iopub.execute_input":"2023-08-11T19:03:46.241450Z","iopub.status.idle":"2023-08-11T19:03:46.254167Z","shell.execute_reply.started":"2023-08-11T19:03:46.241409Z","shell.execute_reply":"2023-08-11T19:03:46.252934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the vocabulary that should be used in the final models  \n# relevant_vocab = train_1_2_3_grams - common_1_2_3_grams_sentiment\n# print(len(relevant_vocab))","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:46.255647Z","iopub.execute_input":"2023-08-11T19:03:46.256616Z","iopub.status.idle":"2023-08-11T19:03:46.269126Z","shell.execute_reply.started":"2023-08-11T19:03:46.256581Z","shell.execute_reply":"2023-08-11T19:03:46.268203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submit_v4 for merged file models  ","metadata":{}},{"cell_type":"markdown","source":"### More Helper functions  ","metadata":{}},{"cell_type":"code","source":"# Testing predictions on missing reviewtext columns  \n\ndef predict_on_missing_review_data(pipe, selected_features, merged_train):\n    missing_reviews_train = merged_train.loc[merged_train['reviewYN'] == 1]\n    missing_reviews_train.reset_index(drop=True)\n    X_train_miss_revs = missing_reviews_train.drop('sentiment', axis = 1)\n    X_train_miss_revs = X_train_miss_revs[selected_features]\n    y_train_miss_revs = missing_reviews_train['sentiment']\n    \n    y_pred_miss_revs = pipe.predict(X_train_miss_revs)\n#     print('Predictions on rows which had missing reviewText')\n    print(\"Confusion matrix and f1-score for rows which have no reviewText in X_train: \")\n    print(confusion_matrix(y_train_miss_revs, y_pred_miss_revs, labels=pipe.classes_))\n    \n    return f1_score(y_train_miss_revs, y_pred_miss_revs, average='micro')","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:46.270361Z","iopub.execute_input":"2023-08-11T19:03:46.271258Z","iopub.status.idle":"2023-08-11T19:03:46.288022Z","shell.execute_reply.started":"2023-08-11T19:03:46.271226Z","shell.execute_reply":"2023-08-11T19:03:46.287010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to build pipelines for GridSearchCV which goes into the final 'submit' function  \ndef build_pipeline(selected_model=LogisticRegression(), \n                   selected_features={'txt': ['reviewText']}, \n                   param_grid=None,\n                   vocab=None,\n                   vocab_usage='tfidf',\n                   strip_accents='unicode', \n                   add_countvec=False):\n    # Encoders  \n    ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n    MMscaler = MinMaxScaler()\n    StdScaler = StandardScaler()\n    RobScaler = RobustScaler()\n    \n    # Text features ['reviewText', 'reviewerName', 'movieid', 'genre', 'director']\n    tfidf_vec = TfidfVectorizer(ngram_range=(1,2))\n    count_vec = CountVectorizer(ngram_range=(1,2))\n    txt_pipe = Pipeline(steps=[\n                            (\"tvec\", TfidfVectorizer(ngram_range=(1,3), strip_accents=strip_accents))    # Adjust ngram_range here for reviewText\n                        ])\n    txt_pipe_vocab = Pipeline(steps=[\n                            (\"tvec\", TfidfVectorizer(ngram_range=(1,3), strip_accents=strip_accents, vocabulary=vocab))    # Adjust ngram_range here for reviewText\n                        ])\n    txt_pipe_2 = Pipeline(steps=[\n                            (\"tvec\", TfidfVectorizer(ngram_range=(2,2)))\n                        ])\n    txt_pipe_3 = Pipeline(steps=[\n                            (\"tvec\", TfidfVectorizer(ngram_range=(1,1)))\n                        ])\n    txt_pipe_4 = Pipeline(steps=[\n                            (\"tvec\", TfidfVectorizer(ngram_range=(1,3)))    # Adjust ngram_range here for reviewText\n                        ])\n    txt_pipe_title  = Pipeline(steps=[\n                            (\"tvec\", TfidfVectorizer(ngram_range=(1,5)))    # Adjust ngram_range here for reviewText\n                        ])\n    \n    # Additional pipes for count vectorizer\n    txt_pipe_countvec = Pipeline(steps=[\n                            (\"cvec\", CountVectorizer(ngram_range=(1,3), strip_accents=strip_accents))    # Adjust ngram_range here for reviewText\n                        ])\n    txt_pipe_countvec_vocab = Pipeline(steps=[\n                            (\"cvec\", CountVectorizer(ngram_range=(1,3), strip_accents=strip_accents, vocabulary=vocab))    # Adjust ngram_range here for reviewText\n                        ])\n    \n    txt_pipe_countvec_ratingContents = Pipeline(steps=[\n                            (\"cvec\", CountVectorizer(ngram_range=(1,5)))    # Adjust ngram_range here for reviewText\n                        ])\n    txt_pipe_countvec_rcSorted = Pipeline(steps=[\n                            (\"cvec\", CountVectorizer(ngram_range=(1,1)))    # Adjust ngram_range here for reviewText\n                        ])\n    txt_pipe_countvec_genre = Pipeline(steps=[\n                            (\"cvec\", CountVectorizer(ngram_range=(1,1)))\n                        ])\n    txt_pipe_countvec_genreSorted = Pipeline(steps=[\n                            (\"cvec\", CountVectorizer(ngram_range=(1,5)))\n                        ])\n    txt_pipe_countvec_distributor = Pipeline(steps=[\n                            (\"cvec\", CountVectorizer(ngram_range=(1,3)))    # Adjust ngram_range here for reviewText\n                        ])\n    txt_pipe_countvec_title = Pipeline(steps=[\n                            (\"cvec\", CountVectorizer(ngram_range=(1,5), strip_accents=strip_accents))\n                        ])\n    txt_pipe_countvec_movieid = Pipeline(steps=[\n                            (\"cvec\", CountVectorizer(ngram_range=(1,1)))\n                        ])\n    # Basic pipes  \n    TFs = []\n    try:\n        for c in selected_features['cat']:\n            TFs.append((f\"cat_{c}\", ohe, [c]))\n    except:\n        pass\n    try:\n        for n in selected_features['num']:\n            if n in [\"runtimeMinutes\", \"boxOffice\", \"releaseDiff\"]:\n                TFs.append((f\"num_{n}\", RobScaler, [n]))\n                TFs.append((f\"num_{n}_ss\", StdScaler, [n]))\n                \n            else:\n                TFs.append((f\"num_{n}\", StdScaler, [n]))\n    except:\n        pass\n    try:\n        for t in selected_features['txt']:\n            if t in ['director', 'reviewerName']:\n                TFs.append((f\"txt_{t}\", txt_pipe_2, t))\n            elif t in [\"originalLanguage\", \"releaseYear\"]:\n                TFs.append((f\"txt_{t}\", txt_pipe_3, t))\n            elif t in ['genre']:\n                TFs.append((f\"txt_{t}\", txt_pipe_countvec_genre, t))\n            elif t in [\"genreSorted\"]:\n                TFs.append((f\"txt_{t}\", txt_pipe_countvec_genreSorted, t))\n            elif t in [\"distributor\"]:\n                TFs.append((f\"txt_{t}\", txt_pipe_countvec_distributor, t))\n            elif t in ['reviewText']:\n#                 if vocab and (vocab_usage in [\"tfidf\", \"both\"]):\n#                     txt_pipe.set_params(tvec__vocabulary=vocab)\n#                     txt_pipe.set_params(tvec__stop_words='english')\n                TFs.append((f\"txt_{t}\", txt_pipe, t))\n            elif t in ['reviewText_2']:\n                if add_countvec:\n#                     if vocab and (vocab_usage in [\"count\", \"both\"]):\n#                         txt_pipe_countvec.set_params(cvec__vocabulary=vocab)\n#                         txt_pipe_countvec.set_params(cvec__stop_words='english')\n                    TFs.append((f\"txt_{t}\", txt_pipe_countvec, t))\n            elif t in ['reviewText_3']:\n                if vocab_usage == 'tfidf':\n                    TFs.append((f\"txt_{t}\", txt_pipe_vocab, t))\n                elif vocab_usage == 'count':\n                    TFs.append((f\"txt_{t}\", txt_pipe_countvec_vocab, t))\n            elif t in [\"ratingContents\"]:\n                TFs.append((f\"txt_{t}\", txt_pipe_countvec_ratingContents, t))\n            elif t in [\"rcSorted\"]:\n                TFs.append((f\"txt_{t}\", txt_pipe_countvec_rcSorted, t))\n            elif t in [\"title\"]:\n                TFs.append((f\"txt_{t}\", txt_pipe_title, t))\n            elif t in [\"movieid\"]:\n                TFs.append((f\"txt_{t}\", txt_pipe_countvec_movieid, t))\n            else:\n                pass\n    except:\n        pass\n\n    # Build ColumnTransformer  \n    ct = ColumnTransformer(transformers=TFs, remainder='drop')\n\n    # Build Pipeline\n    pipe = Pipeline(steps=[('ct', ct), ('model', selected_model)])\n    print(\"\\nPipeline built successfully.\")\n\n    # Use the pipe in GridSearchCV\n    if param_grid == None:\n        param_grid_temp = {\"model__C\": [1],\n                     'model__solver': ['liblinear']}\n        print(\"Full GridSearchCV pipeline built successfully with basic default param_grid.\\n\")\n        pipeCV = GridSearchCV(pipe, param_grid_temp, cv=10, scoring=\"f1_micro\", n_jobs=-1)\n        return pipeCV\n    \n    # GridSearchCV if param_grid provided\n    if param_grid:\n        pipeCV = GridSearchCV(pipe, param_grid, cv=10, scoring=\"f1_micro\", n_jobs=-1)\n        print(\"\\nFull GridSearchCV pipeline built successfully.\")\n        return pipeCV","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:46.289700Z","iopub.execute_input":"2023-08-11T19:03:46.290237Z","iopub.status.idle":"2023-08-11T19:03:46.333682Z","shell.execute_reply.started":"2023-08-11T19:03:46.290205Z","shell.execute_reply":"2023-08-11T19:03:46.332726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocessor():\n    \n    # Merge and preprocess train and movies data  \n    merged = select_features(load_csv(\"train\"), load_csv(\"movies\"), row_thresh_null=None)    # Decide if you want to drop any rows containing lot of nulls\n    # Impute missing numerical values  \n    # Simple Imputer for ['audienceScore', 'runtimeMinutes', 'boxOffice'] and 'releaseDate' columns\n    si = SimpleImputer(strategy='median')\n    merged[['audienceScore', 'runtimeMinutes', 'boxOffice']] = si.fit_transform(merged[['audienceScore', 'runtimeMinutes', 'boxOffice']])\n    merged['releaseDate'] = merged[\"releaseDate\"].fillna(merged[\"releaseDate\"].median())    \n\n    # Create new feature columns\n    \n    # Convert audienceScore to categories  \n    num_bins_as = 20\n    merged[\"audScoreBins\"] = pd.cut(merged['audienceScore'], bins=num_bins_as, labels=False)\n\n    # Convert runtimeMinutes to categories  \n#     num_bins_rt = 20\n    merged[\"runtimeBins\"] = pd.cut(merged['runtimeMinutes'], bins=[0,75,120,180,565], labels=[4,3,2,1])\n    \n    # Convert boxOffice to categories  \n    num_bins_bo = 5\n    merged[\"boxOfficeBins\"] = pd.cut(merged['boxOffice'], bins=num_bins_bo, labels=False)\n    \n    # Convert releaseDiff to categories  \n    num_bins_rd = 5\n    merged[\"releaseDiffBins\"] = pd.cut(merged['releaseDiff'], bins=[-1, 180, 360, 1000, 40000], labels=[0, 1, 2, 3])\n    \n    # Check1 (preprocessor)\n    print(\"\\nCheck 1 (preprocessor) complete.\")\n    print(f\"Shape of X_train: {merged.shape}\")\n    print(f\"Features in X_train: {merged.columns}\")\n\n\n    \n    # Merge and preprocess test and movies data  \n    merged_test = select_features(load_csv(\"test\"), load_csv(\"movies\"))\n    # Transform ['audienceScore', 'runtimeMinutes', 'boxOffice'] columns in merged_test using 'si' fitted on 'merged' df  \n    merged_test[['audienceScore', 'runtimeMinutes', 'boxOffice']] = si.transform(merged_test[['audienceScore', 'runtimeMinutes', 'boxOffice']])\n    # Fill 'releaseDate' column in 'merged_test' df with median from the train (merged) df  \n    merged_test['releaseDate'] = merged_test[\"releaseDate\"].fillna(merged[\"releaseDate\"].median())\n\n    \n    # Create new feature columns\n    \n    # Convert audienceScore to categories  \n    num_bins_as = 20\n    merged_test[\"audScoreBins\"] = pd.cut(merged_test['audienceScore'], bins=num_bins_as, labels=False)\n    \n    # Convert runtimeMinutes to categories  \n#     num_bins_rt = 20\n    merged_test[\"runtimeBins\"] = pd.cut(merged_test['runtimeMinutes'], bins=[0,75,120,180,565], labels=[4,3,2,1])\n    \n    # Convert boxOffice to categories  \n    num_bins_bo = 5\n    merged_test[\"boxOfficeBins\"] = pd.cut(merged_test['boxOffice'], bins=num_bins_bo, labels=False)\n    \n    # Convert releaseDiff to categories  \n    num_bins_rd = 5\n    merged_test[\"releaseDiffBins\"] = pd.cut(merged_test['releaseDiff'], bins=[-1, 180, 360, 1000, 40000], labels=[0, 1, 2, 3])\n    \n    \n    # Check2 (preprocessor)\n    print(\"\\nCheck 2 (preprocessor) complete.\")\n    print(f\"Shape of X_test: {merged_test.shape}\")\n    print(f\"Features in X_test: {merged_test.columns}\")\n\n    return merged, merged_test\n    ","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:46.335055Z","iopub.execute_input":"2023-08-11T19:03:46.335385Z","iopub.status.idle":"2023-08-11T19:03:46.354626Z","shell.execute_reply.started":"2023-08-11T19:03:46.335358Z","shell.execute_reply":"2023-08-11T19:03:46.353117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merged, merged_test = preprocessor()\n# merged.shape, merged_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:46.356162Z","iopub.execute_input":"2023-08-11T19:03:46.356515Z","iopub.status.idle":"2023-08-11T19:03:46.373288Z","shell.execute_reply.started":"2023-08-11T19:03:46.356485Z","shell.execute_reply":"2023-08-11T19:03:46.372268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def submit_v5(classifiers= [\n                {'selected_model' : LogisticRegression(C=1, solver='saga', max_iter=100000), \n                  'selected_features' : {'num': ['audienceScore']}, \n                  'param_grid' : None,\n                  'vocab' : None,\n                  'vocab_usage' : 'tfidf',\n                  'strip_accents' : 'unicode', \n                  'add_countvec' : False}\n              ]):\n    \n    \"\"\"Takes a list of dictionaries each with same keys as mentioned in the default dictionary in function definition\"\"\"\n    \n    print(\"\\nRunning the submit_v5 function...\")\n    \n    merged, merged_test = preprocessor()\n    print(f\"Preprocessing of train and test datasets complete.\")\n    \n    # Build vocabulary (if vocab is True)\n    vocab = None\n    for item in classifiers:\n        if item['vocab']:\n            vocab = True\n            break\n    \n    if vocab == True:\n        # Generate and store the entire vocabulary of training data  \n        print(f\"Generating stop words/phrases specific for this project data...\")\n        train_1_2_3_grams = get_vocab(merged['reviewText'], ngram_range=(1,3))\n        print(f\"Size of vocabulary of training data: {len(train_1_2_3_grams)}\")\n        # sorted(train_1_2_3_grams)\n\n        # Generate stop words/phrases specific for this project data  \n        print(f\"Generating stop words/phrases specific for this project data...\")\n        common_1_2_3_grams = get_common_vocab([merged, merged_test], ngram_range_list=[(1,1), (2,2), (3,3)])\n        print(f\"Number of stop words: {len(common_1_2_3_grams)}\")\n\n        # Get the vocabulary that should be used in the final models  \n        print(f\"Getting the vocabulary that will be fed to the final model(s)...\")\n        relevant_vocab = list(train_1_2_3_grams - common_1_2_3_grams)\n        print(f\"Size of the final relevant vocabulary: {len(relevant_vocab)}\")\n    else:\n        pass\n    \n    \n    # Create a list to store estimators  \n    estimators = []     # List of tuples of the form ('classifier_name', 'classifer_instance')\n    \n    # Build a dataframe of predictions  \n    predictions_df = pd.DataFrame()\n    \n    # Build a separate pipeline and fit it on selected features (and param_grid) for each item in classifiers list\n    for n, item in enumerate(classifiers, start=1):\n        selected_model = item['selected_model']\n        selected_features = item['selected_features']\n        param_grid = item['param_grid']\n        vocab = item['vocab']\n        vocab_usage = item['vocab_usage']\n        strip_accents = item['strip_accents']\n        add_countvec = item['add_countvec']\n    \n    \n        # Fine tune selected_features\n        if add_countvec:\n            if 'txt' in selected_features.keys():\n                if \"reviewText_2\" not in selected_features['txt']:\n                    selected_features['txt'].append('reviewText_2')\n        if vocab:\n            if 'txt' in selected_features.keys():\n                if \"reviewText_3\" not in selected_features['txt']:\n                    selected_features['txt'].append('reviewText_3')\n        else:\n            print(f\"No vocabulary provided/used for this model.\")\n        print(f\"\\nSelected features: {selected_features}\")\n        \n        if type(vocab) in [type([1, 2]), type({1, 2})]:\n            vocab = vocab\n        elif vocab == True:\n            vocab = common_1_2_3_grams    # Choose vocabulary here\n\n        # Modify X_train for the given 'item' by creating a custom 'features' list\n        features = []\n        for item in selected_features.values():\n            features.extend(item)\n            \n        # Add new columns as needed  \n        if add_countvec:\n            merged['reviewText_2'] = merged['reviewText']\n        if vocab:\n            merged['reviewText_3'] = merged['reviewText']\n        \n        # Create X_tran, y_train\n        X_train = merged.drop(labels=\"sentiment\", axis=1)\n        y_train = merged[\"sentiment\"]\n        \n        X_train = merged[features].copy()\n\n\n        # Build Pipeline\n        pipe = build_pipeline(selected_model, selected_features, param_grid=param_grid, \n                              vocab=vocab, vocab_usage='tfidf', \n                              strip_accents=strip_accents, add_countvec=add_countvec)\n        print(pipe)\n\n        \n        # Fit \n        print(f\"\\nTraining started with full pipeline for classifier #{n}/{len(classifiers)}...\")\n        pipe.fit(X_train, y_train)\n        \n\n        # Check1\n        print(f\"\\nCheck #{n}.1 complete.\")\n        print(f\"Details of the best model using classifier #{n} (GridSearchCV) on X_train: \")\n        print(f\"Best Params: {pipe.best_params_}\")\n        print(f\"Best Score: {pipe.best_score_}\")\n        \n        print(predict_on_missing_review_data(pipe, features, merged))    # Function defined above\n        \n        estimators.append((f\"classifier_{n}\", pipe))\n        print(f\"classifier_{n} successfully added to 'estimators' list\")\n\n        \n        # Predict on test.csv file\n        # Add new columns as needed \n        if add_countvec:\n            merged_test['reviewText_2'] = merged_test['reviewText']\n        if vocab:\n            merged_test['reviewText_3'] = merged_test['reviewText']\n        \n               \n        X_test = merged_test[features].copy()\n\n    \n        y_pred = pipe.predict(X_test)\n        \n        # Insert predictions in 'predictions_df' dataframe\n        predictions_df.insert(n-1, f\"pred_{n}\", y_pred, allow_duplicates=False)\n        print(predictions_df.shape)\n        print(predictions_df.head(10))\n        \n    \n        # Check2\n        print(f\"\\nCheck #{n}.2 complete.\")\n    #     cv_results_df = pd.DataFrame(pipe.cv_results_)\n        print(\"Details of the best model using full pipeline (GridSearchCV) on X_train: \")\n#         print(f\"Best Estimator: {pipe.best_estimator_}\")\n        print(f\"Best Params: {pipe.best_params_}\")\n        print(f\"Best Score: {pipe.best_score_}\")\n#         print(f\"Best Index: {pipe.best_index_}\")\n        print(f\"Refit Time: {pipe.refit_time_}\")\n    #     print(f\"Shape of CV results dataframe: {cv_results_df.shape}\")\n    \n    # Voting classifier (custom) with hard voting\n    # Calculate the MODE for all predictions (Note that the 'predictions_df' generated above should have odd number of columns)\n    pred_df_final = predictions_df.mode('columns')\n    pred_df_final.columns = [\"sentiment\"]\n    pred_df_final.index.name = \"id\"\n    pred_df_final.to_csv(\"submission.csv\")\n    \n    print(\"\\nSuccessfully created the submission file!!!\")\n    \n#     return pipe.cv_results_\n    return pred_df_final, estimators","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:03:46.375339Z","iopub.execute_input":"2023-08-11T19:03:46.376197Z","iopub.status.idle":"2023-08-11T19:03:46.411776Z","shell.execute_reply.started":"2023-08-11T19:03:46.376160Z","shell.execute_reply":"2023-08-11T19:03:46.410271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Use 'submit_v5' function  ","metadata":{}},{"cell_type":"code","source":"# Try submit_v5 with default settings\n# submit_v5()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:41:28.077998Z","iopub.execute_input":"2023-08-11T19:41:28.078427Z","iopub.status.idle":"2023-08-11T19:41:28.083640Z","shell.execute_reply.started":"2023-08-11T19:41:28.078387Z","shell.execute_reply":"2023-08-11T19:41:28.082273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing ONE classfier using submit_v5 function  \n\n# Feature dictionaries\nsfs = {'cat': ['isFrequentReviewer', 'rating'],\n       'num': [\"audienceScore\", \"runtimeMinutes\", \"boxOffice\", 'releaseDiff']}\n\nsf_best = {'cat': ['isFrequentReviewer'],\n            'num': [\"audienceScore\", \"boxOffice\", 'releaseDiff'],\n            'txt': ['reviewText', 'reviewerName', 'movieid', 'genre', 'director', \n                         'ratingContents', 'distributor']}\n\nalt_text = {'txt': ['reviewerName', 'movieid', 'genre', 'director', \n                         'ratingContents', 'distributor']}\n\nv88_dict = {'cat': ['isFrequentReviewer', 'audScoreBins', 'boxOfficeBins'],\n            'num': ['releaseDiff'],\n            'txt': ['reviewText', 'reviewerName', 'movieid', 'genre', 'director', \n                         'ratingContents', 'distributor']}\n\n# SGDClassifier hyperparameters  \n# \"model__loss\": ['hinge', 'log_loss', 'modified_huber', \n#                                                   'squared_hinge', 'perceptron', \n#                                                   'squared_error', 'huber', \n#                                                   'epsilon_insensitive', 'squared_epsilon_insensitive']\n\n# 'param_grid' : {\"model__alpha\": [0.0001], \n#                   'model__tol': [0.0001],\n#                   \"model__penalty\": [\"l2\"],\n#                   \"model__n_iter_no_change\": [100],\n#                  }\n\n# Best models \n# For sf_best features\n#                 {'selected_model' : SGDClassifier(loss='hinge', \n#                                      max_iter=1000000,\n#                                      alpha = 0.0001,\n#                                      tol = 0.0001,\n#                                      penalty = \"l2\",\n#                                      n_iter_no_change = 100,\n#                                      n_jobs = -1), \n#                   'selected_features' : sf_best, \n#                   'param_grid' : {\"model__alpha\": [ 0.0001]},\n#                   'vocab' : True,\n#                   'vocab_usage' : 'tfidf',\n#                   'strip_accents' : 'unicode', \n#                   'add_countvec' : True},\n\n# For sfs features\n#                 {'selected_model' : RandomForestClassifier(n_jobs = -1), \n#                   'selected_features' : sfs, \n#                   'param_grid': {'model__n_estimators': [100]},\n#                   'vocab' : None,\n#                   'vocab_usage' : 'tfidf',\n#                   'strip_accents' : 'unicode', \n#                   'add_countvec' : False}\n\n# Best SGD classifer (with params)  \nsgdc = SGDClassifier(loss='hinge', \n                     max_iter=1000000,\n                     alpha = 0.0001,\n                     tol = 0.0001,\n                     penalty = \"l2\",\n                     n_iter_no_change = 100,\n                     n_jobs = -1)\n\n# Classifiers\nclassifiers= [   \n                {'selected_model' : sgdc, \n                  'selected_features' : v88_dict, \n                  'param_grid' : {\"model__alpha\": [0.0001]},\n                  'vocab' : True,\n                  'vocab_usage' : 'tfidf',\n                  'strip_accents' : 'unicode', \n                  'add_countvec' : True}\n            ]\n\n# classifiers= [\n#                 {'selected_model' : LogisticRegression(C=1, solver='saga', max_iter=100000), \n#                   'selected_features' : {'txt': [\"reviewText\"]}, \n#                   'param_grid' : {\"model__C\": [1], \n#                                   'model__solver': ['saga']},\n#                   'vocab' : None,\n#                   'vocab_usage' : 'tfidf',\n#                   'strip_accents' : 'unicode', \n#                   'add_countvec' : False},\n#             ]\n\npred_df, estimators = submit_v5(classifiers=classifiers)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T20:50:47.785044Z","iopub.execute_input":"2023-08-11T20:50:47.785687Z","iopub.status.idle":"2023-08-11T21:18:52.700035Z","shell.execute_reply.started":"2023-08-11T20:50:47.785635Z","shell.execute_reply":"2023-08-11T21:18:52.698136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(pred_df.shape)\nprint(pred_df.head())","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:41:36.764404Z","iopub.execute_input":"2023-08-11T19:41:36.764797Z","iopub.status.idle":"2023-08-11T19:41:36.772346Z","shell.execute_reply.started":"2023-08-11T19:41:36.764769Z","shell.execute_reply":"2023-08-11T19:41:36.770963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# estimators","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.904091Z","iopub.status.idle":"2023-08-11T19:04:08.904492Z","shell.execute_reply.started":"2023-08-11T19:04:08.904299Z","shell.execute_reply":"2023-08-11T19:04:08.904317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Number of estimators: {len(estimators)}\\n\")\nfor est in estimators:\n    print(f\"Estimator: {est[0]}\")\n#     print(est[1].best_estimator_)\n    print(est[1].best_params_)\n    print(est[1].best_score_)\n    print(est[1].refit_time_)\n    print()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.906758Z","iopub.status.idle":"2023-08-11T19:04:08.907562Z","shell.execute_reply.started":"2023-08-11T19:04:08.907264Z","shell.execute_reply":"2023-08-11T19:04:08.907291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing full capabilites of submit_v5  \n\n# # Feature dictionaries\n# sf1 = {'cat': ['isFrequentReviewer', 'rating'],\n#        'num': [\"audienceScore\", \"runtimeMinutes\", \"boxOffice\"]}\n\n# sf2 = {'cat': ['isFrequentReviewer', 'rating'],\n#        'num': [\"audienceScore\", \"runtimeMinutes\", \"boxOffice\"]}\n\n# sf3 = {'cat': ['isFrequentReviewer'],\n#         'num': ['releaseDiff', 'audienceScore', 'boxOffice'],\n#         'txt': ['reviewText', 'reviewerName', 'movieid', 'genre', 'director', \n#                          'ratingContents', 'distributor']}\n\n# # Individual classifiers\n# clf1 =  {'selected_model' : AdaBoostClassifier(), \n#           'selected_features' : sf1, \n#           'param_grid' : {\"model__n_estimators\": [50]},\n#           'vocab' : None,\n#           'vocab_usage' : 'tfidf',\n#           'strip_accents' : 'unicode', \n#           'add_countvec' : False}\n\n# clf2 =  {'selected_model' : RandomForestClassifier(), \n#           'selected_features' : sf2,\n#           'param_grid' : {\"model__n_estimators\": [50], \n#                           'model__criterion': ['gini']},\n#           'vocab' : None,\n#           'vocab_usage' : 'tfidf',\n#           'strip_accents' : 'unicode', \n#           'add_countvec' : False}\n\n# clf3 =  {'selected_model' : LogisticRegression(C=1, solver='saga', max_iter=100000), \n#           'selected_features' : sf3, \n#           'param_grid' : {'model__C' : [1],\n#                             'model__solver': ['saga'],\n#                             \"model__fit_intercept\" : [True],\n#                             \"model__dual\" : [False]},\n#           'vocab' : None,\n#           'vocab_usage' : 'tfidf',\n#           'strip_accents' : 'unicode', \n#           'add_countvec' : True}\n\n\n# # List of classifiers for voting\n# classifiers= [clf1, clf2, clf3]\n\n# # Final predictions \n# pred_df = submit_v5(classifiers=classifiers)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.909584Z","iopub.status.idle":"2023-08-11T19:04:08.910065Z","shell.execute_reply.started":"2023-08-11T19:04:08.909812Z","shell.execute_reply":"2023-08-11T19:04:08.909832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(pred_df.shape)\npred_df","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.911379Z","iopub.status.idle":"2023-08-11T19:04:08.911784Z","shell.execute_reply.started":"2023-08-11T19:04:08.911588Z","shell.execute_reply":"2023-08-11T19:04:08.911607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pred_df_mode = pred_df.mode(axis='columns')\n# print(pred_df_mode.shape)\n# pred_df_mode","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.913100Z","iopub.status.idle":"2023-08-11T19:04:08.913496Z","shell.execute_reply.started":"2023-08-11T19:04:08.913303Z","shell.execute_reply":"2023-08-11T19:04:08.913322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_df.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.915282Z","iopub.status.idle":"2023-08-11T19:04:08.915681Z","shell.execute_reply.started":"2023-08-11T19:04:08.915487Z","shell.execute_reply":"2023-08-11T19:04:08.915505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NOTE: Move submit_v4 submissions below the suubmit_v4 function  ","metadata":{}},{"cell_type":"code","source":"# Try 'submit_v4' function with default params (LogisticRegression model)  \n\n# submit_v4()\n\n#Default params to this function gave a score of 0.8259 - improvement over previous score of 0.82563!","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.918100Z","iopub.status.idle":"2023-08-11T19:04:08.918937Z","shell.execute_reply.started":"2023-08-11T19:04:08.918691Z","shell.execute_reply":"2023-08-11T19:04:08.918712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Try out GridSearchCV on \"submit_v4\" function with param_grid  \n# param_grid = {\n#     \"model__C\": [0.1, 1, 5, 10]\n# }\n\n# submit_v4(selected_features={'txt': ['genre']}, param_grid=param_grid)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.920184Z","iopub.status.idle":"2023-08-11T19:04:08.920885Z","shell.execute_reply.started":"2023-08-11T19:04:08.920671Z","shell.execute_reply":"2023-08-11T19:04:08.920692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Try LinearSVC with GridSearchCV  ","metadata":{}},{"cell_type":"code","source":"# all_dict = {'cat': [\"isFrequentReviewer\", \"rating\", \"originalLanguage\"],\n#              'num': [\"audienceScore\", \"runtimeMinutes\", \"boxOffice\"],\n#              'txt': ['reviewText', 'reviewerName', 'movieid', 'genre', 'director']}\n\n# param_grid_svc = {\n#     \"model__C\": [0.1, 1, 10, 100]\n# }\n# param_grid_svc","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.922168Z","iopub.status.idle":"2023-08-11T19:04:08.922904Z","shell.execute_reply.started":"2023-08-11T19:04:08.922674Z","shell.execute_reply":"2023-08-11T19:04:08.922695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LinearSCV on single feature  \n\n# submit_v4(selected_model=LinearSVC(max_iter=100000, random_state=42), selected_features={'num': [\"audienceScore\"]}, param_grid=param_grid_svc)\n\n# Comment: LinearSVC even on single column feature set takes too long to converge.","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.924191Z","iopub.status.idle":"2023-08-11T19:04:08.924915Z","shell.execute_reply.started":"2023-08-11T19:04:08.924693Z","shell.execute_reply":"2023-08-11T19:04:08.924714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LinearSCV on all available features\n\n# submit_v4(selected_model=LinearSVC(max_iter=100000, random_state=42), selected_features=all_dict, param_grid=param_grid_svc)\n\n# (Update): This took 66 mins to run and gave a public score of 0.84295 (lesser than logreg gridsearchcv wwhich gave 0.84441). Best C was 1.0.\n","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.926147Z","iopub.status.idle":"2023-08-11T19:04:08.926934Z","shell.execute_reply.started":"2023-08-11T19:04:08.926710Z","shell.execute_reply":"2023-08-11T19:04:08.926731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Boosting techniques  ","metadata":{}},{"cell_type":"code","source":"# adc = AdaBoostClassifier(estimator=LogisticRegression(C=5, solver=\"saga\", max_iter=100000), n_estimators=50)\n# adc","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.928162Z","iopub.status.idle":"2023-08-11T19:04:08.928878Z","shell.execute_reply.started":"2023-08-11T19:04:08.928666Z","shell.execute_reply":"2023-08-11T19:04:08.928687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit_v4(selected_model=adc, selected_features={'num': [\"audienceScore\"]}, param_grid=None)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.930128Z","iopub.status.idle":"2023-08-11T19:04:08.930865Z","shell.execute_reply.started":"2023-08-11T19:04:08.930640Z","shell.execute_reply":"2023-08-11T19:04:08.930661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit_v4(selected_model=adc, selected_features=all_dict, param_grid=None)\n\n# Took 1 hour 15 mins to run and gave a public score of only 0.71089. Discarded.","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.932230Z","iopub.status.idle":"2023-08-11T19:04:08.933088Z","shell.execute_reply.started":"2023-08-11T19:04:08.932747Z","shell.execute_reply":"2023-08-11T19:04:08.932772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### LightGBM  ","metadata":{}},{"cell_type":"code","source":"# lgb = ltb.LGBMClassifier()\n# lgb","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.934592Z","iopub.status.idle":"2023-08-11T19:04:08.935413Z","shell.execute_reply.started":"2023-08-11T19:04:08.935130Z","shell.execute_reply":"2023-08-11T19:04:08.935156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Try LightGBM with default settings\n# (Update): Public score only 0.77713. It was fast, took less than 5 mins (without GridSearchCV)\n\n# submit_v4(selected_model=ltb.LGBMClassifier(), selected_features=all_dict, param_grid=None)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.937378Z","iopub.status.idle":"2023-08-11T19:04:08.937989Z","shell.execute_reply.started":"2023-08-11T19:04:08.937674Z","shell.execute_reply":"2023-08-11T19:04:08.937700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"### Plan  \n* Add a new column 'reviewWC' which has word count of 'reviewText'  \n    * Check if there is any relationship between 'reviewWC' and 'sentiment'\n* Work on vocabulary\n     * Use TfidfVectorizer and find out the vocabulary of 'reviewText' column for various ngrams\n     * Use RecursiveFeatureElimination (RFE) or RFECV to select 1000 top words/vocab for each ngram\n     * Use the final vocab (1000-3000 words) in the model and see how it performs compared to whole vocab\n\n`(Update): Code incorporated into the \"select_features\" function  `  \n`(Update): Many other new features incorporated into the \"select_features\" function too  `  \n\n","metadata":{}},{"cell_type":"markdown","source":"# Back to vocab after success of version 63  ","metadata":{}},{"cell_type":"code","source":"def submit_v4(selected_model=LogisticRegression(C=1, solver='liblinear', max_iter=100000), \n              selected_features={'txt': ['reviewText']}, \n              param_grid=None,\n              vocab=None,\n              vocab_usage='tfidf',\n              strip_accents='unicode', \n              add_countvec=False):\n    \n    print(\"\\nRunning the submit_v4 function...\")\n    \n    # Fine tune selected_features\n    if add_countvec:\n        if 'txt' in selected_features.keys():\n            if \"reviewText_2\" not in selected_features['txt']:\n                selected_features['txt'].append('reviewText_2')\n    if vocab:\n        if 'txt' in selected_features.keys():\n            if \"reviewText_3\" not in selected_features['txt']:\n                selected_features['txt'].append('reviewText_3')\n    print(f\"\\nSelected features: {selected_features}\")\n\n    \n    \n    # Build Pipeline\n    pipe = build_pipeline(selected_model, selected_features, param_grid=param_grid, \n                          vocab=vocab, vocab_usage='tfidf', \n                          strip_accents=strip_accents, add_countvec=add_countvec)\n    print(pipe)\n\n    \n    \n    # Features list\n    features = []\n    for item in selected_features.values():\n        features.extend(item)\n \n\n    # Merge and preprocess train and movies data  \n    merged = select_features(load_csv(\"train\"), load_csv(\"movies\"), row_thresh_null=None)    # Decide if you want to drop any rows containing lot of nulls\n    # Impute missing numerical values  \n    # Simple Imputer for ['audienceScore', 'runtimeMinutes', 'boxOffice'] and 'releaseDate' columns\n    si = SimpleImputer(strategy='median')\n    merged[['audienceScore', 'runtimeMinutes', 'boxOffice']] = si.fit_transform(merged[['audienceScore', 'runtimeMinutes', 'boxOffice']])\n    merged['releaseDate'] = merged[\"releaseDate\"].fillna(merged[\"releaseDate\"].median())    \n    # Add new columns as needed  \n    if add_countvec:\n        merged['reviewText_2'] = merged['reviewText']\n    if vocab:\n        merged['reviewText_3'] = merged['reviewText']\n        \n    X_train = merged.drop(labels=\"sentiment\", axis=1)\n    y_train = merged[\"sentiment\"]\n\n    X_train = X_train[features]\n    \n    \n    # Check1\n    print(\"\\nCheck 1 complete.\")\n    print(f\"Shape of X_train: {X_train.shape}\")\n    print(f\"Features in X_train: {X_train.columns}\")\n#     print(X_train.head())\n    \n    \n    # Fit \n    print(\"\\nTraining started with full pipeline...\")\n    pipe.fit(X_train, y_train)\n    \n    # Check2\n    print(\"\\nCheck 2 complete.\")\n    print(\"Details of the best model using full pipeline (GridSearchCV) on X_train: \")\n    print(f\"Best Params: {pipe.best_params_}\")\n    print(f\"Best Score: {pipe.best_score_}\")\n    \n    print(predict_on_missing_review_data(pipe, features, merged))    # Function defined above\n    \n        \n    # Predict on test.csv file\n    \n    # Merge and preprocess test and movies data  \n    merged_test = select_features(load_csv(\"test\"), load_csv(\"movies\"))\n    # Transform ['audienceScore', 'runtimeMinutes', 'boxOffice'] columns in merged_test using 'si' fitted on 'merged' df  \n    merged_test[['audienceScore', 'runtimeMinutes', 'boxOffice']] = si.transform(merged_test[['audienceScore', 'runtimeMinutes', 'boxOffice']])\n    # Fill 'releaseDate' column in 'merged_test' df with median from the train (merged) df  \n    merged_test['releaseDate'] = merged_test[\"releaseDate\"].fillna(merged[\"releaseDate\"].median())\n    # Add new columns as needed \n    if add_countvec:\n        merged_test['reviewText_2'] = merged_test['reviewText']\n    if vocab:\n        merged_test['reviewText_3'] = merged_test['reviewText']\n        \n    X_test = merged_test.copy()\n\n    X_test = X_test[features]\n    \n    \n    # Check3\n    print(\"\\nCheck 3 complete.\")\n    print(f\"Shape of X_test: {X_test.shape}\")\n    print(f\"Features in X_test: {X_test.columns}\")\n#     print(X_test.head())\n    \n    y_pred = pipe.predict(X_test)\n    \n    # Check4\n    print(\"\\nCheck 4 complete.\")\n#     cv_results_df = pd.DataFrame(pipe.cv_results_)\n    print(\"Details of the best model using full pipeline (GridSearchCV) on X_train: \")\n    print(f\"Best Estimator: {pipe.best_estimator_}\")\n    print(f\"Best Params: {pipe.best_params_}\")\n    print(f\"Best Score: {pipe.best_score_}\")\n    print(f\"Best Index: {pipe.best_index_}\")\n    print(f\"Refit Time: {pipe.refit_time_}\")\n#     print(f\"Shape of CV results dataframe: {cv_results_df.shape}\")\n    \n    pred_df = pd.DataFrame(y_pred)\n    pred_df.columns = [\"sentiment\"]\n    pred_df.index.name = \"id\"\n    pred_df.to_csv(\"submission.csv\")\n    \n    print(\"\\nSuccessfully created the submission file!!!\")\n    \n    return pipe.cv_results_","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.939404Z","iopub.status.idle":"2023-08-11T19:04:08.939991Z","shell.execute_reply.started":"2023-08-11T19:04:08.939671Z","shell.execute_reply":"2023-08-11T19:04:08.939702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged.columns","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.941840Z","iopub.status.idle":"2023-08-11T19:04:08.942409Z","shell.execute_reply.started":"2023-08-11T19:04:08.942129Z","shell.execute_reply":"2023-08-11T19:04:08.942153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Best #2\nv80_dict = {'cat': ['isFrequentReviewer', 'audScoreBins', 'boxOfficeBins'], \n                  'txt': ['reviewText', 'reviewerName', 'movieid', 'genre', 'director', \n                          'ratingContents', 'distributor']}\n# Best #1\nv88_dict = {'cat': ['isFrequentReviewer', 'audScoreBins', 'boxOfficeBins'],\n            'num': ['releaseDiff'],\n            'txt': ['reviewText', 'reviewerName', 'movieid', 'genre', 'director', \n                         'ratingContents', 'distributor']}\n\nv92_dict = {'cat': ['isFrequentReviewer', 'audScoreBins', 'boxOfficeBins', 'releaseDiffBins'],\n            'txt': ['reviewText', 'reviewerName', 'title', 'genre', 'director', \n                         'ratingContents', 'distributor']}\n\n# Best univariable datapoints dict\nbest_uni_dict = {'cat': [\"isFrequentReviewer\", \"audScoreBins\"],\n                 'txt': ['reviewText','movieid', 'director', \"ratingContents\"]}\n\n# param_grids for LogisticRegression  \n\n# Best #1  \n# param_grid = {\n#     'model__C' : [1],\n#     'model__solver': ['saga'],\n#     \"model__fit_intercept\" : [True],\n#     \"model__dual\" : [False]\n#     }\n\n# working\nparam_grid = {\n    'model__C' : [1],\n    'model__solver': ['saga'],\n    \"model__fit_intercept\" : [True],\n    \"model__dual\" : [False],\n#     \"model__class_weight\": ['balanced', None]\n}\n\n\n# param_grids for LinearSVC  \n\n# param_grid = {\n#     'model__C' : [1, 10, 20],\n#     'model__loss': ['hinge', 'squared_hinge'],\n#     \"model__fit_intercept\" : [True, False],\n# #     \"model__dual\" : [True, False] \n# }\n\nsvm = LinearSVC(max_iter=10000, random_state=42)    # LinearSVC\n\n\n# Local testing\n# selected_mov = {'num': ['audienceScore', 'boxOffice', 'releaseDiff'], \n#                 'txt': ['movieid', 'genre', 'director', \n#                          'ratingContents', 'distributor']}\n# results = submit_v4(\n#             selected_features={'num': ['boxOffice']},\n#             add_countvec=False,\n#             vocab=None,\n#             vocab_usage='tfidf',\n#             param_grid=param_grid\n#          )\n\n# results = submit_v4(selected_model = DummyClassifier(strategy='constant', constant='NEGATIVE'),\n#             selected_features={'num': ['boxOffice']},\n#             add_countvec=False,\n#             vocab=None,\n#             vocab_usage='tfidf',\n#             param_grid={'model__strategy' : ['constant']}\n#          )\n\n# Main submission\n\n# results = submit_v4(\n#     selected_features=v88_dict,\n#     add_countvec=False,\n#     vocab=common_1_2_3_grams,\n#     vocab_usage='tfidf',\n#     param_grid=param_grid\n#     )\n\n# results","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.945151Z","iopub.status.idle":"2023-08-11T19:04:08.948097Z","shell.execute_reply.started":"2023-08-11T19:04:08.947678Z","shell.execute_reply":"2023-08-11T19:04:08.947712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ratingContents analysis  ","metadata":{}},{"cell_type":"code","source":"# Try string split  \n# s = \"comedy, animation, adventure, fantasy\"\n# (\",\").join(sorted(s.split(\", \")))","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.949808Z","iopub.status.idle":"2023-08-11T19:04:08.950745Z","shell.execute_reply.started":"2023-08-11T19:04:08.950441Z","shell.execute_reply":"2023-08-11T19:04:08.950470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ratingContents_analysis = merged[[\"ratingContents\", \"sentiment\"]].copy()\n# print(ratingContents_analysis.head())\n# ratingContents_analysis[\"rcSorted\"] = ratingContents_analysis[\"ratingContents\"].apply(lambda x: (\",\").join(sorted(x.strip(\"][\").split(\", \"))))\n# ratingContents_analysis[\"rcSorted\"] = ratingContents_analysis[\"rcSorted\"].apply(lambda x: re.sub(r\"'\", \"\", x))\n# ratingContents_analysis[\"rcSorted\"] = ratingContents_analysis[\"rcSorted\"].apply(lambda x: re.sub(r\"[/\\s]\", \"_\", x))\n# ratingContents_analysis.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.952355Z","iopub.status.idle":"2023-08-11T19:04:08.953285Z","shell.execute_reply.started":"2023-08-11T19:04:08.952936Z","shell.execute_reply":"2023-08-11T19:04:08.952971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cvec_rc = CountVectorizer(ngram_range=(1,1))\n# cvec_rc.fit(ratingContents_analysis['rcSorted'])\n# # len(cvec_rc.vocabulary_), cvec_rc.vocabulary_","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.955230Z","iopub.status.idle":"2023-08-11T19:04:08.955856Z","shell.execute_reply.started":"2023-08-11T19:04:08.955641Z","shell.execute_reply":"2023-08-11T19:04:08.955673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# genre_testing = cvec_g.transform(merged[\"genre\"])\n# print(genre_testing)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.957214Z","iopub.status.idle":"2023-08-11T19:04:08.957920Z","shell.execute_reply.started":"2023-08-11T19:04:08.957683Z","shell.execute_reply":"2023-08-11T19:04:08.957706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Statistical tests  ","metadata":{}},{"cell_type":"markdown","source":"[Go to genre](#genre_analysis)","metadata":{}},{"cell_type":"code","source":"# print(merged['boxOffice'].head())\n# merged[\"boxOffice\"].describe()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.959516Z","iopub.status.idle":"2023-08-11T19:04:08.960490Z","shell.execute_reply.started":"2023-08-11T19:04:08.960242Z","shell.execute_reply":"2023-08-11T19:04:08.960275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function for independent samples t-test on numerical columns  \n# def ttest_ind(feature):\n#     pos_grp = merged[feature].loc[merged['sentiment'] == \"POSITIVE\"]\n#     neg_grp = merged[feature].loc[merged['sentiment'] == \"NEGATIVE\"]\n\n#     print(pos_grp.shape, neg_grp.shape)\n#     print(pos_grp.describe(), neg_grp.describe())\n\n#     return stats.ttest_ind(pos_grp, neg_grp)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.961788Z","iopub.status.idle":"2023-08-11T19:04:08.962529Z","shell.execute_reply.started":"2023-08-11T19:04:08.962312Z","shell.execute_reply":"2023-08-11T19:04:08.962335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ttest_ind('boxOffice')","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.964006Z","iopub.status.idle":"2023-08-11T19:04:08.965212Z","shell.execute_reply.started":"2023-08-11T19:04:08.964856Z","shell.execute_reply":"2023-08-11T19:04:08.964889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ttest_ind('runtimeMinutes')","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.967319Z","iopub.status.idle":"2023-08-11T19:04:08.968405Z","shell.execute_reply.started":"2023-08-11T19:04:08.968085Z","shell.execute_reply":"2023-08-11T19:04:08.968115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ttest_ind('audienceScore')","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.970193Z","iopub.status.idle":"2023-08-11T19:04:08.971364Z","shell.execute_reply.started":"2023-08-11T19:04:08.970978Z","shell.execute_reply":"2023-08-11T19:04:08.971013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sns.boxplot(x=merged['sentiment'], y=merged['boxOffice'])","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.972851Z","iopub.status.idle":"2023-08-11T19:04:08.973669Z","shell.execute_reply.started":"2023-08-11T19:04:08.973447Z","shell.execute_reply":"2023-08-11T19:04:08.973469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <div id='genre_analysis'>Genre analysis</div>","metadata":{}},{"cell_type":"code","source":"# genre_analysis = merged[[\"genre\", \"genreSorted\", \"sentiment\"]].copy()\n# # print(genre_analysis.head())\n# # genre_analysis[\"genre\"] = genre_analysis[\"genre\"].apply(lambda x: (\",\").join(sorted(x.split(\", \"))))\n# genre_analysis.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.975349Z","iopub.status.idle":"2023-08-11T19:04:08.976305Z","shell.execute_reply.started":"2023-08-11T19:04:08.975936Z","shell.execute_reply":"2023-08-11T19:04:08.976005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cvec_g = CountVectorizer(ngram_range=(1,3))\n# cvec_g.fit(genre_analysis['genre'])\n# # len(cvec_g.vocabulary_), cvec_g.vocabulary_","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.978693Z","iopub.status.idle":"2023-08-11T19:04:08.980060Z","shell.execute_reply.started":"2023-08-11T19:04:08.979682Z","shell.execute_reply":"2023-08-11T19:04:08.979723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cvec_gSorted = CountVectorizer(ngram_range=(1,3))\n# cvec_gSorted.fit(genre_analysis['genreSorted'])\n# len(cvec_gSorted.vocabulary_), cvec_gSorted.vocabulary_","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.981801Z","iopub.status.idle":"2023-08-11T19:04:08.982816Z","shell.execute_reply.started":"2023-08-11T19:04:08.982513Z","shell.execute_reply":"2023-08-11T19:04:08.982537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# genre_testing = cvec_g.transform(merged[\"genre\"])\n# # print(genre_testing)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.984694Z","iopub.status.idle":"2023-08-11T19:04:08.985509Z","shell.execute_reply.started":"2023-08-11T19:04:08.985202Z","shell.execute_reply":"2023-08-11T19:04:08.985229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# genre_counts_testing = merged[[\"genre\", \"sentiment\"]].copy()\n# genre_counts_testing[\"gCount\"] = genre_counts_testing.apply(lambda x: len(str(x[\"genre\"]).split()), axis=1)\n# genre_counts_testing","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.987090Z","iopub.status.idle":"2023-08-11T19:04:08.988170Z","shell.execute_reply.started":"2023-08-11T19:04:08.987840Z","shell.execute_reply":"2023-08-11T19:04:08.987872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sns.boxplot(y=genre_counts_testing[\"gCount\"], x=genre_counts_testing[\"sentiment\"])","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.989668Z","iopub.status.idle":"2023-08-11T19:04:08.990288Z","shell.execute_reply.started":"2023-08-11T19:04:08.989973Z","shell.execute_reply":"2023-08-11T19:04:08.989999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sns.boxplot(y=merged[\"reviewWC\"], x=merged[\"sentiment\"])","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.991836Z","iopub.status.idle":"2023-08-11T19:04:08.993131Z","shell.execute_reply.started":"2023-08-11T19:04:08.992794Z","shell.execute_reply":"2023-08-11T19:04:08.992825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# audienceScore bins\n# asc = merged[['audienceScore', 'sentiment']].copy()\n# asc.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.995089Z","iopub.status.idle":"2023-08-11T19:04:08.995678Z","shell.execute_reply.started":"2023-08-11T19:04:08.995375Z","shell.execute_reply":"2023-08-11T19:04:08.995400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Binning numerical features  \n\n# print(merged[\"runtimeBins\"].value_counts())\n# sns.displot(merged[\"runtimeBins\"])","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:08.998082Z","iopub.status.idle":"2023-08-11T19:04:08.999052Z","shell.execute_reply.started":"2023-08-11T19:04:08.998723Z","shell.execute_reply":"2023-08-11T19:04:08.998753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Chi-square test for isFrequentReviewer column and sentiment column   \n\n# contingency_table = pd.crosstab(traindf['isFrequentReviewer'], traindf['sentiment'])\n# print(contingency_table)\n# stats.chi2_contingency(contingency_table)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.000731Z","iopub.status.idle":"2023-08-11T19:04:09.001609Z","shell.execute_reply.started":"2023-08-11T19:04:09.001302Z","shell.execute_reply":"2023-08-11T19:04:09.001331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Baseline performance of 'reviewText' column  ","metadata":{}},{"cell_type":"code","source":"# rt_dict = {'txt': ['reviewText']}\n# rt_dict","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.003352Z","iopub.status.idle":"2023-08-11T19:04:09.004290Z","shell.execute_reply.started":"2023-08-11T19:04:09.003990Z","shell.execute_reply":"2023-08-11T19:04:09.004018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit_v4(selected_model=LogisticRegression(C=5, solver=\"saga\", max_iter=100000),\n#           selected_features=rt_dict,\n#           param_grid=None,\n#           vocab=None)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.006111Z","iopub.status.idle":"2023-08-11T19:04:09.007111Z","shell.execute_reply.started":"2023-08-11T19:04:09.006752Z","shell.execute_reply":"2023-08-11T19:04:09.006790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## RFE  ","metadata":{}},{"cell_type":"code","source":"# def fs_rfe(selector, text_df, labels, ngram_range=(1,1)):\n#     text_df_ngram = TfidfVectorizer(ngram_range=ngram_range, stop_words='english').fit_transform(text_df)\n#     print(\"text_df was vectorized using TF-IDF vectorizer with ngram_range: \", ngram_range)\n#     print(\"text_df.shape: \", text_df.shape)\n#     print(\"labels.shape: \", labels.shape)\n#     print(\"text_df_ngram.shape: \", text_df_ngram.shape)\n#     print()\n\n#     print(\"Starting RFE fit...\")\n#     selector.fit(text_df_ngram, labels)\n#     print(\"RFE fit complete.\\n\")\n    \n#     print(\"selector.n_features_: \", selector.n_features_)   \n#     print(\"selector.n_features_in_: \", selector.n_features_in_)\n#     print(\"selector.support_.shape: \", selector.support_.shape)\n\n#     return selector.support_","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.009161Z","iopub.status.idle":"2023-08-11T19:04:09.010124Z","shell.execute_reply.started":"2023-08-11T19:04:09.009814Z","shell.execute_reply":"2023-08-11T19:04:09.009835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`RFE for unigrams`  ","metadata":{}},{"cell_type":"code","source":"# estimator_rfe_1 = LogisticRegression(solver='saga', max_iter=100000)\n# selector_rfe_1 = RFE(estimator_rfe_1, step=0.1, n_features_to_select=30000)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.012107Z","iopub.status.idle":"2023-08-11T19:04:09.012842Z","shell.execute_reply.started":"2023-08-11T19:04:09.012618Z","shell.execute_reply":"2023-08-11T19:04:09.012639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rfe_1_feat_mask = fs_rfe(selector_rfe_1, rt_senti[\"reviewText\"], rt_senti[\"sentiment\"], ngram_range=(1,1))\n# rfe_1_feat_mask","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.014245Z","iopub.status.idle":"2023-08-11T19:04:09.015034Z","shell.execute_reply.started":"2023-08-11T19:04:09.014761Z","shell.execute_reply":"2023-08-11T19:04:09.014783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# voc_1gram_rfe = list(compress(voc_1gram, rfe_1_feat_mask))\n# len(voc_1gram_rfe), voc_1gram_rfe[:10]","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.016520Z","iopub.status.idle":"2023-08-11T19:04:09.017011Z","shell.execute_reply.started":"2023-08-11T19:04:09.016753Z","shell.execute_reply":"2023-08-11T19:04:09.016774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`RFE for bigrams`  ","metadata":{}},{"cell_type":"code","source":"# estimator_rfe_2 = LogisticRegression(solver='saga', max_iter=100000)\n# selector_rfe_2 = RFE(estimator_rfe_2, step=0.1, n_features_to_select=50000)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.018251Z","iopub.status.idle":"2023-08-11T19:04:09.018676Z","shell.execute_reply.started":"2023-08-11T19:04:09.018473Z","shell.execute_reply":"2023-08-11T19:04:09.018493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rfe_2_feat_mask = fs_rfe(selector_rfe_2, rt_senti[\"reviewText\"], rt_senti[\"sentiment\"], ngram_range=(2,2))\n# rfe_2_feat_mask","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.021463Z","iopub.status.idle":"2023-08-11T19:04:09.022720Z","shell.execute_reply.started":"2023-08-11T19:04:09.022190Z","shell.execute_reply":"2023-08-11T19:04:09.022220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# voc_2gram_rfe = list(compress(voc_2gram, rfe_2_feat_mask))\n# len(voc_2gram_rfe), voc_2gram_rfe[:10]","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.024677Z","iopub.status.idle":"2023-08-11T19:04:09.028856Z","shell.execute_reply.started":"2023-08-11T19:04:09.028395Z","shell.execute_reply":"2023-08-11T19:04:09.028429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Final RFE-derived vocabulary  ","metadata":{}},{"cell_type":"code","source":"# rfe_vocab = voc_1gram_rfe + voc_2gram_rfe\n# len(rfe_vocab), rfe_vocab[:10], rfe_vocab[-10:]","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.030389Z","iopub.status.idle":"2023-08-11T19:04:09.031363Z","shell.execute_reply.started":"2023-08-11T19:04:09.031024Z","shell.execute_reply":"2023-08-11T19:04:09.031055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Test RFE obtained vocabulary in final pipeline (only with reviewText)  \n# submit_v4(selected_model=LogisticRegression(C=5, solver=\"saga\", max_iter=100000),\n#           selected_features=rt_dict,\n#           param_grid=None,\n#           vocab=rfe_vocab)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.035943Z","iopub.status.idle":"2023-08-11T19:04:09.038012Z","shell.execute_reply.started":"2023-08-11T19:04:09.037465Z","shell.execute_reply":"2023-08-11T19:04:09.037505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Use rfe_vocab in final pipeline with all params  ","metadata":{}},{"cell_type":"code","source":"# submit_v4(selected_model=LogisticRegression(max_iter=100000),\n#           selected_features=all_dict,\n#           param_grid=param_grid,\n#           vocab=rfe_vocab)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.040357Z","iopub.status.idle":"2023-08-11T19:04:09.041057Z","shell.execute_reply.started":"2023-08-11T19:04:09.040721Z","shell.execute_reply":"2023-08-11T19:04:09.040753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adc = AdaBoostClassifier(estimator=LogisticRegression(C=5, solver=\"saga\", max_iter=100000), n_estimators=50)\nadc","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.042618Z","iopub.status.idle":"2023-08-11T19:04:09.043099Z","shell.execute_reply.started":"2023-08-11T19:04:09.042856Z","shell.execute_reply":"2023-08-11T19:04:09.042875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit_v4(selected_model=adc,\n#           selected_features={'cat': ['isFrequentReviewer']},\n#           param_grid=None,\n#           vocab=rfe_vocab)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.044444Z","iopub.status.idle":"2023-08-11T19:04:09.045258Z","shell.execute_reply.started":"2023-08-11T19:04:09.045035Z","shell.execute_reply":"2023-08-11T19:04:09.045057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# AdaBoost on all features with RFE vocab on reviewText\n\n# submit_v4(selected_model=adc,\n#           selected_features=all_dict,\n#           param_grid=None,\n#           vocab=rfe_vocab)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.046962Z","iopub.status.idle":"2023-08-11T19:04:09.047496Z","shell.execute_reply.started":"2023-08-11T19:04:09.047205Z","shell.execute_reply":"2023-08-11T19:04:09.047225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RandomForestClassifier test run on one feature\n\n# rfc_2 = RandomForestClassifier()\n# rfc_2","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.049127Z","iopub.status.idle":"2023-08-11T19:04:09.049589Z","shell.execute_reply.started":"2023-08-11T19:04:09.049362Z","shell.execute_reply":"2023-08-11T19:04:09.049383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit_v4(selected_model=rfc_2,\n#           selected_features={'txt': ['reviewerName']},\n#           param_grid=None,\n#           vocab=rfe_vocab)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.051130Z","iopub.status.idle":"2023-08-11T19:04:09.051624Z","shell.execute_reply.started":"2023-08-11T19:04:09.051361Z","shell.execute_reply":"2023-08-11T19:04:09.051381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RandomForestClassifier on all features with RFE vocab on reviewText\n\n# submit_v4(selected_model=rfc_2,\n#           selected_features=all_dict,\n#           param_grid=None,\n#           vocab=rfe_vocab)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.056047Z","iopub.status.idle":"2023-08-11T19:04:09.056543Z","shell.execute_reply.started":"2023-08-11T19:04:09.056328Z","shell.execute_reply":"2023-08-11T19:04:09.056349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submit_v2 for merged file models  ","metadata":{}},{"cell_type":"code","source":"# def submit_v2(selected_model=pipe_final, selected_features=None):\n#     '''\n#     Note that \"selected_preprocessor\" is already used within selected_model or pipeline\n#     '''\n#     # Retrain on the whole train.csv file  \n#     merged = select_features(load_csv(\"train\"), load_csv(\"movies\"))\n#     X_train = merged.drop(labels=\"sentiment\", axis=1)\n#     y_train = merged[\"sentiment\"]\n    \n#     #Use selected features\n#     if selected_features:\n#         X_train = X_train[selected_features]\n    \n#     # Check1\n#     print(X_train.shape)\n#     print(X_train.head())\n#     try:\n#         print(selected_model.named_steps['model'].intercept_, selected_model.named_steps['model'].coef_)\n#     except:\n#         print(\"Model not trained yet!\")\n    \n#     # Fit \n#     selected_model.fit(X_train, y_train)\n    \n#     # Check2\n#     print(selected_model.named_steps['model'].intercept_, selected_model.named_steps['model'].coef_)\n    \n#     # Predict on test.csv file\n#     merged_test = select_features(load_csv(\"test\"), load_csv(\"movies\"))\n#     X_test = merged_test.copy()\n#     if selected_features:\n#         X_test = X_test[selected_features]\n    \n#     # Check3\n#     print(X_test.shape)\n#     print(X_test.head())\n    \n#     y_pred = selected_model.predict(X_test)\n    \n#     pred_df = pd.DataFrame(y_pred)\n#     pred_df.columns = [\"sentiment\"]\n#     pred_df.index.name = \"id\"\n#     pred_df.to_csv(\"submission.csv\")\n    \n#     return \"Successfully created the submission file!!!\"","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.057709Z","iopub.status.idle":"2023-08-11T19:04:09.058181Z","shell.execute_reply.started":"2023-08-11T19:04:09.057958Z","shell.execute_reply":"2023-08-11T19:04:09.057978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#     X_test = merged_test.copy()\n    \n#     y_pred = pipe_best4.predict(X_test)\n# #     np.unique(y_pred, return_counts=True)\n#     pred_df = pd.DataFrame(y_pred)\n#     pred_df.columns = [\"sentiment\"]\n#     pred_df.index.name = \"id\"\n#     pred_df.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.059731Z","iopub.status.idle":"2023-08-11T19:04:09.060181Z","shell.execute_reply.started":"2023-08-11T19:04:09.059963Z","shell.execute_reply":"2023-08-11T19:04:09.059983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_test.columns","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.062431Z","iopub.status.idle":"2023-08-11T19:04:09.062829Z","shell.execute_reply.started":"2023-08-11T19:04:09.062638Z","shell.execute_reply":"2023-08-11T19:04:09.062655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Uncomment to submit using v2 of submit function  ","metadata":{}},{"cell_type":"code","source":"# best4 = [\"audienceScore\", \"rating\", \"isFrequentReviewer\", \"reviewText\"]\n# best4","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.064135Z","iopub.status.idle":"2023-08-11T19:04:09.064547Z","shell.execute_reply.started":"2023-08-11T19:04:09.064355Z","shell.execute_reply":"2023-08-11T19:04:09.064373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit_v2(selected_model=pipe_RTonly, selected_features=['reviewText'])","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.065724Z","iopub.status.idle":"2023-08-11T19:04:09.066163Z","shell.execute_reply.started":"2023-08-11T19:04:09.065957Z","shell.execute_reply":"2023-08-11T19:04:09.065975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inspect the submission.csv file  ","metadata":{}},{"cell_type":"code","source":"# sub = pd.read_csv('submission.csv')\n# sub.shape, sub.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.067779Z","iopub.status.idle":"2023-08-11T19:04:09.068241Z","shell.execute_reply.started":"2023-08-11T19:04:09.068012Z","shell.execute_reply":"2023-08-11T19:04:09.068032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub['sentiment'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.070401Z","iopub.status.idle":"2023-08-11T19:04:09.070940Z","shell.execute_reply.started":"2023-08-11T19:04:09.070707Z","shell.execute_reply":"2023-08-11T19:04:09.070727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## submit_v3 for merged file models - does not retrain on whole data  ","metadata":{}},{"cell_type":"code","source":"# def submit_v3(selected_model=pipe_final):\n#     '''\n#     Note that \"selected_preprocessor\" is already used within selected_model or pipeline\n#     '''\n      \n#     # Predict on test.csv file\n#     merged_test = select_features(load_csv(\"test\"), load_csv(\"movies\"))\n#     X_test = merged_test.copy()\n    \n#     X_test = X_test[[\"audienceScore\", \"rating\", \"isFrequentReviewer\", \"reviewText\"]]    # This is a new line\n\n    \n#     y_pred = selected_model.predict(X_test)\n    \n#     pred_df = pd.DataFrame(y_pred)\n#     pred_df.columns = [\"sentiment\"]\n#     pred_df.index.name = \"id\"\n#     pred_df.to_csv(\"submission.csv\")\n    \n#     return \"Successfully created the submission file!!!\"","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.072456Z","iopub.status.idle":"2023-08-11T19:04:09.072972Z","shell.execute_reply.started":"2023-08-11T19:04:09.072739Z","shell.execute_reply":"2023-08-11T19:04:09.072759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Uncomment to submit using v3 of submit function  ","metadata":{}},{"cell_type":"code","source":"# submit_v3(selected_model=pipe_best4)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.074033Z","iopub.status.idle":"2023-08-11T19:04:09.074450Z","shell.execute_reply.started":"2023-08-11T19:04:09.074249Z","shell.execute_reply":"2023-08-11T19:04:09.074269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Rough work  ","metadata":{}},{"cell_type":"code","source":"    # Predict on test.csv file\n    merged_test = select_features(load_csv(\"test\"), load_csv(\"movies\"))\n    X_test = merged_test.copy()\n    \n    X_test = X_test[[\"audienceScore\", \"rating\", \"isFrequentReviewer\", \"reviewText\"]]    # This is a new line","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.075539Z","iopub.status.idle":"2023-08-11T19:04:09.075983Z","shell.execute_reply.started":"2023-08-11T19:04:09.075752Z","shell.execute_reply":"2023-08-11T19:04:09.075771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.077567Z","iopub.status.idle":"2023-08-11T19:04:09.078154Z","shell.execute_reply.started":"2023-08-11T19:04:09.077835Z","shell.execute_reply":"2023-08-11T19:04:09.077859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_test['audienceScore'].describe()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.080104Z","iopub.status.idle":"2023-08-11T19:04:09.080664Z","shell.execute_reply.started":"2023-08-11T19:04:09.080383Z","shell.execute_reply":"2023-08-11T19:04:09.080409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_test['rating'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.082430Z","iopub.status.idle":"2023-08-11T19:04:09.083036Z","shell.execute_reply.started":"2023-08-11T19:04:09.082715Z","shell.execute_reply":"2023-08-11T19:04:09.082741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_test['isFrequentReviewer'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.084977Z","iopub.status.idle":"2023-08-11T19:04:09.085573Z","shell.execute_reply.started":"2023-08-11T19:04:09.085282Z","shell.execute_reply":"2023-08-11T19:04:09.085308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Implement KNN classifier  ","metadata":{}},{"cell_type":"code","source":"# from sklearn.neighbors import KNeighborsClassifier","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.087362Z","iopub.status.idle":"2023-08-11T19:04:09.087955Z","shell.execute_reply.started":"2023-08-11T19:04:09.087650Z","shell.execute_reply":"2023-08-11T19:04:09.087676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Note that we are borrowing \"ct_final\" column transformer from above  ","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.089567Z","iopub.status.idle":"2023-08-11T19:04:09.090189Z","shell.execute_reply.started":"2023-08-11T19:04:09.089865Z","shell.execute_reply":"2023-08-11T19:04:09.089909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pipe_knn = Pipeline(steps=[\n#                         (\"preprocessor\", ct_final),\n#                         (\"model\", KNeighborsClassifier())\n#                     ])\n# pipe_knn","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.091800Z","iopub.status.idle":"2023-08-11T19:04:09.092446Z","shell.execute_reply.started":"2023-08-11T19:04:09.092145Z","shell.execute_reply":"2023-08-11T19:04:09.092173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train and predict on merged training data  \n# split_train_predict(merged_train_features, merged_train_labels, pipe_knn, test_size=0.25, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.094163Z","iopub.status.idle":"2023-08-11T19:04:09.094758Z","shell.execute_reply.started":"2023-08-11T19:04:09.094453Z","shell.execute_reply":"2023-08-11T19:04:09.094480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part I (Older code)  ","metadata":{}},{"cell_type":"markdown","source":"### Logistic Regression with stop words  ","metadata":{"papermill":{"duration":0.013226,"end_time":"2023-06-05T20:36:39.503219","exception":false,"start_time":"2023-06-05T20:36:39.489993","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# tvec_sw = TfidfVectorizer(stop_words=stop_words)","metadata":{"papermill":{"duration":0.020254,"end_time":"2023-06-05T20:36:39.536710","exception":false,"start_time":"2023-06-05T20:36:39.516456","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:04:09.096645Z","iopub.status.idle":"2023-08-11T19:04:09.097177Z","shell.execute_reply.started":"2023-08-11T19:04:09.096945Z","shell.execute_reply":"2023-08-11T19:04:09.096977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# logreg_sw_pipe = preprocess_n_train(X_train, y_train, tvec_sw, logreg)\n# logreg_sw_pipe","metadata":{"papermill":{"duration":0.020434,"end_time":"2023-06-05T20:36:39.570928","exception":false,"start_time":"2023-06-05T20:36:39.550494","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:04:09.098870Z","iopub.status.idle":"2023-08-11T19:04:09.099303Z","shell.execute_reply.started":"2023-08-11T19:04:09.099096Z","shell.execute_reply":"2023-08-11T19:04:09.099122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_pred_logreg_sw = predict_n_evaluate(logreg_sw_pipe, X_test, y_test)\n# y_pred_logreg_sw","metadata":{"papermill":{"duration":0.019379,"end_time":"2023-06-05T20:36:39.603838","exception":false,"start_time":"2023-06-05T20:36:39.584459","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:04:09.100546Z","iopub.status.idle":"2023-08-11T19:04:09.100978Z","shell.execute_reply.started":"2023-08-11T19:04:09.100750Z","shell.execute_reply":"2023-08-11T19:04:09.100768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Logistic regression with different ngram ranges  ","metadata":{"papermill":{"duration":0.013351,"end_time":"2023-06-05T20:36:39.630832","exception":false,"start_time":"2023-06-05T20:36:39.617481","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# tvec_ngram_2 = TfidfVectorizer(ngram_range=(1,2))","metadata":{"papermill":{"duration":0.019472,"end_time":"2023-06-05T20:36:39.690553","exception":false,"start_time":"2023-06-05T20:36:39.671081","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:04:09.102334Z","iopub.status.idle":"2023-08-11T19:04:09.102729Z","shell.execute_reply.started":"2023-08-11T19:04:09.102529Z","shell.execute_reply":"2023-08-11T19:04:09.102547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# logreg_ng2_pipe = preprocess_n_train(X_train, y_train, tvec_ngram_2, logreg)\n# logreg_ng2_pipe","metadata":{"papermill":{"duration":0.02033,"end_time":"2023-06-05T20:36:39.724467","exception":false,"start_time":"2023-06-05T20:36:39.704137","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:04:09.104010Z","iopub.status.idle":"2023-08-11T19:04:09.104481Z","shell.execute_reply.started":"2023-08-11T19:04:09.104211Z","shell.execute_reply":"2023-08-11T19:04:09.104229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_pred_logreg_ng2 = predict_n_evaluate(logreg_ng2_pipe, X_test, y_test)\n# y_pred_logreg_ng2","metadata":{"papermill":{"duration":0.020093,"end_time":"2023-06-05T20:36:39.758320","exception":false,"start_time":"2023-06-05T20:36:39.738227","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:04:09.105539Z","iopub.status.idle":"2023-08-11T19:04:09.105996Z","shell.execute_reply.started":"2023-08-11T19:04:09.105780Z","shell.execute_reply":"2023-08-11T19:04:09.105799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Logistic regression with C=2, ngram range (1,2), stop words as None and min_df, max_df adjusted\n### Class weight balanced","metadata":{"papermill":{"duration":0.013408,"end_time":"2023-06-05T20:36:39.786183","exception":false,"start_time":"2023-06-05T20:36:39.772775","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# logreg = LogisticRegression(max_iter=100000, C=2, class_weight=\"balanced\")","metadata":{"papermill":{"duration":0.020532,"end_time":"2023-06-05T20:36:39.820442","exception":false,"start_time":"2023-06-05T20:36:39.799910","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:04:09.107086Z","iopub.status.idle":"2023-08-11T19:04:09.107471Z","shell.execute_reply.started":"2023-08-11T19:04:09.107282Z","shell.execute_reply":"2023-08-11T19:04:09.107299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tvec_ngram_2_sw_df = TfidfVectorizer(ngram_range=(1,2), stop_words=None, min_df=0.0001, max_df=0.50)\n# tvec_ngram_2_sw_df","metadata":{"papermill":{"duration":0.023793,"end_time":"2023-06-05T20:36:39.857749","exception":false,"start_time":"2023-06-05T20:36:39.833956","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:04:09.108873Z","iopub.status.idle":"2023-08-11T19:04:09.109331Z","shell.execute_reply.started":"2023-08-11T19:04:09.109132Z","shell.execute_reply":"2023-08-11T19:04:09.109155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# logreg_ng2_sw_df_pipe = preprocess_n_train(X_train, y_train, tvec_ngram_2_sw_df, logreg)\n# logreg_ng2_sw_df_pipe","metadata":{"papermill":{"duration":17.521448,"end_time":"2023-06-05T20:36:57.393178","exception":false,"start_time":"2023-06-05T20:36:39.871730","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:04:09.110427Z","iopub.status.idle":"2023-08-11T19:04:09.110909Z","shell.execute_reply.started":"2023-08-11T19:04:09.110702Z","shell.execute_reply":"2023-08-11T19:04:09.110721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_pred_logreg_ng2_sw_df = predict_n_evaluate(logreg_ng2_sw_df_pipe, X_test, y_test)\n# y_pred_logreg_ng2_sw_df","metadata":{"papermill":{"duration":3.1684,"end_time":"2023-06-05T20:37:00.590780","exception":false,"start_time":"2023-06-05T20:36:57.422380","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-11T19:04:09.112360Z","iopub.status.idle":"2023-08-11T19:04:09.112745Z","shell.execute_reply.started":"2023-08-11T19:04:09.112551Z","shell.execute_reply":"2023-08-11T19:04:09.112576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Log reg with parameters from GridSearchCV  \n\n`This is the best score with \"reviewText column alone for analysis`  ","metadata":{}},{"cell_type":"code","source":"logreg_cv1 = LogisticRegression(max_iter=100000, C=10)\ntvec_cv1 = TfidfVectorizer(max_features=None, ngram_range=(1,2))","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.113856Z","iopub.status.idle":"2023-08-11T19:04:09.114242Z","shell.execute_reply.started":"2023-08-11T19:04:09.114059Z","shell.execute_reply":"2023-08-11T19:04:09.114077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe_cv1 = Pipeline(steps=[\n    (\"preprocessor\", tvec_cv1),\n    (\"model\", logreg_cv1)\n])","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.116202Z","iopub.status.idle":"2023-08-11T19:04:09.116597Z","shell.execute_reply.started":"2023-08-11T19:04:09.116407Z","shell.execute_reply":"2023-08-11T19:04:09.116424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pipe_cv1.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.117631Z","iopub.status.idle":"2023-08-11T19:04:09.118030Z","shell.execute_reply.started":"2023-08-11T19:04:09.117828Z","shell.execute_reply":"2023-08-11T19:04:09.117845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pipe_cv1.score(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.119861Z","iopub.status.idle":"2023-08-11T19:04:09.120335Z","shell.execute_reply.started":"2023-08-11T19:04:09.120117Z","shell.execute_reply":"2023-08-11T19:04:09.120146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### SVM model with stop words  ","metadata":{}},{"cell_type":"code","source":"# svm_sw_pipe = preprocess_n_train(X_train, y_train, tvec_sw, svm)\n# svm_sw_pipe","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.121484Z","iopub.status.idle":"2023-08-11T19:04:09.121933Z","shell.execute_reply.started":"2023-08-11T19:04:09.121704Z","shell.execute_reply":"2023-08-11T19:04:09.121722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_pred_svm_sw = predict_n_evaluate(svm_sw_pipe, X_test, y_test)\n# y_pred_svm_sw","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.123696Z","iopub.status.idle":"2023-08-11T19:04:09.124157Z","shell.execute_reply.started":"2023-08-11T19:04:09.123948Z","shell.execute_reply":"2023-08-11T19:04:09.123969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### GaussianNB  ","metadata":{}},{"cell_type":"markdown","source":"https://stackoverflow.com/questions/28384680/scikit-learns-pipeline-a-sparse-matrix-was-passed-but-dense-data-is-required","metadata":{}},{"cell_type":"code","source":"# gnb = GaussianNB()\n# gnb","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.125675Z","iopub.status.idle":"2023-08-11T19:04:09.126147Z","shell.execute_reply.started":"2023-08-11T19:04:09.125929Z","shell.execute_reply":"2023-08-11T19:04:09.125953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gnb_pipe = preprocess_n_train(X_train, y_train, tvec, gnb)\n# gnb_pipe","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.127143Z","iopub.status.idle":"2023-08-11T19:04:09.127532Z","shell.execute_reply.started":"2023-08-11T19:04:09.127344Z","shell.execute_reply":"2023-08-11T19:04:09.127362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part II (Older code)  \n","metadata":{}},{"cell_type":"markdown","source":"### Separate features and labels from merged dataset  ","metadata":{}},{"cell_type":"code","source":"# merged_train_features = merged[['movieid', 'reviewerName', 'isFrequentReviewer', 'reviewText',\n#        'audienceScore', 'rating', 'runtimeMinutes', 'genre',\n#        'originalLanguage', 'director']]\n# merged_train_features.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.137315Z","iopub.status.idle":"2023-08-11T19:04:09.138030Z","shell.execute_reply.started":"2023-08-11T19:04:09.137677Z","shell.execute_reply":"2023-08-11T19:04:09.137712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merged_train_labels = merged[\"sentiment\"]\n# merged_train_labels.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.140002Z","iopub.status.idle":"2023-08-11T19:04:09.140613Z","shell.execute_reply.started":"2023-08-11T19:04:09.140309Z","shell.execute_reply":"2023-08-11T19:04:09.140344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Identify variable types for different preprocessing pipes  ","metadata":{}},{"cell_type":"code","source":"# num_vars = [\"audienceScore\", \"runtimeMinutes\"]\n# txt_vars = [\"originalLanguage\", \"genre\", \"director\", \"reviewerName\", \"reviewText\"]\n# cat_vars = [\"rating\", \"isFrequentReviewer\"]","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.142315Z","iopub.status.idle":"2023-08-11T19:04:09.142909Z","shell.execute_reply.started":"2023-08-11T19:04:09.142604Z","shell.execute_reply":"2023-08-11T19:04:09.142633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# num_pipe = Pipeline(steps=[\n#                             (\"imputer\", SimpleImputer(strategy=\"mean\", missing_values=np.nan)),\n#                             (\"scaler\", MinMaxScaler())\n#                         ])\n# num_pipe","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.144741Z","iopub.status.idle":"2023-08-11T19:04:09.145348Z","shell.execute_reply.started":"2023-08-11T19:04:09.145066Z","shell.execute_reply":"2023-08-11T19:04:09.145092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# txt_pipe = Pipeline(steps=[\n#                             (\"tvec\", TfidfVectorizer())\n#                         ])\n# txt_pipe","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.147262Z","iopub.status.idle":"2023-08-11T19:04:09.147682Z","shell.execute_reply.started":"2023-08-11T19:04:09.147473Z","shell.execute_reply":"2023-08-11T19:04:09.147491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cat_pipe = Pipeline(steps=[\n#                             (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n#                         ])\n# cat_pipe","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.155408Z","iopub.status.idle":"2023-08-11T19:04:09.155965Z","shell.execute_reply.started":"2023-08-11T19:04:09.155683Z","shell.execute_reply":"2023-08-11T19:04:09.155714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tfidf_vec_1 = TfidfVectorizer(ngram_range=(1,2))\n# tfidf_vec_1","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.157323Z","iopub.status.idle":"2023-08-11T19:04:09.157770Z","shell.execute_reply.started":"2023-08-11T19:04:09.157559Z","shell.execute_reply":"2023-08-11T19:04:09.157580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ct_final = ColumnTransformer(transformers=[\n#                                         (\"num\", num_pipe, num_vars),\n#                                         (\"txt1\", txt_pipe, \"originalLanguage\"),\n#                                         (\"txt2\", txt_pipe, \"genre\"),\n#                                         (\"txt3\", txt_pipe, \"director\"),\n#                                         (\"cat\", cat_pipe, cat_vars),\n#                                         (\"txt4a\", tfidf_vec_1, \"reviewText\")\n# #                                         (\"txt4\", TfidfVectorizer(ngram_range=(1,2)), \"reviewText\"),\n# #                                         (\"cat2\", cat_pipe, [\"isFrequentReviewer\"])\n#                                         ], remainder=\"drop\", n_jobs=1)\n\n# # Note that this transformer drops \"movieid\" column and \"reviewerName\" column  \n# ct_final","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.159585Z","iopub.status.idle":"2023-08-11T19:04:09.160098Z","shell.execute_reply.started":"2023-08-11T19:04:09.159843Z","shell.execute_reply":"2023-08-11T19:04:09.159864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pipe_final = Pipeline(steps=[\n#                         (\"preprocessor\", ct_final),\n#                         (\"model\", LogisticRegression(max_iter=100000))\n#                     ])\n# pipe_final","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.161947Z","iopub.status.idle":"2023-08-11T19:04:09.162401Z","shell.execute_reply.started":"2023-08-11T19:04:09.162191Z","shell.execute_reply":"2023-08-11T19:04:09.162211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final_vars = num_vars + txt_vars + cat_vars\n# len(final_vars), final_vars","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.164834Z","iopub.status.idle":"2023-08-11T19:04:09.165285Z","shell.execute_reply.started":"2023-08-11T19:04:09.165084Z","shell.execute_reply":"2023-08-11T19:04:09.165105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Use \"split_train_predict\" function to run end-to-end pipeline  ","metadata":{}},{"cell_type":"code","source":"# split_train_predict(merged_train_features, merged_train_labels, pipe_final, test_size=0.25, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.166382Z","iopub.status.idle":"2023-08-11T19:04:09.166840Z","shell.execute_reply.started":"2023-08-11T19:04:09.166625Z","shell.execute_reply":"2023-08-11T19:04:09.166646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Try the best four features obtained on local machine  ","metadata":{}},{"cell_type":"code","source":"# tfidf_vec_2 = TfidfVectorizer(ngram_range=(1,2))\n# tfidf_vec_2","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.168244Z","iopub.status.idle":"2023-08-11T19:04:09.168679Z","shell.execute_reply.started":"2023-08-11T19:04:09.168465Z","shell.execute_reply":"2023-08-11T19:04:09.168485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ct_best4 = ColumnTransformer(transformers=[\n#                                             (\"num\", num_pipe, [\"audienceScore\"]),\n#                                             (\"cat\", cat_pipe, [\"rating\", \"isFrequentReviewer\"]),\n#                                             (\"tvec\", tfidf_vec_2, \"reviewText\")\n#                             ])\n\n# pipe_best4 = Pipeline(steps=[\n#     (\"preprocessor\", ct_best4),\n#     (\"model\", LogisticRegression())\n# ])\n\n# pipe_best4.set_params(model__C=10, model__max_iter=100000)\n\n# pipe_best4","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.169864Z","iopub.status.idle":"2023-08-11T19:04:09.170320Z","shell.execute_reply.started":"2023-08-11T19:04:09.170113Z","shell.execute_reply":"2023-08-11T19:04:09.170133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split_train_predict(merged[[\"audienceScore\", \"rating\", \"isFrequentReviewer\", \"reviewText\"]], merged[\"sentiment\"], pipe_best4, test_size=0.25)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.171561Z","iopub.status.idle":"2023-08-11T19:04:09.172022Z","shell.execute_reply.started":"2023-08-11T19:04:09.171782Z","shell.execute_reply":"2023-08-11T19:04:09.171802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Try only 'reviewText' column  ","metadata":{}},{"cell_type":"code","source":"# tfidf_vec_3 = TfidfVectorizer(ngram_range=(1,2))\n# tfidf_vec_3","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.173542Z","iopub.status.idle":"2023-08-11T19:04:09.173982Z","shell.execute_reply.started":"2023-08-11T19:04:09.173754Z","shell.execute_reply":"2023-08-11T19:04:09.173773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ct_RTonly = ColumnTransformer(transformers=[\n#                                             ('txt', tfidf_vec_3, 'reviewText'),\n#                                             ], remainder='drop')\n# ct_RTonly","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.175375Z","iopub.status.idle":"2023-08-11T19:04:09.175793Z","shell.execute_reply.started":"2023-08-11T19:04:09.175585Z","shell.execute_reply":"2023-08-11T19:04:09.175604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pipe_RTonly = Pipeline(steps=[\n#     (\"preprocessor\", ct_RTonly),\n#     (\"model\", LogisticRegression())\n# ])\n\n# pipe_RTonly.set_params(model__C=10, model__max_iter=100000)\n\n# pipe_RTonly","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.177223Z","iopub.status.idle":"2023-08-11T19:04:09.177628Z","shell.execute_reply.started":"2023-08-11T19:04:09.177432Z","shell.execute_reply":"2023-08-11T19:04:09.177451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using the 'submit_v4' function  ","metadata":{}},{"cell_type":"markdown","source":"### Try the best 4 parameters with submit_v4 function","metadata":{}},{"cell_type":"code","source":"# best4 = [\"audienceScore\", \"rating\", \"isFrequentReviewer\", \"reviewText\"]\n\n# best4_dict = {'cat': [\"rating\", \"isFrequentReviewer\"],\n#              'num': [\"audienceScore\"],\n#              'txt': ['reviewText']}\n\n# best4_dict = {'num': [\"audienceScore\"],\n#              'txt': ['reviewText', 'movieid', 'director']}\n\n# best4_dict","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.179706Z","iopub.status.idle":"2023-08-11T19:04:09.180155Z","shell.execute_reply.started":"2023-08-11T19:04:09.179941Z","shell.execute_reply":"2023-08-11T19:04:09.179964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit_v4(selected_features=best4_dict)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.181870Z","iopub.status.idle":"2023-08-11T19:04:09.182311Z","shell.execute_reply.started":"2023-08-11T19:04:09.182107Z","shell.execute_reply":"2023-08-11T19:04:09.182127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Try the best 3 parameters with submit_v4 function","metadata":{}},{"cell_type":"code","source":"# best3 = [\"audienceScore\", \"isFrequentReviewer\", \"reviewText\"]\n# best3_dict = {'cat': [\"isFrequentReviewer\"],\n#              'num': [\"audienceScore\"],\n#              'txt': ['reviewText']}\n# best3_dict","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.183617Z","iopub.status.idle":"2023-08-11T19:04:09.184042Z","shell.execute_reply.started":"2023-08-11T19:04:09.183815Z","shell.execute_reply":"2023-08-11T19:04:09.183833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit_v4(selected_features=best3_dict)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.185060Z","iopub.status.idle":"2023-08-11T19:04:09.185470Z","shell.execute_reply.started":"2023-08-11T19:04:09.185274Z","shell.execute_reply":"2023-08-11T19:04:09.185293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Try throwing almost everything (no boxOffice) at submit_v4!  ","metadata":{}},{"cell_type":"code","source":"\"\"\"Most from merged = ['movieid', 'reviewerName', 'isFrequentReviewer', 'reviewText',\n       'audienceScore', 'rating', 'runtimeMinutes', 'genre', \n       'originalLanguage', 'director']\"\"\"\n\n# almost_dict = {'cat': [\"isFrequentReviewer\", \"rating\", \"originalLanguage\"],\n#              'num': [\"audienceScore\", \"runtimeMinutes\"],\n#              'txt': ['reviewText', 'reviewerName', 'movieid', 'genre', 'director']}\n# almost_dict","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.186867Z","iopub.status.idle":"2023-08-11T19:04:09.187317Z","shell.execute_reply.started":"2023-08-11T19:04:09.187109Z","shell.execute_reply":"2023-08-11T19:04:09.187128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit_v4(selected_features=almost_dict)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.189085Z","iopub.status.idle":"2023-08-11T19:04:09.189459Z","shell.execute_reply.started":"2023-08-11T19:04:09.189273Z","shell.execute_reply":"2023-08-11T19:04:09.189290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Try throwing everything possible at submit_v4!  ","metadata":{}},{"cell_type":"code","source":"\"\"\"All from merged = ['movieid', 'reviewerName', 'isFrequentReviewer', 'reviewText',\n       'audienceScore', 'rating', 'runtimeMinutes', 'genre', 'boxOffice',\n       'originalLanguage', 'director']\"\"\"\n\n# all_dict = {'cat': [\"isFrequentReviewer\", \"rating\", \"originalLanguage\"],\n#              'num': [\"audienceScore\", \"runtimeMinutes\", \"boxOffice\"],\n#              'txt': ['reviewText', 'reviewerName', 'movieid', 'genre', 'director']}\n# all_dict","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.190483Z","iopub.status.idle":"2023-08-11T19:04:09.190852Z","shell.execute_reply.started":"2023-08-11T19:04:09.190671Z","shell.execute_reply":"2023-08-11T19:04:09.190687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit_v4(selected_features=all_dict)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.192186Z","iopub.status.idle":"2023-08-11T19:04:09.192558Z","shell.execute_reply.started":"2023-08-11T19:04:09.192367Z","shell.execute_reply":"2023-08-11T19:04:09.192385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Try GridSearchCV on everything  ","metadata":{}},{"cell_type":"code","source":"# param_grid = {\n#     \"model__C\": [0.5, 2, 5, 15]\n# }\n\n# param_grid = {\n#     'model__C' : [1, 5],\n#     'model__solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n# }\n\n# param_grid = {\n#     'model__C' : [1, 5],\n#     'model__solver': ['lbfgs', 'liblinear', 'sag', 'saga']\n# }\n\n# param_grid = {\n#     'model__C' : [1, 5, 10, 15],\n#     'model__solver': ['lbfgs', 'liblinear', 'saga', 'newton-cg']\n# }\n\n# param_grid = {\n#     'model__C' : [1, 5, 10, 20],\n#     'model__solver': ['lbfgs', 'liblinear', 'saga']\n# }\n\n# param_grid","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.193952Z","iopub.status.idle":"2023-08-11T19:04:09.194322Z","shell.execute_reply.started":"2023-08-11T19:04:09.194139Z","shell.execute_reply":"2023-08-11T19:04:09.194156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit_v4(selected_features={'txt': [\"genre\"]}, param_grid=param_grid)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.197615Z","iopub.status.idle":"2023-08-11T19:04:09.198018Z","shell.execute_reply.started":"2023-08-11T19:04:09.197816Z","shell.execute_reply":"2023-08-11T19:04:09.197833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit_v4(selected_features=all_dict, param_grid=param_grid)\n\n# Best C was 5\n# Best solver was liblinear\n\n\"\"\"Used 'groupby' function instead on 'drop_duplicates' on movies.csv file. \nIt reduced the number of missing values significantly! \nThen used LogisticRegression() with GridSearchCV on submit_v4 function with \nparam_grid={'model__C': [1, 5, 10], 'model__solver': ['lbfgs', 'liblinear', 'saga']}. \nThe best f1_micro score in GridSearchCV was 0.8399771362056203 which is highest among \nall the versions so far. Best C was 5 and best solver was 'saga'.\nScore obtained was 0.84385 which is lower than 0.84441.\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.204243Z","iopub.status.idle":"2023-08-11T19:04:09.204690Z","shell.execute_reply.started":"2023-08-11T19:04:09.204476Z","shell.execute_reply":"2023-08-11T19:04:09.204494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Best 5 parameters\n\n# best5_dict = {'num': [\"audienceScore\"],\n#              'txt': ['reviewText', 'reviewerName','movieid', 'director']}\n\n# best5_dict","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.205821Z","iopub.status.idle":"2023-08-11T19:04:09.206221Z","shell.execute_reply.started":"2023-08-11T19:04:09.206033Z","shell.execute_reply":"2023-08-11T19:04:09.206051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Submit best 5 features\n\n\"\"\"(Update): Used both CountVectorizer and TfidfVectorizer on a massive GridSearchCV \nwhich took 22527.2s  (6.25 hrs) to run! Gave a score of 0.8439093822800923 locally and did not overfit!\nBest params: {'model__C': 1, 'model__solver': 'liblinear'}.\nHighest public score yet: 0.84591 (Rank up from 9 to 5!)\"\"\"\n\n# param_grid = {\n#     'model__C' : [5, 10, 15],\n#     'model__solver': ['lbfgs', 'liblinear', 'saga']\n# }\n\n\n# Try new param_grid with fit_intercept and dual in logreg\n\n# param_grid = {\n#     'model__C' : [1],\n#     'model__solver': ['liblinear'],\n#     \"model__fit_intercept\" : [True, False],\n#     \"model__dual\" : [True, False] \n# }\n\n\n# Local testing  \n# submit_v4(selected_features={'num': ['audienceScore']},\n#          add_countvec=True)\n\n# submit_v4(selected_features={'num': ['audienceScore']},\n#          add_countvec=True, \n#           param_grid=param_grid)\n\n\n# Main submission\n\n# submit_v4(selected_features=best5_dict,\n#          add_countvec=True)\n\n\n# submit_v4(selected_features=best5_dict,\n#           add_countvec=True,\n#           param_grid=param_grid)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.207420Z","iopub.status.idle":"2023-08-11T19:04:09.207800Z","shell.execute_reply.started":"2023-08-11T19:04:09.207608Z","shell.execute_reply":"2023-08-11T19:04:09.207632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## ALL DICT cv=10\n\n# all_dict = {'cat': [\"isFrequentReviewer\", \"rating\", \"originalLanguage\"],\n#              'num': [\"audienceScore\", \"runtimeMinutes\", \"boxOffice\"],\n#              'txt': ['reviewText', 'reviewerName', 'movieid', 'genre', 'director']}\n# print(all_dict)\n\n# param_grid = {\n#     'model__C' : [2, 5, 10],\n#     'model__solver': ['lbfgs', 'liblinear', 'saga']\n# }\n# print(param_grid)\n\n# param_grid = {\n#     'model__C' : [1, 5, 10],\n#     'model__solver': ['liblinear'],\n#     \"model__fit_intercept\" : [True, False],\n#     \"model__dual\" : [True, False] \n# }\n\n\n# Main submission\n\n# submit_v4(selected_model=LogisticRegression(C=5, solver='liblinear', max_iter=10000),\n#           selected_features=all_dict,\n#           param_grid=param_grid)\n\n# submit_v4(selected_features=all_dict,\n#           add_countvec=True,\n#           param_grid=param_grid)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.208878Z","iopub.status.idle":"2023-08-11T19:04:09.209257Z","shell.execute_reply.started":"2023-08-11T19:04:09.209076Z","shell.execute_reply":"2023-08-11T19:04:09.209093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Best 6 parameters\n\n# best6_dict = {'cat': [\"isFrequentReviewer\"],\n#              'num': [\"audienceScore\"],\n#              'txt': ['reviewText', 'reviewerName', 'genre', 'director']}\n\n# best6_dict = {'num': [\"audienceScore\"],\n#              'txt': ['reviewText', 'reviewerName', 'genre','movieid', 'director']}\n\n# best6_dict","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.210399Z","iopub.status.idle":"2023-08-11T19:04:09.210765Z","shell.execute_reply.started":"2023-08-11T19:04:09.210577Z","shell.execute_reply":"2023-08-11T19:04:09.210593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Submit best 6 features (version 2)\n\n# submit_v4(selected_features=best6_dict,\n#           param_grid=param_grid)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.212881Z","iopub.status.idle":"2023-08-11T19:04:09.213282Z","shell.execute_reply.started":"2023-08-11T19:04:09.213087Z","shell.execute_reply":"2023-08-11T19:04:09.213106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Best 7 parameters\n\n# best7_dict = {'cat': [\"isFrequentReviewer\"],\n#              'num': [\"audienceScore\"],\n#              'txt': ['reviewText', 'reviewerName', 'movieid', 'genre', 'director']}\n# best7_dict","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.214356Z","iopub.status.idle":"2023-08-11T19:04:09.214739Z","shell.execute_reply.started":"2023-08-11T19:04:09.214542Z","shell.execute_reply":"2023-08-11T19:04:09.214560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Submit best 7 features\n\n# submit_v4(selected_features=best7_dict,\n#           param_grid=param_grid)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.216748Z","iopub.status.idle":"2023-08-11T19:04:09.217164Z","shell.execute_reply.started":"2023-08-11T19:04:09.216957Z","shell.execute_reply":"2023-08-11T19:04:09.216975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit_v4(selected_features=best6_dict, param_grid=param_grid)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.218516Z","iopub.status.idle":"2023-08-11T19:04:09.218883Z","shell.execute_reply.started":"2023-08-11T19:04:09.218700Z","shell.execute_reply":"2023-08-11T19:04:09.218717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Try a new feature dict  \n\n","metadata":{}},{"cell_type":"code","source":"# all_dict_new = {'cat': [\"isFrequentReviewer\", \"rating\", \"originalLanguage\"],\n#              'num': [\"audienceScore\", \"runtimeMinutes\", \"boxOffice\"],\n#              'txt': ['reviewText', \"reviewerName\", 'movieid', 'genre', 'director']}\n# all_dict_new","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.220326Z","iopub.status.idle":"2023-08-11T19:04:09.220748Z","shell.execute_reply.started":"2023-08-11T19:04:09.220513Z","shell.execute_reply":"2023-08-11T19:04:09.220530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit_v4(selected_features={'txt': ['genre']}, param_grid=param_grid)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.221801Z","iopub.status.idle":"2023-08-11T19:04:09.222183Z","shell.execute_reply.started":"2023-08-11T19:04:09.222000Z","shell.execute_reply":"2023-08-11T19:04:09.222017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit_v4(selected_features=all_dict_new, param_grid=param_grid)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.223439Z","iopub.status.idle":"2023-08-11T19:04:09.223815Z","shell.execute_reply.started":"2023-08-11T19:04:09.223622Z","shell.execute_reply":"2023-08-11T19:04:09.223639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Try non-text based columns\n# num_cat_dict = {'cat': ['isFrequentReviewer', 'rating', 'originalLanguage'],\n#  'num': ['audienceScore', 'runtimeMinutes', 'boxOffice']}\n# num_cat_dict","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.225175Z","iopub.status.idle":"2023-08-11T19:04:09.225543Z","shell.execute_reply.started":"2023-08-11T19:04:09.225359Z","shell.execute_reply":"2023-08-11T19:04:09.225376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use num_cat_dict features\n# (Update): Gets a local score of 0.7027181356991726. Not great.\n# submit_v4(selected_model=LogisticRegression(max_iter=100000), selected_features=num_cat_dict, param_grid=param_grid)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.227478Z","iopub.status.idle":"2023-08-11T19:04:09.227860Z","shell.execute_reply.started":"2023-08-11T19:04:09.227673Z","shell.execute_reply":"2023-08-11T19:04:09.227690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Try data other than reviewText\n\n# mov_dict = {'cat': ['rating', 'originalLanguage'],\n#  'num': ['audienceScore', 'runtimeMinutes', 'boxOffice'],\n#  'txt': ['movieid', 'genre', 'director']}\n# mov_dict","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.229279Z","iopub.status.idle":"2023-08-11T19:04:09.229664Z","shell.execute_reply.started":"2023-08-11T19:04:09.229470Z","shell.execute_reply":"2023-08-11T19:04:09.229487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use mov_dict features\n# (Update): Gets a local score of 0.7475454316469369, which is not bad at all.\n# submit_v4(selected_model=LogisticRegression(max_iter=100000), selected_features=mov_dict, param_grid=param_grid)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.231004Z","iopub.status.idle":"2023-08-11T19:04:09.231383Z","shell.execute_reply.started":"2023-08-11T19:04:09.231194Z","shell.execute_reply":"2023-08-11T19:04:09.231211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Try a new column 'reviewYN'  \n\n","metadata":{}},{"cell_type":"code","source":"# all_dict_3 = {'cat': [\"isFrequentReviewer\", \"rating\", \"originalLanguage\", \"reviewYN\"],\n#              'num': [\"audienceScore\", \"runtimeMinutes\", \"boxOffice\"],\n#              'txt': ['reviewText', \"reviewerName\", 'movieid', 'genre', 'director']}\n# all_dict_3","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.232712Z","iopub.status.idle":"2023-08-11T19:04:09.233550Z","shell.execute_reply.started":"2023-08-11T19:04:09.233333Z","shell.execute_reply":"2023-08-11T19:04:09.233354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit_v4(selected_model=LogisticRegression(max_iter=100000),\n#          selected_features=all_dict_3, \n#           param_grid=param_grid)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.235213Z","iopub.status.idle":"2023-08-11T19:04:09.235599Z","shell.execute_reply.started":"2023-08-11T19:04:09.235410Z","shell.execute_reply":"2023-08-11T19:04:09.235428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### More GridSearchCV using LinearSVC  ","metadata":{}},{"cell_type":"code","source":"# param_grid_svc_2 = {\n#     'model__C': [1.0],\n#     'model__loss': ['hinge', 'squared_hinge'],\n#     'model__class_weight': ['balanced', None]\n# }\n# param_grid_svc_2","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.236823Z","iopub.status.idle":"2023-08-11T19:04:09.237263Z","shell.execute_reply.started":"2023-08-11T19:04:09.237056Z","shell.execute_reply":"2023-08-11T19:04:09.237076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit_v4(selected_model=LinearSVC(max_iter=100000, random_state=42), selected_features={'num': [\"audienceScore\"]}, param_grid=param_grid_svc_2)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.238717Z","iopub.status.idle":"2023-08-11T19:04:09.239155Z","shell.execute_reply.started":"2023-08-11T19:04:09.238946Z","shell.execute_reply":"2023-08-11T19:04:09.238965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit_v4(selected_model=LinearSVC(max_iter=100000, random_state=42), selected_features=all_dict, param_grid=param_grid_svc_2)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.240511Z","iopub.status.idle":"2023-08-11T19:04:09.240956Z","shell.execute_reply.started":"2023-08-11T19:04:09.240728Z","shell.execute_reply":"2023-08-11T19:04:09.240747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Boosting techniques  ","metadata":{}},{"cell_type":"code","source":"# adc = AdaBoostClassifier(estimator=LogisticRegression(C=5, solver=\"saga\", max_iter=100000), n_estimators=50)\n# adc","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.242304Z","iopub.status.idle":"2023-08-11T19:04:09.242669Z","shell.execute_reply.started":"2023-08-11T19:04:09.242486Z","shell.execute_reply":"2023-08-11T19:04:09.242503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit_v4(selected_model=adc, selected_features={'num': [\"audienceScore\"]}, param_grid=None)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.244658Z","iopub.status.idle":"2023-08-11T19:04:09.245350Z","shell.execute_reply.started":"2023-08-11T19:04:09.245138Z","shell.execute_reply":"2023-08-11T19:04:09.245160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit_v4(selected_model=adc, selected_features=all_dict, param_grid=None)\n\n# Took 1 hour 15 mins to run and gave a public score of only 0.71089. Discarded.","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.246911Z","iopub.status.idle":"2023-08-11T19:04:09.247475Z","shell.execute_reply.started":"2023-08-11T19:04:09.247189Z","shell.execute_reply":"2023-08-11T19:04:09.247214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### LightGBM  ","metadata":{}},{"cell_type":"code","source":"# lgb = ltb.LGBMClassifier()\n# lgb","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.249370Z","iopub.status.idle":"2023-08-11T19:04:09.250041Z","shell.execute_reply.started":"2023-08-11T19:04:09.249734Z","shell.execute_reply":"2023-08-11T19:04:09.249761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Try LightGBM with default settings\n# (Update): Public score only 0.77713. It was fast, took less than 5 mins (without GridSearchCV)\n\n# submit_v4(selected_model=ltb.LGBMClassifier(), selected_features=all_dict, param_grid=None)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.252391Z","iopub.status.idle":"2023-08-11T19:04:09.252790Z","shell.execute_reply.started":"2023-08-11T19:04:09.252598Z","shell.execute_reply":"2023-08-11T19:04:09.252616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Try feature selection and vocab fine tuning of reviewText column","metadata":{}},{"cell_type":"markdown","source":"## Plan  \n* Add a new column 'reviewWC' which has word count of 'reviewText'  \n    * Check if there is any relationship between 'reviewWC' and 'sentiment'\n* Work on vocabulary\n     * Use TfidfVectorizer and find out the vocabulary of 'reviewText' column for various ngrams\n     * Use RecursiveFeatureElimination (RFE) or RFECV to select 1000 top words/vocab for each ngram\n     * Use the final vocab (1000-3000 words) in the model and see how it performs compared to whole vocab\n","metadata":{}},{"cell_type":"code","source":"# 'reviewWC' and 'sentiment'\n# (Conclusion): 'reviewWC' is practically same as DummyClassifier (accuracy of 0.6682375059904889 on train data). It just predicts 'positive' for all columns\n\n# reviewWC_dict = {\"num\": [\"reviewWC\"]}\n# submit_v4(selected_model=LogisticRegression(),\n#          selected_features=reviewWC_dict,\n#          param_grid=None)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.254206Z","iopub.status.idle":"2023-08-11T19:04:09.254651Z","shell.execute_reply.started":"2023-08-11T19:04:09.254445Z","shell.execute_reply":"2023-08-11T19:04:09.254465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 'reviewYN' and 'sentiment'\n# (Conclusion): 'reviewYN' is practically same as DummyClassifier (accuracy of 0.6682375059904889 on train data). It just predicts 'positive' for all columns\n\n# reviewYN_dict = {\"cat\": [\"reviewYN\"]}\n# submit_v4(selected_model=LogisticRegression(),\n#          selected_features=reviewYN_dict,\n#          param_grid=None)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.256016Z","iopub.status.idle":"2023-08-11T19:04:09.256447Z","shell.execute_reply.started":"2023-08-11T19:04:09.256248Z","shell.execute_reply":"2023-08-11T19:04:09.256268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submissions using 'vocabulary' built from 'reviewText' data  ","metadata":{}},{"cell_type":"markdown","source":"### Submit best 6 features along with common vocab  ","metadata":{}},{"cell_type":"code","source":"# Best 6 parameters (version 2)  \n\n# best6_dict = {'num': [\"audienceScore\"],\n#              'txt': ['reviewText', 'reviewerName', 'genre','movieid', 'director']}\n\n# best6_dict","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.257656Z","iopub.status.idle":"2023-08-11T19:04:09.258105Z","shell.execute_reply.started":"2023-08-11T19:04:09.257866Z","shell.execute_reply":"2023-08-11T19:04:09.257886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Submit best 6 features (version 2) with common vocabulary (common_1_2_grams)\n# (Update): Score 0.82867\n\n# submit_v4(selected_features=best6_dict,\n#           param_grid=param_grid,\n#          vocab=common_1_2_grams)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.259925Z","iopub.status.idle":"2023-08-11T19:04:09.260337Z","shell.execute_reply.started":"2023-08-11T19:04:09.260135Z","shell.execute_reply":"2023-08-11T19:04:09.260162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Submit best 6 features (version 2) with common vocabulary (common_1_2_3_grams)\n# Note: for this submission submit_v4 function has to be modified: reviewText TfidfVectorizer must have ngram_range(1,3).\n# (Update): Score in the range 0.825+\n\n# submit_v4(selected_features=best6_dict,\n#           param_grid=param_grid,\n#          vocab=common_1_2_3_grams)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T19:04:09.261443Z","iopub.status.idle":"2023-08-11T19:04:09.261836Z","shell.execute_reply.started":"2023-08-11T19:04:09.261642Z","shell.execute_reply":"2023-08-11T19:04:09.261659Z"},"trusted":true},"execution_count":null,"outputs":[]}]}